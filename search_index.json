[
["index.html", "Apuntes de Matemáticas II; Cálculo Capítulo 1 Introducción", " Apuntes de Matemáticas II; Cálculo Jose Miró Julià 7/2/2020 Capítulo 1 Introducción El estudiante de ciencias o ingeniería, cuando piensa en matemáticas piensa en obtener resultados. Es decir, no piensa en las matemáticas en sí, sino en usar las matemáticas para resolver los problemas con los que se enferenta. Y mayoritariamente estas soluciones no son nuevas ecuaciones sino números: velocidades, masas, fuerzas, voltajes, etc. Para obtener estas soluciones se ha desarrollado la rama de las matemáticas llamada cálculo. Aunque los inicios del cálculo pueden trazarse hasta los matemáticos griegos, especialmente Arquímedes, el cálculo moderno fue una creación de dos grandes genios del S. XVII: Newton y Leibniz. Ellos desarrollaron las ideas básicas de las derivadas y de las integrales, que son el centro del cálculo moderno. Sus ideas fueron desarrolladas en los siglos sucesicos. Y siguen desarrollándose hoy en día. Sin el cálculo no existirían las matemáticas como las conocemos ahora. Realmente, no se puede ser un ingeniero sin dominar el cálculo: cualquier magnitud, por ejemplo un voltaje que cambia con el tiempo necesita de las derivadas; muchas energías se calculan como la acumulación de pequeñas energías en breves instantes de tiempo y necesitan de las integrales. Los modelos a plantear para resolver los problemas que surgen se escriben a menudo como ecuaciones diferenciales. Y todos estos conceptos parten de las ideas fundamentales de funciones y límites. No, no se puede ser un ingeniero sin dominar el cálculo. Estos son apuntes para la asignatura de Matemáticas II – Cálculo de primer curso del Grado de Ingeniería Electrónica Industrial. En ellos haremos un recorrido por las bases fundamentales de las sucesiones, límites de sucesiones, series, funciones, derivadas, integrales del cálculo en una variable. Veremos también el concepto de ecuacuión diferencial y acabaremos dando una rápida revista a cómo estos conceptos de funciones de una variables se extieden a cuando tenemos varias variables. Con el contenido de esta asignatura se tendrá una bena parte de la base matemática necesaria para abordar problemas ingenieriles de mecanica, electricidad, circuitos, etc. "],
["el-infinito-no-existe.html", "Capítulo 2 El infinito no existe 2.1 Infinitos en números 2.2 El uso de las matemáticas", " Capítulo 2 El infinito no existe En esta asignatura hablaremos una y otra vez del infinito: sucesiones infinitas, sumas infinitas, funciones que tienden al infinito… y también hablaremos a menudo de infinitesimales: números o distancias infinitamente pequeños. Conviene empezar por afirmar una realidad: el infinito no existe. Y lo infinitamente pequeño, tampoco. El infinito es una abstracción matemática que nos es muy útil y por eso la hemos creado y por eso aparece tanto. Pero en realidad no existe. Es más, los límites de lo finito pueden estar sorprendentemente cerca. Sabemos que hay 10 números naturales que podemos escribir con una cifra, 100 números que podemos escribir con dos cifras, 1000 con 3 cifras y en general \\(10^n\\) números con \\(n\\) cifras. Si queremos escribir todos los números de una cifra, del 1 al 9, nos basta un lápiz, una hoja de papel y unos segundos. Si queremos escribir todos los de hasta dos cifras, del 1 al 99, sigue bastando una hoja de papel, pero necesitaremos un minuto o dos. Si quisiéramos escribir todos los de 4 cifras, del 1 al 9999, necesitaríamos un cuaderno y una par de horas. Si quisiéramos escribir todos los de 6 cifras necesitaríamos una semana y una caja de cuadernos. Si pudiéramos escribir en átomos y cogemos un átomo y escribimos el 1, cogemos otro átomo y escribimos el 2, y así sucesivamente, ¿de cuántas cifras sería el número que escribiríamos en el último átomo del universo? No muy grande: de sólo unas 80 cifras. El infinito no existe. Lo que llamamos infinito y escribimos como \\(\\infty\\) es una abstraccion matemática. Es algo que es más grande que cualquier cosa que podamos producir. Es un número más grande que cualquier número que podamos escribir. Es el crecimiento ilimitado. 2.1 Infinitos en números Un lugar donde aparece este concepto de infinito, donde necesitamos este concepto de infinito, es en el número real, ya que un número real puede tener infinitos decimales. Luego si el infinito no existe, el número real, tampoco. Y es cierto: siempre que acabamos con un cálculo y un número, este número tiene un número finito de decimales. Si usamos una calculadora, probablemente tenga 10 a 12 decimales. Si usamos un ordenador potente, unos 16. Nunca tenemos uno con infinitos decimales. Es cierto que podemos trabajar con \\(\\pi\\) o con \\(\\sqrt{2}\\), que tiene infinitos decimales, pero en cunto lo convirtamos en algo que usemos –una distancia, un tiempo, un peso– lo recortaremos, lo redondearemos, a un número pequeño de decimales. Y deja de ser pues, un número real. Pero necesitamos los números reales. Sin números reales no tendríamos derivadas, ni integrales, ni casi ninguna de las herramientas del cálculo que han hecho posible entender el funcionamiento de la naturaleza y el avance científico. El número real, y el infinito, es una abstracción que no existe pero que nos es imprescindible. 2.2 El uso de las matemáticas El concepto del infinito y el uso que hacemos de él nos permite entender mejor el uso que hacemos de las matemáticas. Partimos de unas medidas reales de tiempo, espacio, voltajes o lo que sea. Lo que obtenemos tiene un precisión finita, luego no son numeros reales. Trasladamos estas mediciones al mundo matemático, con infinitos y por lo tanto números reales. Esto nos permite integrar, derivar resolver ecuaciones… hacer uso de toda la potencia de las herramientas matemáticas para obtener resultados como números reales. Y estos resultados los volvemos a trasladar al mundo natural. Este paso por el mundo conceptual de las matemáticas nos ha permitido llegar mucho más lejos, más rápido y con más facilidad que si nos hubiéramos quedado todo el rato en el mundo natural. Esa es la potencia de la abstracción matemática. Y sí, el pensamiento abstracto es más árido. Y sí, requiere precisión y rigor, lo que lo hace más exigente. Y sí, pierdes el sentido de utilidad directa que tiene lo real –sea un martillo o una manzana– pero despreciando la abstracción y el rigor, sin avanzar en la teoría (aunque no sepas muy bien para qué), nunca llegarás muy lejos en este mundo real. "],
["sucesiones.html", "Capítulo 3 Sucesiones 3.1 Ejemplos 3.2 Definición de sucesión 3.3 Fórmula de recurrencia 3.4 Definiciones 3.5 Representación gráfica de una sucesión 3.6 Límites de sucesiones 3.7 Operaciones con sucesiones 3.8 Ceros e infinitos 3.9 Indeterminaciones 3.10 Más sobre el cálculo de limites de sucesiones", " Capítulo 3 Sucesiones 3.1 Ejemplos Supongamos que tienes resistencias de \\(10 \\Omega\\) y los vas poniendo en serie. Si sólo tienes una resistencia, la resistencia total es de \\(10 \\Omega\\), si tienes dos, es de \\(2 \\cdot 10 \\Omega\\), si tienes 3, \\(3 \\cdot 10 \\Omega\\) y en general, si pones \\(n\\) resistencias en serie, la resistencia total es de \\(10n \\Omega\\). Supongamos ahora que los pones en paralelo. Si sólo tienes una resistencia, la resistencia total es de \\(10 \\Omega\\), si tienes dos, es de \\(\\frac{10}{2} \\Omega\\), si tienes 3, \\(\\frac{10}{3}\\Omega\\) y en general, si pones \\(n\\) resistencias en serie, la resistencia total es de \\(\\frac{10}{n} \\Omega\\). Tienes una moneda y la tiras al aire repetidamente. La probabilidad de que la primera tirada salga cara es \\(\\frac{1}{2}\\). La probabilidad de que las dos primeras salgan cara es de \\(\\frac{1}{4}\\), la probabilidad de que las 3 primeras salgan cara es de \\(\\frac{1}{8}\\) y en general, la probabilidad de que las \\(n\\) primeras salgan cara es de \\(\\frac{1}{2^n}\\). Como esto son matemáticas, olvidémonos de los ejemplos concretos y concentrémonos en los números que nos han salido. En el primer caso tenemos una sucesión de números que es \\[10, 10\\cdot2, 10\\cdot 3, \\ldots, 10n, \\ldots\\] En el segundo caso la sucesión es \\[10, \\frac{10}{2}, \\frac{10}{3}, \\ldots, \\frac{10}{n}, \\ldots\\] Y en el tercero es \\[\\frac{1}{2}, \\frac{1}{4}, \\frac{1}{8}, \\ldots, \\frac{1}{2^n},\\ldots\\] Estos son tres ejemplos de sucesiones. 3.2 Definición de sucesión Informalmente, una sucesión es una lista infinita de numeros que siguen un orden determinado. El orden es importante: la sucesión \\(1, 2, 3, 4, 5, 6, \\ldots\\) es distinta de la sucesión \\(3, 2, 1, 4, 5, 6, \\ldots\\). No tiene por qué seguir un patrón determinado. Por ejemplo, las temperaturas máximas diarias obtenidas en la estación meteorológica del aeropuerto de Palma es una lista (potencialmente) infinita de números que no siguen un patrón definido: no tenemos ninguna manera de saber el valor de la sucesión de dentro de mil días. En general nos interesan las sucesiones que tienen un patrón que podemos describir y representamos estas sucesiones indicando este patrón. Así, la primera sucesión de nuestros ejemplos es la sucesión \\(\\{a_n = 10\\cdot n\\}\\), la segunda es \\(\\{a_n = 10/n\\}\\) y la tercera es \\(\\{a_n = 1/2^n\\}\\). Seamos más formales. Una sucesión es una función que a cada número natural \\(n\\) le asigna un número real \\(a_n\\). El número \\(a_1\\) sería el primer término de la sucesión, \\(a_2\\) sería el segundo término de la sucesión y \\(a_n\\) sería el \\(n\\)-simo término de la sucesión. Algunas veces nos interesa empezar por \\(a_0\\) y a este le llamaríamos el cero-ésimo término de la sucesión, pero a menos que lo digamos explícitamente, nuestras sucesiones empezarán en 1. En general representamos la sucesión indicando la expresión del término \\(n\\)-simo. Por ejemplo la sucesión \\(\\{n^2\\}\\) sería la sucesión \\(1, 4, 9, \\ldots,n^2,\\ldots\\). Es necesario siempre dar una descripción de la sucesión. No basta con dar los primeros términos. Por ejemplo, si me dicen “sea la sucesión {1, 2, 3, …}” lo más normal es pensar que es la sucesión de los números naturales: {1, 2, 3, …, \\(n\\)…}. Pero podría ser la sucesión de Fibonacci sin el primer 1: {1, 2, 3, 5, 8…} u otra cosa más complicada: {1, 2, 3, 7, 22, … , } (cada uno es el producto de los dos anteriores más uno). Y con la edad uno aprende que una cosa es lo que uno tiene en la cabeza y otra diferente lo que le viene en la cabeza al que lo lee. Siempre hay que dar una descripcion, aunque sea informal, de toda la sucesión. 3.3 Fórmula de recurrencia Hay una segunda manera de describir una sucesión: en vez de relacionar el valor del término \\(n\\)-simo con \\(n\\) mediante una expresión matemática, lo hacemos relacionando el valor del término \\(n\\)-simo con los valores de los términos anteriores. A esto se llama una fórmula de recurrencia. El caso más conocido es el de la sucesión de Fibonacci: \\[1, 1, 2, 3, 5, 8, 13\\ldots\\] Los dos primeros términos son 1 (\\(a_1 = a_2 = 1\\)) y a partir de ahí, cada término es la suma de los dos anteriores, es decir \\(a_n = a_{n-1} + a_{n-2}\\). Hay otras dos sucesiones que a menudo se describen mediante una fórmula de recurrencia. Una es la sucesión en la que cada término es el término anterior más un cierto valor: \\(a_n = a_{n-1} + d\\). La otra es similar: cada término es el término anterio multiplicado por un factor: \\(a_n = r\\cdot a_{n-1}\\). Estas dos sucesiones tienen nombre propio y se llaman la progresión aritmética y la progresión geométrica respectivamente. Un motivo por el que se usa la fórmula de recurrencia es que puede ser mucho más sencillo describir la sucesión así que de la forma tradicional. Este es el caso de la sucesión de Fibonacci. Otro motivo es porque muestra de forma más intuitiva la esencia de la sucesión. La progresión aritmética se puede describir como \\(\\{a_n = a_1 + (n-1)d\\}\\) y la progresión geométrica como \\(\\{a_n = a_1\\cdot r^{n-1}\\}\\), pero estas dos expresiones no muestran de forma tan obvia como varía la sucesión. 3.4 Definiciones Paul Halmos es un conocido matemático americano. En su autobiografía comenta que cuando estudiaba la carrera de matemáticas descubrió que sabiéndose bien las definiciones y con un poco de sentido común y técnica, tenía prácticamente garantizado el notable. Además, es mucho más fácil seguir una explicación, sea del profesor o de un libro, si tienes interiorizadas las defeniciones: si una frase comienza con “Sea una sucesión acotada…” y no sabes qué es una sucesión acotada, todo lo que sigue no tiene significado para ti. Yo creo que buena parte de las dificultades que la gente tiene en entender las matemáticas proviene de no esforzarse por conocer primero las definiciones. Empecemos por ellas Decimos que una sucesión \\(\\{a_n\\}\\) es monótona creciente si para todo \\(n\\), \\(a_n ≤ a_{n+1}\\). Es decir, cada término es mayor o igual que el anterior. Decimos que una sucesión \\(\\{a_n\\}\\) es monótona decreciente si para todo \\(n\\), \\(a_n ≥ a_{n+1}\\). Es decir, que cada término es menor o igual que el anterior. Decimos que una sucesión \\(\\{a_n\\}\\) es monótona si es o monótona creciente o monótona decreciente. Decimos que una sucesión \\(\\{a_n\\}\\) es estrictamente creciente si para todo \\(n\\), \\(a_n &lt; a_{n+1}\\). Es decir, que cada término es estrictamente mayor que el anterior. Decimos que una sucesión \\(\\{a_n\\}\\) es estrictamente decreciente si para todo \\(n\\), \\(a_n &gt; a_{n+1}\\). Es decir, que cada término es estrictamente menor que el anterior. Decimos que una sucesión \\(\\{a_n\\}\\) está acotada superiormente si existe un número \\(M\\) tal que \\(a_n ≤ M\\) para todo \\(n\\). Es decir, que hay un valor \\(M\\) que es mayor o igual que cualquier término de la sucesión. Se dice que \\(M\\) es una cota superior de la sucesión. Decimos que una sucesión \\(\\{a_n\\}\\) está acotada inferiormente si existe un numero \\(M\\) tal que \\(a_n ≥ M\\) para todo \\(n\\). Es decir, que hay un valor \\(M\\) que es menor o igual que cualquier término de la sucesión. Se dice que \\(M\\) es una cota inferior de la sucesión. Decimos que una sucesión \\(\\{a_n\\}\\) está acotada si está acotada superiormente e inferiormente. En resumen, la palabra monótona nos indica que siempre va en la misma dirección, aunque permite que se mantenga constante. La palabra estricta indica que va siempre en la misma dirección y no puede manetenerse constante: estrictamente crece o decrece. La palabra acotada nos indica que hay una cota: una valor que nunca se traspasa, ya sea superiormente o inferiormente. Veamos algunos ejemplos. 3.4.1 Ejemplos Ejemplo 3.1 Veamos que la sucesión de los números naturales \\(\\{n\\}\\) es monótona creciente. Aplicamos la definición: Es monótona creciente si para todo \\(n\\), \\(a_n ≤ a_{n+1}\\) que se traduce en \\(n ≤ n+1\\) para todo \\(n\\). Aunque esto es obviamente cierto, seamos formales: restemos \\(n\\) a cada lado y tenemos \\(0 ≤ 1\\), y esto es siempre cierto. Es más, como \\(0 &lt; 1\\) es estrictamente creciente. Ejemplo 3.2 Sea la sucesión \\(\\{a_n = n^2 - n\\}\\), con \\(n = 0, 1, 2…\\). Veamos que es monótona creciente. Aplicamos la definición: \\(a_{n+1} ≥ a_{n}\\) se traduce en \\[(n+1)^2 - (n+1) ≥ n^2 - n\\] Desarrollamos: \\[n^2 + 2n + 1 - n - 1 ≥ n^2 - n\\] y nos queda \\[n^2 + n ≥ n^2 - n\\] lo que significa que \\[n ≥ -n\\] Como \\(n ≥ 0\\), esto se cumple siempre. Nótese que la sucesión no es estrictamente creciente, pues para \\(n = 0\\) tenemos que \\(n = -n\\). Si los términos son todos positivos, la definición de monótona creciente, \\(a_{n+1} ≥ a_n\\), es equivalente a decir que \\(a_{n+1}/a_n ≥ 1\\) (o \\(a_{n+1}/a_n ≤ 1\\) para las monótonas decrecientes). Y esta segunda definición puede ser más conveniente a veces. Ejemplo 3.3 Determine si la sucesión \\(\\{a_n = 1/(n - 5.1)^2\\}\\) es monótona. Veamos si es monótona creciente. Entonces: \\[\\frac{a_{n+1}}{a_{n}} = \\frac{\\frac{1}{(n+1-5.1)^{2}}}{\\frac{1}{(n-5.1)^{2}}} = \\frac{(n-5.1)^{2}}{(n-4.1)^{2}} = \\frac{n^{2} + 26.01 - 10.2 n}{n^{2} + 16.81 - 8.2 n}\\] Teniendo en cuenta que \\(26.01 = 16.82 +9.2\\) y que \\(10.2n = 8.2n + 2n\\) podemos reescribir el numerador como \\[\\frac{(n^{2} + 16.81 - 8.2 n) + (9.2 - 2 n)}{n^{2} + 16.81 - 8.2 n} = 1 + \\frac{9.2 - 2 n}{n^{2} + 16.81 - 8.2 n}\\] Y ahora todo se reduce a saber si la fracción es positiva o negativa. Es fácil ver que el numerador es positivo para \\(n&lt;5\\) y negativo para \\(n ≥ 5\\). Para el denominador podríamos resolver la ecuación de segundo grado. Pero si nos damos cuenta que para valores grandes de \\(n\\) es positivo, podemos probar alguno valores menores y nos damos cuenta de que siempre es positivo. En resumen, la fracción es positiva para \\(n &lt; 5\\) y negativa para \\(n ≥ 5\\). De aquí deducimos que \\(\\frac{a_{n+1}}{a_{n}} &gt; 1\\), y por lo tanto la sucesión es creciente, para \\(n &lt; 5\\) y \\(\\frac{a_{n+1}}{a_{n}} &gt; 1\\), y por lo tanto lo tanto la sucesión es decreciente, para \\(n≥5\\). Como para ciertos valores de \\(n\\) es creciente y para otros es decreciente, esta sucesión no es monótona. Ejemplo 3.4 Determine si la sucesión \\(\\{a_n = 1/(n - 5.1)^2\\}\\) está acotada. Sabemos por el ejemplo anterior que esta sucesión es creciente hasta \\(n = 5\\) y decreciente después, luego la sucesión está acotada superiormente. El valor \\(a_5 = 100\\) es una cota superior. Naturalmente, 105 o 200 o 578,3 o cualquier valor mayor que 100 será también una cota superior. El numerador del término general es 1 y el denominador es siempre positivo, luego todos los términos son estrictamente positivos. Esto hace que 0 sea una cota inferior. Cualquier número negativo también será una cota inferior. Como la sucesión tiene cota superior y cota inferior, la sucesión está acotada. 3.5 Representación gráfica de una sucesión Nuestros ojos son muy poderosos y visualizar una sucesión nos puede resultar muy útil para coger una idea de cómmo se comporta. Hay dos maneras habituales de respresentar gráficamente una sucesión: la recta real y el plano cartesiano. Usemos como primer ejemplo la sucesion \\(\\{a_n = n/(n+1)\\}\\). Sus primeros términos son 1/2, 2/3, 3/4, 4/5, 5/6… La primera forma de representación es simplemente coger la recta real y marcar todos los términos de la sucesión: Esta representación nos permite ver los infinitos términos de una sucesión acotada, pero perdemos la información de qué punto corresponde a qué término. La segunda forma de representación es el plano cartesiano: en el eje X tenemos \\(n\\) y en el eje Y tenemos \\(a_n\\): Con esta gráfica podemos ver la “evolución” de la sucesión al aumentar \\(n\\), pero nunca podremos ver más allá de unos pocos términos. Qué representación es mejor depende de cada caso. Veamos otro ejemplo: \\(a_n = \\sin(n)/n\\). La primera representación sería Y la segunda En la primera representación vemos que hay muchos puntos aglomerados alrededor del 0, lo que nos permite suponer que tiende a 0. En la segunda, los términos que vemos tienden a 0, o que también nos permite suponer que tiende a 0 al tender \\(n\\) a infinito. 3.6 Límites de sucesiones La sucesión \\(\\{a_n = n\\}\\) crece y crece y no tiende a ningún valor. En cambio las dos sucesiones que hemos visto en el apartado anterior, \\(\\{a_n = n/(n+1)\\}\\) y \\(\\{a_n = \\sin(n)/n\\}\\) sí que parece que tienden a algún valor: la primera se va acercando a 1 y la segunda se va acercando a 0. Pero qué queremos decir con “tiende a”. Informalmente queremos decir que se va acercando más y más al valor en cuestión y llega un momento en el que nunca se aleja, que acaban estando tan cerca como queramos no sólo para un valor de \\(n\\), sino para todos los valores de \\(n\\) a partir de un cierto momento. Cuando esto sucede, decimos que el límite de la sucesión es este valor y que la sucesión converge. Si en cambio nunca se acerca definitivamente a un valor decimos que no tiene límite y que la sucesión diverge. Ya hemos visto gráficamente que la sucesión \\(\\{a_n = n/(n+1)\\}\\) tiene límite 1, o que converge hacia 1. También hemos dicho, y es fácil de ver, que la sucesión \\(\\{a_n = n\\}\\) crece sin límite, y por lo tanto diverge. Hay otro caso que conviene considerar. Sea la sucesión 0, 1, 2, 1, 0, 1, 2, 1, 0… que sube y baja sin cesar en forma de sierra: Esta sucesión no tiende a ningún valor y no se acerca definitivamente a ningún valor, nunca se acaba de decidir. Esta sucesión no se hace infinitamente grande, pero no tiene límite y también diverge. 3.6.1 Definición formal de limite de una sucesión Sea una sucesión \\(\\{a_n\\}\\). Decimos que esta sucesión tiene límite \\(L\\) cuando \\(n\\) tiende a infinito si para cualquier distancia \\(\\varepsilon\\) que nosotros queramos, tan pequeña como queramos, existe un cierto término de la sucesión \\(N\\), tal que a partir de este término, todos los términos de la sucesión están más cerca de \\(L\\) que \\(\\varepsilon\\). De forma más “matemática”, más rigurosa y abstracta: Definición 3.1 Sea una sucesión \\(\\{a_n\\}\\). Decimos que esta sucesión tiene límite \\(L\\) cuando \\(n\\) tiende a infinito, y lo escribimos como \\[\\lim_{n \\to \\infty} a_n = L\\] si para cualquier número positivo \\(\\varepsilon\\), podemos encontrar un entero positivo \\(N\\), dependiente de \\(\\varepsilon\\), tal que \\(|a_n – L| &lt; \\varepsilon\\) para todos los enteros \\(n &gt; N\\). Esto lo podemos representar gráficamente. Si lo hacemos con la primera representación, tenemos para cualquier \\(\\varepsilon\\) que escojamos, un intervalo \\((L-\\varepsilon, L+\\varepsilon)\\) tal que a partir de un cierto término \\(N\\), todos los puntos de la sucesión están dentro del intervalo. Si lo hacemos con la segunda forma de representación, hay una banda entre \\((L-\\varepsilon\\) y \\(L+\\varepsilon)\\) tal que todos los puntos de la sucesión están dentro de esta banda. 3.6.2 Un teorema importante En cuanto tenemos un poco de experiencia en la mayoría de los casos podemos establecer si una sucesión tiene límite (es convergente) o no. Pero incluso para una persona experimentada hay algunas sucesiones para las que no es obvio saber si tienen límite o no. Hay una serie de teoremas que nos ayudan para establecer la convergencia de sucesiones. El más importante es el siguiente: Teorema 3.1 Una sucesión monótona y acotada es convergente. No vamos a demostrar este teorema, pero si lo pensamos un poco es bastante lógico. Consideremos el caso monótona creciente y acotada superiormente. El caso decreciente es análogo. Si la sucesión es monótona creciente, cada término es al menos tan grande como el anterior. Al ser acotada, no puede crecer sin límite, pues no puede pasar la cota. Luego tiene que tender hacia algún valor sin pasarlo, acercándose a este valor más y más. Luego tiene límite. Ejemplo 3.5 Demuestre que la sucesión \\(\\{a_n = \\frac{1}{n}\\}\\) tiene límite. vamos a empezar por demostrar que es monótona decreciente. Para ello calculamos \\(a_{n+1}/a_n\\) y demostramos que es menor que 1: \\[ \\frac{a_{n+1}}{a_n} = \\frac{\\frac{1}{n+1}}{\\frac{1}{n}} = \\frac{n}{n+1} &lt; 1\\] Una vez demostrado que la sucesión es monótona decreciente, vamos a demostrar que tiene una cota inferior. Es inmediato: todos los términos son estrictamente positivos, luego 0 es una cota inferior. Como la sucesión \\(\\{a_n = \\frac{1}{n}\\}\\) es monótona y acotada, es convergente. 3.6.3 Ejemplos Ejemplo 3.6 Hemos visto gráficamente que la sucesión \\(\\{a_n = n/(n+1)\\}\\) tiende al valor 1. Vamos a demostrar que el límite de esta sucesión es efectivamente 1. Como la sucesión es siempre menor que 1, podemos escribir \\(|a_n – L| &lt; \\varepsilon\\) como \\((1 - \\frac{n}{n+1}) &lt; \\varepsilon\\) sin el valor absoluto y entonces tenemos \\[1 - \\frac{n}{n+1} = \\frac{n+1-n}{n} = \\frac{1}{n+1} &lt; \\varepsilon\\] que podemos reescribir como \\[ \\frac{1}{\\varepsilon} &lt; n+1\\] y despejando la \\(n\\) nos queda \\[n &gt; \\frac{1}{\\varepsilon} - 1. \\] Y ahora para cualquier valor de \\(\\varepsilon\\) que queramos podemos calcular el término a partir del cual la sucesión está siempre más cerca del valor del límite que \\(\\varepsilon\\). Por ejemplo, para \\(\\varepsilon = 0,01\\) sabemos que para \\(n &gt; (1/0,01) - 1 = 99\\) la sucesión siempre estará a menos de 0,01 de 1. Para \\(\\varepsilon = 0,0005\\) sabemos que para \\(n &gt; (1/0,0005) - 1 = 1999\\) la sucesión siempre estará a menos de 0,0005 de 1. La otra sucesion para la que hicimos las representaciones gráficas fue \\(\\{sen(n)/n\\}\\) y vimos que tiende a 0. Podríamos pensar que ese \\(\\sin(n)\\) nos iba hacer muy complicado demostrar que tiene límite. Pero en estos casos hay un truco simple y útil: buscamos una sucesión que está más alejada y que de todas formas tiende a 0. Para simplificar la explicación vamos a considerar sólo los casos positivos (se haría igual con los negativos). Como \\(\\sin(n) ≤ 1\\), en vez de \\(\\{\\sin(n)/n\\}\\) consideramos la sucesión \\(\\{1/n\\}\\). Si para cualquier \\(\\varepsilon\\) puedo encontrar un valor de \\(N\\) tal que para todo \\(n&gt;N\\) \\(|(1/n) - 0| &lt; \\varepsilon\\), con más razón \\(|(\\sin(n)/n) - 0|\\), que es menor, va a estar más cerca del 0. Es un buen ejercicio en estos momentos demostrar que efectivamente \\(lim_{n \\to \\infty} (1/n) = 0\\). Ejemplo 3.7 Vamos a demostrar que la sucesión 0, 1, 2, 1, 0, 1, 2, 1, 0… no tiene límite. Escojamos un valor de \\(\\varepsilon\\) menor que 1. Por ejemplo \\(\\varepsilon = 0,7\\). Entonces no hay ningún valor \\(L\\) tal que el intervalo \\((L - 0.7, L + 0.7)\\) cubra el 0, el 1 y el 2. Como hemos encontrado un valor de \\(\\varepsilon\\) que hace que no se cumpla la condición, la sucesión no tiene límite. Nótese que para que haya límite debo poder encontrar el valor de \\(N\\) para cualquier valor de \\(\\varepsilon\\). Pero para que no la haya, basta encontrar un valor de \\(\\varepsilon\\) para el que no haya ningún valor de \\(N\\). Ejemplo 3.8 Demuestre que la sucesión \\(\\{n^2 - n \\}\\) no tiene límite. Es fácil ver que esta sucesión crece sin límite. Vamos a demostrar que la sucesión no se acerca a ningún valor, sino que se aleja de cualquier valor \\(L\\). Es decir, para cualquier valor \\(L\\) hay un \\(N\\) tal que para valores \\(n &gt; N\\) la sucesión es siempre mayor que \\(L\\). Si \\(a_n &gt; L\\) entonces \\(a_n - L &gt; 0\\). Esto queda como: \\[n^2 - n - L &gt;0\\] Podemos resolver la ecuación de segundo grado y quedarnos sólo con el valor positivo de \\(n\\) y nos queda \\[n &gt; \\frac{1 + \\sqrt{1 + 4L}}{2} = \\frac{1}{2} + \\sqrt{\\frac{1}{4} + L}\\] Luego para cualquier \\(L\\), por grande que lo hagamos, tenemos un valor de \\(N\\) tal que para todo \\(N &gt; n\\), \\(a_n &gt; L\\). No tiene límite. 3.7 Operaciones con sucesiones Supongamos que tenemos una sucesión \\(a_n = 1, 2, 3, 4,…\\) y otra sucesión \\(b_n = -1, -3, -5, -7, …\\) Podemos definir la suma de estas sucesiones como la suma término a término: \\(1-1, 2-3, 3-5, 4-7,… = 0, -1, -2, -3,…\\). Formalmente, sean dos sucesiones \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\) y una operación \\(\\circ\\). Definimos la sucesión \\(\\{c_n\\} = \\{a_n\\} \\circ \\{b_n\\}\\) como la sucesión \\(a_1 \\circ b_1, a_2 \\circ b_2, a_3 \\circ b_3,…\\). El término general de la sucesión \\(\\{c_n\\}\\) es \\(a_n \\circ b_n\\). Por ejemplo para el caso de la suma esto se resume en la frase “el límite de la suma es la suma de los límites”. Y lo mismo para las demás operaciones. Las operaciones más habituales son las aritméticas: \\(\\{a_n + b_n\\}\\), \\(\\{a_n - b_n\\}\\), \\(\\{a_n \\cdot b_n\\}\\), \\(\\{a_n / b_n\\}\\). Pero también se usa la potenciación \\(a_n^{b_n}\\). Las operaciones con sucesiones son muy interesantes pues facilita el cálculo de límites Tenemos las sucesiones \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) y \\(\\{c_n\\} = \\{a_n\\} \\circ \\{b_n\\}\\) y tenemos que los límites de \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) existen y son \\(\\lim_{n \\to \\infty}a_n = A\\) y \\(\\lim_{n \\to \\infty}b_n = B\\). Entonces, en general, \\(\\lim_{n \\to \\infty}c_n = A\\circ B\\). Hay excepciones que veremos un poco más adelante. Ejemplo 3.9 Sea \\(\\{a_n = 3 + (1/n)\\}\\) y \\(\\{ b_n = 2 - (1/n^2)\\}\\). Es fácil ver y demostrar que \\(\\lim_{n \\to \\infty}a_n = 3\\) y \\(\\lim_{n \\to \\infty}b_n = 2\\). Entonces \\[\\begin{align} lim_{n \\to \\infty} (a_n + b_n) &amp;= \\lim_{n \\to \\infty}a_n + \\lim_{n \\to \\infty}b_n = 3 + 2 = 5\\\\ lim_{n \\to \\infty} (a_n - b_n) &amp;= \\lim_{n \\to \\infty}a_n - \\lim_{n \\to \\infty}b_n = 3 - 2 = 1\\\\ lim_{n \\to \\infty} (a_n \\cdot b_n) &amp;= \\lim_{n \\to \\infty}a_n \\cdot \\lim_{n \\to \\infty}b_n = 3 \\cdot 2 = 6\\\\ lim_{n \\to \\infty} \\frac{a_n}{b_n} &amp;= \\frac{\\lim_{n \\to \\infty}a_n}{\\lim_{n \\to \\infty}b_n} = \\frac{3}{2} = 1,5\\\\ lim_{n \\to \\infty} a_n^{b_n} &amp;= \\lim_{n \\to \\infty}a_n^{\\lim_{n \\to \\infty}b_n} = 3^2 = 9 \\end{align}\\] 3.8 Ceros e infinitos Nota previa: A partir de aquí vamos a hablar de sucesiones cuyo límite es infinito (o menos infinito) y escribiremos cosas como \\(\\lim_{n \\to \\infty}a_n = \\infty\\). Esto es incorrecto. Lo correcto es decir que el límite no existe. Pero expresarnos con absoluta corrección matemática es farragoso y dificulta tanto escribir el texto como leerlo y entenderlo. Es costumbre en todos los libros que conozco usar esta incorrección para facilitar la comprensión. Sea la sucesión \\(\\{a_n = n/(n+1)\\}\\). Sabemos que \\(\\lim_{n \\to \\infty}a_n = 1\\). Sea la sucesión \\(\\{b_n = n^2\\}\\). Es fácil ver que \\(\\lim_{n \\to \\infty}b_n = \\infty\\). Consideremos la suma de estas sucesiones, \\(\\{ c_n\\} = \\{a_n\\} + \\{b_n\\}\\). Si la primera se acerca a 1 todo lo que queramos al crecer \\(n\\) y la otra crece sin límite, es de razón ver que la suma de ambas crece sin límite: \\(\\lim_{n \\to \\infty} c_n = \\infty\\). Si en vez de sumar las sucesiones, las dividimos, \\(\\{ c_n\\} = \\{a_n\\}/\\{b_n\\}\\), entonces tenemos unos términos que se aproximan a 1 que están divididos por términos cada vez mayores. Es de razón ver que la división de ambas se hace cada vez más pequeño: \\(\\lim_{n \\to \\infty} c_n = 0\\). No vamos a entrar en más detalles, pero es fácil comprobar la siguiente aritmética de los límites de sucesiones: \\[ A + \\infty = \\infty \\qquad A - \\infty = -\\infty \\qquad \\infty - A = \\infty \\qquad \\infty + \\infty = \\infty\\] \\[ A \\cdot \\infty = \\infty \\qquad A \\cdot -\\infty = -\\infty \\qquad \\infty \\cdot \\infty = \\infty\\] \\[ A/ \\infty = 0 \\qquad \\infty/A = \\infty \\qquad A/0 = \\infty\\; (A ≠ 0) \\qquad \\] Debe notarse que lo que representamos arriba no son números, sino límites de sucesiones. No estamos diciendo, por ejemplo, que el número \\(A\\) dividido por el número 0 es el número \\(\\infty\\), sino que si tenemos una sucesión cuyo límite es \\(A\\) y otra sucesión cuyo límite es 0, el límite de la sucesión resultante de dividir estas dos sucesiones tiene por límite \\(\\infty\\). No todos los casos posibles están representados arriba. Uno se podría preguntar, ¿qué pasa si restamos dos sucesiones cuyos límites son ambos \\(\\infty\\)? En este caso tenemos una indeterminación y es lo que estudiaremos en el próximo apartado. 3.9 Indeterminaciones Sea la sucesión \\(\\{a_n = n\\}\\) y la sucesión \\(\\{b_n = n-1\\}\\). Sabemos que \\(\\lim_{n \\to \\infty}a_n = \\infty\\) y que \\(\\lim_{n \\to \\infty}b_n = \\infty\\). Consideremos ahora la sucesión \\(\\{c_n\\} = \\{a_n\\} - \\{b_n\\}\\). Esta sucesión es \\(\\{c_n = n - (n-1) = 1\\}\\) y su límite es, obviamente, 1. Luego tenemos dos sucesiones que tienden a \\(\\infty\\), que cuando las restamos dan lugar a una sucesión de límite 1. Pero no es siempre así. Consideremos las sucesiones \\(\\{a_n = n^2\\}\\) y \\(\\{b_n = n\\}\\). Ambas tienen límite infinito. La sucesión resultante de la resta es \\(\\{c_n = n^2 - n\\}\\) y más arriba demostramos que \\(\\lim_{n \\to \\infty} n^2 - n = \\infty\\). Luego si tenemos dos sucesiones con límite infinito, no sabemos qué valor tendrá el límite de la sucesión obtenida restándolas. Decimos que el límite es indeterminado. Hay siete tipos de indeterminaciones. Son: \\[\\infty - \\infty \\qquad \\frac{\\infty}{\\infty} \\qquad 1^\\infty \\qquad 0\\cdot \\infty \\qquad \\infty^0 \\qquad \\frac{0}{0} \\qquad 0^0\\] Repito otra vez que no quiere decir esto que el número 0 multiplicado por el “número” \\(\\infty\\) sea indeterminado, sino que si tengo una sucesión cuyo límite es cero y otra sucesión cuyo límite es \\(\\infty\\), el límite de la sucesión producto de estas dos sucesiones es indeterminado. Si tenemos una indeterminación, no sabemos a priori qué pasa con el límite de la sucesión: puede ser convergente, puede ser divergente, puede tender a cualquier número. Hay que resolver la indeterminación caso por caso para poder calcular el límite. Veamos algunos casos. 3.9.1 Indeterminación \\(\\frac{\\infty}{\\infty}\\) Sea la sucesión \\[c_n = \\frac{3n^2 + n + 6}{2n^2 -5}\\] Es fácil ver que el límite tanto del numerador como del denominador es \\(\\infty\\), luego tenemos una indeterminación del tipo \\(\\frac{\\infty}{\\infty}\\). En casos como este lo que hemos de hacer es dividir tanto el numerador como el denominador por el término de mayor exponente: \\[\\lim_{n \\to \\infty}\\frac{3n^2 + n + 6}{2n^2 -5} = \\lim_{n \\to \\infty}\\frac{\\frac{3n^2 + n + 6}{n^2}}{\\frac{2n^2 -5}{n^2}} = \\lim_{n \\to \\infty}\\frac{3 + 1/n + 6/n^2}{2 - 5/n^2}\\] Difundimos los límites: \\[\\frac{\\lim_{n \\to \\infty} (3 + 1/n + 6/n^2)}{\\lim_{n \\to \\infty}(2 - 5/n^2)} = \\frac{\\lim_{n \\to \\infty} 3 + \\lim_{n \\to \\infty}(1/n) + \\lim_{n \\to \\infty}(6/n^2)}{\\lim_{n \\to \\infty}2 - \\lim_{n \\to \\infty}(5/n^2)}\\] Todos los límites son fáciles de calcular y nos queda \\[\\lim_{n \\to \\infty} c_n = \\frac{3 + 0 + 0}{2 - 0} = \\frac{3}{2}\\] Veamos otro ejemplo. Ejemplo 3.10 Encuentre el límite de la sucesión \\[c_n = \\frac{n - 6}{n^2 + 4}\\] Es otra vez de tipo \\(\\frac{\\infty}{\\infty}\\). Dividimos numerador y denominador por el \\(n\\) con mayor exponente y tenemos \\[\\lim_{n \\to \\infty} c_n = \\lim_{n \\to \\infty} \\frac{\\frac{n-6}{n^2}}{\\frac{n^2 + 4}{n^2}} = \\lim_{n \\to \\infty} \\frac{1/n - 6/n^2}{1 + 4/n^2}\\] Difundimos los límites y nos queda: \\[\\lim_{n \\to \\infty} c_n = \\frac{0 - 0}{1 + 0} = 0\\] 3.9.2 Indeterminación \\(\\infty - \\infty\\) Sea la sucesión \\(\\{c_n = 3n^2 - 8n\\}\\). Este es un claro caso de indeterminación del tipo \\(\\infty - \\infty\\). En casos como este multiplicamos y dividimos por el conjugado de la expresión, es decir, \\(3n^2 + 8n\\): \\[\\lim_{n \\to \\infty} 3n^2 - 8n = \\lim_{n \\to \\infty} \\frac{(3n^2 - 8n)(3n^2 + 8n)}{3n^2 + 8n}\\] Como “suma por diferencia es la diferencia de cuadrados” nos queda: \\[\\lim_{n \\to \\infty} \\frac{3n^4 - 8n^2}{3n^2 + 8n}\\] Y hemos convertido la indeterminación de tipo \\(\\infty - \\infty\\) a una de tipo \\(\\frac{\\infty}{\\infty}\\) que ya sabemos resolver. Dejo los detalles, pero el resultado final es \\[\\lim_{n \\to \\infty} c_n = \\frac{3 - 0}{0 + 0} = \\infty\\] Veamos otro ejemplo. Ejemplo 3.11 Encuentre el límite de la sucesión \\[c_n = \\sqrt{n^2 - n + 1} - 2n\\] Multiplicamos y dividimos por el conjugado: \\[\\lim_{n \\to \\infty} c_n = \\frac{(\\sqrt{n^2 - n + 1} - 2n)(\\sqrt{n^2 - n + 1} + 2n)}{\\sqrt{n^2 - n + 1} + 2n}\\] Esto se convierte en \\[\\lim_{n \\to \\infty}\\frac{(n^2 - n + 1) - 4n^2}{\\sqrt{n^2 - n + 1} + 2n} = \\frac{-3n^2 - n + 1}{\\sqrt{n^2 - n + 1} + 2n}\\] Ya es una indeterminación del tipo \\(\\frac{\\infty}{\\infty}\\). Dividimos numerador y denominador por \\(n^2\\): \\[\\lim_{n \\to \\infty}\\frac{-3 - 1/n + 1/n^2}{\\sqrt{1/n^2 - 1/n^3 + 1/n^4} + 2/n}\\] Difundimos los límites y queda: \\[\\lim_{n \\to \\infty} c_n = \\frac{-3}{0} = -\\infty\\] 3.9.3 Indeterminación \\(1^\\infty\\) Sea la sucesión \\(\\{c_n = (1 + \\frac{1}{n})^n\\}\\). Tenemos la sucesión \\(\\{a_n = (1 + \\frac{1}{n})\\}\\) que tiene límite 1, elevada a la sucesión \\(\\{b_n = n\\}\\) que tiene límite , luego en una indeterminación del tipo \\(1^\\infty\\). Se puede demostrar que esta sucesión tiene límite y que este límite es el número \\(e\\). Este resultado lo podemos generalizar. Dada cualquier sucesión \\(\\{a_n\\}\\) tal que \\(\\lim_{n \\to \\infty} a_n = \\pm\\infty\\), la sucesión \\(\\{c_n = (1 + \\frac{1}{a_n})^{a_n}\\}\\) tiene por límite el número \\(e\\). Una de las maneras de resolver este tipo de indeterminaciones es manipular la sucesión para que tenga una parte central de la forma \\((1 + \\frac{1}{a_n})^{a_n}\\). Sea la sucesión \\[\\{c_n = (1 + \\frac{1}{n^2})^n\\}\\] Queremos manipular el exponente de manera que aparezca un \\(n^2\\). No es difícil: \\[(1 + \\frac{1}{n^2})^{n^2 \\frac{1}{n}}\\] Y ahora: \\[\\lim_{n \\to \\infty} (1 + \\frac{1}{n^2})^{n^2 \\frac{1}{n}} = \\lim_{n \\to \\infty} ((1 + \\frac{1}{n^2})^{n^2})^\\frac{1}{n} = (\\lim_{n \\to \\infty} (1 + \\frac{1}{n^2})^{n^2})^{\\lim_{n \\to \\infty} 1/n} = e^0 = 1\\] A veces la manipulación es un poco más complicada, como en el siguiente ejemplo. Ejemplo 3.12 Calcule el límite de la sucesión \\[\\{c_n = \\left(\\frac{2n + 3}{2n -4}\\right)^{n-3}\\}\\] Como \\(2n+3 = (2n-4) + 7\\), podemos reescribir la fracción como \\[\\left(\\frac{2n -4 + 7}{2n -4}\\right)^{n-3} = \\left(1 + \\frac{7}{2n -4}\\right)^{n-3}\\] Queremos \\((1 + \\frac{1}{n})\\), luego pasamos el 7 al denominador: \\[ \\left(1 + \\frac{1}{\\frac{2n -4}{7}}\\right)^{n-3}\\] Queremos la sucesión \\(\\{\\frac{2n -4}{7}\\}\\) en el exponente, luego reescribimos el exponente: \\[ \\left(1 + \\frac{1}{\\frac{2n -4}{7}}\\right)^{\\frac{2n-4}{7}\\cdot \\frac{7(n-3)}{2n - 4}}\\] Y ya podemos calcular el límite: \\[\\lim_{n \\to \\infty}c_n =\\lim_{n \\to \\infty} \\left(1 + \\frac{1}{\\frac{2n -4}{7}}\\right)^{\\frac{2n-4}{7}\\cdot \\frac{7(n-3)}{2n - 4}} = \\left(\\lim_{n \\to \\infty} \\left(1 + \\frac{1}{\\frac{2n -4}{7}}\\right)^{\\frac{2n-4}{7}}\\right)^{\\lim_{n \\to \\infty}\\frac{7(n-3)}{2n - 4}} = e^{\\frac{7}{2}}\\] 3.10 Más sobre el cálculo de limites de sucesiones 3.10.1 Regla del encaje Tenemos tres sucesiones \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) y \\(\\{c_n\\}\\) y a partir de algún \\(N\\), no importa lo grande que sea, \\(\\{c_n\\}\\) está siempre entre \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\). Entonces, si existen los tres límites, el límite de \\(\\{c_n\\}\\) también está entre los de \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\). Formalmente, si para todo \\(n &gt; N\\), \\(b_n ≤ c_n ≤ a_n\\), entonces \\(\\lim_{n \\to \\infty} \\{b_n\\} ≤ \\lim_{n \\to \\infty} \\{c_n\\} ≤ \\lim_{n \\to \\infty} \\{a_n\\}\\). A esto se le llama la regla del encaje: si \\(\\{c_n\\}\\) está “encajada” entre \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\), su límite también lo está. No es difícil demostrar este resultado a partir de la definición de límite. El caso más interesante es cuando \\(\\lim_{n \\to \\infty} \\{b_n\\} = \\lim_{n \\to \\infty} \\{a_n\\}\\), porque entonces los tres límites han de ser iguales: \\(\\lim_{n \\to \\infty} \\{b_n\\} = \\lim_{n \\to \\infty} \\{c_n\\} = \\lim_{n \\to \\infty} \\{a_n\\}\\). Esta regla del encaje nos es muy útil en algunos casos, por ejemplo si tenemos funciones trigonométricas. Ejemplo 3.13 Calcule el límite de la sucesión de término general \\[\\frac{n - \\cos(nπ)}{3n}\\] Como el valor del coseno está siempre entre \\(-1\\) y \\(1\\), podemos crear con facilidad dos sucesiones encajadas: \\[\\frac{n - 1}{3n} ≤ \\frac{n - \\cos(nπ)}{3n} ≤ \\frac{n +1}{3n}\\] Ahora aplicamos límites: \\[\\lim_{n \\to \\infty}\\frac{n - 1}{3n} ≤ \\lim_{n \\to \\infty}\\frac{n - \\cos(nπ)}{3n} ≤ \\lim_{n \\to \\infty}\\frac{n +1}{3n}\\] y tenemos que \\[\\frac{1}{3} ≤ \\lim_{n \\to \\infty}\\frac{n - \\cos(nπ)}{3n} ≤ \\frac{1}{3}\\] Y ya tenemos nuestro límite: \\[\\lim_{n \\to \\infty}\\frac{n - \\cos(nπ)}{3n} = \\frac{1}{3}\\] 3.10.2 Jerarquía de infinitos No todos los infinitos son iguales. Unos infinitos son “más infinitos” que otros. Consideremos la sucesión \\(\\{n^2 - 10n\\}\\). Para valores pequeños de \\(n\\) el segundo término es de mayor magnitud que el primero y los términos son negativos, pero a medida que \\(n\\) crece, el \\(n^2\\) domina sobre el \\(10n\\) y éste acaba siendo un pequeño apéndice sin importancia del total. Esto nos simplifica mucho el cálculo de límites: en las sumas o restas sólo los infinitos dominantes importan y nos podemos olvidar del resto. Formalmente: Dadas dos sucesiones \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\) tales que \\(\\lim_{n \\to \\infty} \\{a_n\\} = \\infty\\) y \\(\\lim_{n \\to \\infty} \\{b_n\\} = \\infty\\), se dice que \\(\\{b_n\\}\\) es un infinito de orden superior, o que \\(\\{b_n\\}\\) domina sobre \\(\\{a_n\\}\\) si \\[\\lim_{n \\to \\infty} \\frac{\\{b_n\\}}{\\{a_n\\}} = 0\\] Esto se representa como \\(\\{a_n\\} \\ll \\{b_n\\}\\). Podemos crear con este concepto una jerarquía de infinitos. Dadas dos constantes \\(a &gt;1\\) y \\(p &gt; 0\\): \\[\\log(n) \\ll n^p \\ll a^n \\ll n! \\ll n^n \\] y dentro de las potencias \\(n^{p} \\ll n^q\\) si \\(0 &lt; p &lt; q\\). Para calcular un límite, de las sumas o restas de sucesiones buscamos cuál es el infinito de orden superior y eliminamos el resto. Ejemplo 3.14 Calcule el límite de la sucesión de término general \\[\\frac{n^2 - \\sqrt{n^2 - 5n} + \\log(n^2)}{3n + 1,2^n}\\] En el numerador el infinito de orden superior es \\(n^2\\) y en el denominador es \\(1,2^n\\), luego \\[\\lim_{n \\to \\infty}\\frac{n^2 - \\sqrt{n^2 - 5n} + \\log(n^2)}{3n + 1.2^n} = \\lim_{n \\to \\infty} \\frac{n^2}{1.2^n} = 0\\] "],
["inducción-matemática.html", "Capítulo 4 Inducción matemática 4.1 La inducción nos hace inteligentes 4.2 Induccion matemática 4.3 Aplicación a sucesiones", " Capítulo 4 Inducción matemática 4.1 La inducción nos hace inteligentes Hay dos tipos de razonamiento: el inductivo y el deductivo. El razonamiento inductivo es el que va desde lo particular a lo general: observas algunos casos concretos e induces a partir de ellos una regla general que gobierna todos los casos. El razonamiento deductivo parte de la ley general y a partir de ella deduce el comportamiento esperado en casos concretos. Generalmente usamos el razonamiento deductivo: conocemos las leyes generales (algún teorema matemático o las leyes de Newton en mecánica, por ejemplo) y las aplicamos para los casos concretos que aparecen en nuestra vida diaria. Las leyes generales, las abstracciones, dan potencia a nuestro intelecto y el razonamiento deductivo es muy útil. Pero para tener esas leyes generales hemos de utilizar el razonamiento inductivo y se requiere un genio especial, un salto en la imaginación, que permite pasar de ver cómo se mueven objetos si aplicamos a ellos una fuerza a \\(F = m\\cdot a\\). Sin el razonamiento inductivo no hay conocimiento intelectual. Sólo el hombre puede realizar razonamientos inductivos y por eso sólo el hombre es inteligente (y es por esto mismo que ningún ordenador va a ser nunca “inteligente”, independientemente de lo que pase en las películas de ciencia ficción). Dentro de las matemáticas, y en particular dentro de las matemáticas de los números naturales, hay una técnica particular que nos permite realizar inducciones y es la llamada inducción matemática. Vamos a describir esta técnica y ver algunos ejemplos. 4.2 Induccion matemática Tienes un grupo muy grande, potencialmente infinito, de personas. Y de cuando en cuando quieres que todas se enteren de un secreto. Podrías ir contando el secreto a todas las personas una por una, pero eso es mucho trabajo. Hay otro método mejor: ordenas a las personas de alguna manera (por orden alfabético, por ejemplo) y das orden de que cuando una se entera de un secreto debe contárselo al siguiente de la lista. Si ahora quieres que todas se enteren de un secreto basta que se lo cuentes a la primera de la lista, y el secreto se transmitirá al grupo entero. O tienes muchas fichas de dominó puestas en pie y quieres tirarlas todas. Las puedes tirar una a una, pero eso es mucho trabajo. Si las colocas de manera que cuando una caiga tire la siguiente, entonces basta tirar la primera para que todas caigan. Esta es la idea básica de la inducción matemática. Sea \\(P\\) una propiedad que puede o no poseer un número natural \\(n\\). Decimos que \\(P(1)\\) es cierta si el número 1 posee la propiedad, que \\(P(2)\\) es cierta si el número 2 posee la propiedad y en general que \\(P(n)\\) es cierta si el número \\(n\\) posee la propiedad. Queremos averiguar si todos los infinitos números naturales poseen la propiedad. ¿Cómo lo hacemos? No podemos irlo demostrando número a número porque hay infinitos números y, literalmente, no acabaríamos nunca. Pero podemos utilizar una técnica similar al de contar el secreto o tirar las fichas de dominó. Consta de dos pasos: Demostramos que el primer numero posee la propiedad, es decir, que \\(P(1)\\) es cierta; Demostramos que si un número \\(k\\) posee la propiedad, entonces también la posee el siguiente, es decir, que si \\(P(k)\\) es cierta,entonces \\(P(k+1)\\) también es cierta. Simplemente con estos dos pasos demostramos que \\(P\\) es cierta para todos los números naturales. Veamos un ejemplo. Vamos a demostrar por inducción que la suma de los primeros \\(n\\) números impares, \\(S_i(n)\\), es \\(n^2\\): \\[S_i(n) = 1 + 3 + 5 + \\cdots + (2n-1) = n^2\\] Primer paso: Es cierto para \\(n = 1\\). Este es el paso simple: simplemente hay que comprobarlo. Efectivamente: \\(S(1) = 1 = 1^2\\). Segundo paso: Si es cierto para \\(n = k\\), también lo es para \\(n = k+1\\). Es decir, si \\(S_i(k) = 1 + 3 + 5 + \\cdots + (2k-1) = k^2\\), entonces \\(S_i(k+1) = 1 + 3 + \\cdots + (2k-1)+ (2(k+1)-1) = (k+1)^2\\). Notamos que \\(2(k+1) - 1 = 2k + 1\\). Partimos de la definición de \\(S_i(k+1)\\): \\[S_i(k+1) = 1 + 3 + 5 + \\cdots + (2k -1) + (2k + 1) \\] Estamos suponiendo que \\(S(k) = 1 + 3 + 5 + \\cdots + (2k-1) = k^2\\). Lo introducimos en nuestra expresión y tenemos \\[S_i(k+1) = k^2 + (2k +1) \\] pero por el binomio de Newton \\(k^2 + 2k + 1 = (k+1)^2\\), luego \\[S_i(k+1) = (k+1)^2\\] Con estos dos pasos hemos demostrado por inducción que \\(1 + 3 + 5 + \\cdots + (2n-1) = n^2\\) para todos los números naturales. 4.3 Aplicación a sucesiones Como las sucesiones tienen lugar sobre los enteros, la inducción es especialmente útil para demostrar propiedades como la monotonicidad o la acotación. Puede aplicarse a casos en el que tenemos el término general en función de \\(n\\), pero resulta especialmente útil cuando lo que tenemos es una fórmula de recurrencia. Veamos un ejemplo. Ejemplo 4.1 Sea la sucesión \\(\\{a_n\\}\\) cuyos primeros téminos son: \\[a_1 = \\sqrt{2}, \\quad a_2 = \\sqrt{2 + \\sqrt{2}}, \\quad a_3 = \\sqrt{2 + \\sqrt{2 + \\sqrt{2}}}, \\dots\\] Podemos describir esta sucesión con la fórmula de recurrencia \\(a_{n+1} = \\sqrt{2 + a_n}\\). Vamos a demostrar que es convergente. Para ello usaremos el teorema 3.1 y nos bastará demostrar que es monótona creciente y que está acotada superiormente. Usaremos la inducción matemática en ambas demostraciones. Empecemos por demostrar que es monótona creciente. Queremos demostrar que \\(a_n ≤ a_{n+1}\\) para todo \\(n\\). Primer paso: \\(a_1 ≤ a_2\\). Basta sacar la calculadora: \\(a_1 = 1,414 &lt; 1,848 = a_2\\). Demostrado Segundo paso: Suponemos que \\(a_k ≤ a_{k+1}\\). Será nuestro punto de partida: \\[a_k ≤ a_{k+1}\\] Sumamos 2 a cada lado: \\[2 + a_k ≤ 2 + a_{k+1}\\] Sacamos la raíz cuadrada a ambos lados: \\[\\sqrt{2 + a_k} ≤ \\sqrt{2 + a_{k+1}}\\] Y nos damos cuenta que lo que tenemos a ambos lados es precisamente la fórmula de recurrencia. La aplicamos y tenemos: \\[a_{k+1} ≤ a_{k+2}\\] Y así queda demostrado que la sucesión es monótona creciente. Ahora demostremos que tiene una cota superior. En particular, vamos a demostrar que 2 es una cota superior, es decir que \\(a_n ≤ 2\\) para todo \\(n\\). Primer paso: \\(a_1 = 1.4 &lt; 2\\). Demostrado. Segundo paso: Suponemos que \\(a_k ≤ 2\\) y usamos una técnica muy parecida a la de antes: \\[\\begin{align} a_k &amp;≤ 2\\\\ 2 + a_k &amp;≤ 2 + 2\\\\ \\sqrt{2 + a_k} &amp;≤ \\sqrt{2 + 2} = 2\\\\ a_{k+1} &amp;≤ 2 \\end{align}\\] Y hemos demostrado por inducción que 2 es una cota superior. Como la sucesión es monótona y acotada, entonces es convergente. "],
["series.html", "Capítulo 5 Series 5.1 Definición 5.2 Criterios de convergencia de una serie 5.3 Operaciones con series 5.4 Progresiones geométricas", " Capítulo 5 Series (El ejemplo y las imágenes están sacadas de un video de Matt Parker, del canal de You Tube Standup Maths, de visión recomendable.) Supongamos que tienes un conjunto (infinito) de ladrillos sobre una mesa. Empiezas con uno y quieres ponerlo en el borde, de manera que sobresalga lo más posible, pero sin caerse: Como el centro de gravedad del ladrillo tiene que estar sobre la mesa, y el centro de gravedad está en el centro del ladrillo, esto quiere decir que podemos tener a lo más medio ladrillo sobresaliendo de la mesa. Si ponemos dos ladrillos, el ladrillo superior sobresaldrá 1/2 sobre el inferior, pero el par sobresaldrá menos que eso sobre la mesa. Y si ponemos aún más ladrillos, cada uno sobresaldrá menos que el que tiene encima: Si añadimos más ladrillos el ladrillo superior sobresale cada vez más, pero lo que gana por cada ladrillo adicional es cada vez menos. ¿Hasta dónde podemos conseguir que sobresalga este ladrillo superior? Tenemos un cubo grande y una persona le mete 1 litro de agua, después viene una segunda persona y le añade 1/4 litro, una tercera persona le añade 1/9 de litro, y así: la \\(n\\)-sima persona le añade \\(1/n^2\\) litros. ¿Se acabará desbordando el cubo? En el primer ejemplo tenemos una sucesión \\(s_1, s_2, s_3, …\\) de longitudes de ladrillo que sobresalen sobre el ladrillo inferior. Lo que sobresale el primer ladrillo sobre la mesa es \\(s_1 + s_2 + s_3 + \\cdots\\). En el segundo, tenemos la sucesión \\(\\{a_n = 1/n^2\\}\\) y la cantidad de agua en el cubo es \\(1 + 1/4 + 1/9 +\\cdots + 1/n^2 + \\cdots\\). Las soluciones a estos problemas se obtienen realizando una suma infinita. A esta suma infinita se le llama la serie infinita de la sucesión (o simplemente serie de la sucesión), y es lo que estudiaremos en este capítulo. 5.1 Definición La idea intuitiva de serie es que es la suma de los infinitos términos de una sucesión. Lo que uno se pregunta es ¿pódemos sumar infinitos términos? Y la respuesta es: no. El concepto de serie es una extensión del concepto de suma. Sabemos sumar un número finito de términos, por muchos que haya. Vamos a extender esta idea a la suma de infinitos términos. Usemos un ejemplo como punto de partida. Sea la sucesión \\(\\{a_n = 1/2^n\\}\\), cuyos primeros téminos son 1/2, 1/4, 1/8, 1/16,…. Como sabemos sumar un número finito de términos, vamos a ir calculando lo que llamaremos sumas parciales: la suma de un término, de dos, de tres, etc. Llamaremos \\(S_n\\) a la suma parcial de los \\(n\\) primeros términos. Las sumas parciales de esta sucesión son: \\[\\begin{align} S_1 &amp;= \\frac{1}{2}\\\\ S_2 &amp;= \\frac{1}{2} + \\frac{1}{4} = \\frac{3}{4}\\\\ S_3 &amp;= \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8}= \\frac{7}{8}\\\\ ...\\\\ S_n &amp;= \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots + \\frac{1}{2^n} = \\frac{2^n -1}{2^n}\\\\ \\end{align}\\] Vemos que \\(S_n\\) tiende a 1. Esto nos hace pensar que una forma razonable de extender la idea de suma a una suma infinita en este caso es decir que la suma de los infinitos términos de la sucesión \\(\\{a_n = 1/2^n\\}\\) es 1. Vamos a generalizar y formalizar esta idea. Definición 5.1 Dada una sucesión \\(\\{a_n\\}\\), llamamos sumas parciales \\(S_n\\) a las sumas de los primeros \\(n\\) términos: \\[S_n = \\sum_{i=1}^n a_i.\\] Estas sumas parciales forman la sucesión \\(\\{S_n\\}\\). Definimos como serie infinita de \\(\\{a_n\\}\\) (o simplemente serie de \\(\\{a_n\\}\\)), y lo escribimos como \\(\\sum_{i = 1}^\\infty a_i\\), al límite de la sucesión \\(\\{S_n\\}\\): \\[\\sum_{i = 1}^\\infty a_i = \\lim_{n \\to \\infty} \\{S_n\\}\\] Nota: La palabra serie designa a la suma infinita de los términos de una sucesión. Por lo tanto lo correcto es decir “La serie vale 1.66” o “La serie de la sucesión vale 1.66”. Pero muy a menudo se dice “La suma de la serie vale 1.66” o “La suma de la sucesión es 1,66”. Estrictamente, son incorrecciones, pero no son graves. Hemos supuesto que el primer término de la sucesión es \\(n = 1\\), pero la serie se puede definir de forma análoga si el primer término es el \\(n=0\\). Si el límite existe, decimos que la serie es convergente, si no, decimos que es divergente. Seguiremos siendo un poco incorrectos y si la sucesión \\(\\{S_n\\}\\) crece (o decrece) de forma ilimitada diremos que la serie es \\(\\infty\\) (o \\(-\\infty\\)). Veamos algunos ejemplos. Ejemplo 5.1 Sea la sucesión \\(\\{a_n\\ = n\\}\\). Las sumas parciales son: \\[\\begin{align} S_1 &amp;= 1\\\\ S_2 &amp;= 1+2 = 3\\\\ S_3 &amp;= 1+2+3= 6\\\\ S_3 &amp;= 1+2+3+4 = 10\\\\ ...\\\\ S_n &amp;= 1+2+3 + \\cdots + n = \\frac{1+n}{2}n = \\frac{n^2+n}{2}\\\\ \\end{align}\\] El límite de la sucesión es \\(\\infty\\) y por lo tanto decimos que la serie de esta sucesión es \\(\\infty\\). Ejemplo 5.2 Sea la sucesión \\(\\{a_n\\ = -1^n\\}\\). Los primeros términos de la sucesión son -1, 1, -1, 1,…Las sumas parciales son: \\[\\begin{align} S_1 &amp;= -1\\\\ S_2 &amp;= -1+1 = 0\\\\ S_3 &amp;= -1+1-1= -1\\\\ S_3 &amp;= -1+1-1+1 = 0\\\\ ...\\\\ S_n &amp;= -1+1-1 + \\cdots + -1^n = \\left\\{\\begin{array}{ll} -1 &amp; \\mbox{si } n \\mbox{ es impar}\\\\ 0 &amp; \\mbox{si } n \\mbox{ es par}\\end{array}\\right. \\end{align}\\] Esta sucesión \\(\\{S_n\\}\\) no tiene límite y por lo tanto la serie no tiene valor. O podemos decir que la sucesion \\(\\{a_n\\ = -1^n\\}\\) no tiene suma. 5.2 Criterios de convergencia de una serie En general no es fácil determinar cuánto vale una serie. Pero si sabemos si es convergente o no tenemos mucho ganado: si es divergente ya no nos molestamos y si es convergente, podemos hacernos una idea del valor de la serie sumando unos cuantos miles de términos con la ayuda del ordenador. Luego el primer paso es determinar si la serie es convergente o no y para eso tenemos los criterios de convergencia de las series. Enunciemos, pues, algunso criterios de convergencia. No las vamos a demostrar formalmente, pero daremos algunas indicaciones de la plausibilidad de los resultados. En estas indicaciones vamos a suponer que los términos de la sucesión son todos positivos. Si son negativos, o positivos y negativos, las ideas son las mismas, los resultados son casi los mismos, pero la notación y las explicaciones son mucho más largas. Si las ideas se entienden bien para el caso positivo, no es difícil extenderlo a los otros casos. Teorema 5.1 Sea la sucesión \\(\\{a_n\\}\\). Si \\(\\lim_{n \\to \\infty} \\{a_n\\} ≠ 0\\) o no existe, la serie es divergente. Si el límite no existe, es obvio que el límite de las sumas parciales tampoco puede existir. Y si existe pero no es cero, esto quiere decir que estamos sumando algo infinitas veces, y por lo tanto la sumas parciales explotarán a \\(\\infty\\). Teorema 5.2 Sea la serie \\(\\{a_n\\}\\). Si la serie es convergente, \\(\\lim_{n \\to \\infty} \\{a_n\\} = 0\\). Esta es la afirmación inversa a la del criterio anterior. Cuidado con un error lógico muy habitual. El criterio dice que si la serie es convergente, entonces el límite de la sucesión es 0. Pero no dice que si el límite de la sucesión es 0, entonces la serie converge. El límite de la sucesión puede ser 0 y la serie ser divergente. Veremos un ejemplo. Teorema 5.3 Sean dos sucesiones \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\) y la serie de \\(\\{a_n\\}\\) converge. Si existe un valor \\(N\\) tal que para todo \\(n ≥ N\\), \\(b_n ≤ a_n\\), entonces la serie de \\(\\{b_n\\}\\) también converge. Supongamos para empezar que \\(N = 1\\). Entonces si todos los términos de \\(\\{b_n\\}\\) son menores que todos los términos de \\(\\{a_n\\}\\), entonces las sumas parciales de \\(\\{b_n\\}\\) van a ser todas menores o iguales que las de \\(\\{a_n\\}\\). Y por lo tanto el límite de las sumas parciales de \\(\\{b_n\\}\\) existirá y será menor o igual al límite de las de \\(\\{a_n\\}\\). Ahora supongamos que \\(N&gt;1\\). Llamemos \\(Sb\\), si existe, a la serie de \\(\\{b_n\\}\\) y llamemos \\(Sb_N\\) a las suma parcial de los \\(N\\) primeros términos de la sucesión. Como \\(Sb_N\\) se obtiene de sumas normales, es seguro que existe y es finito. Llamemos \\(\\{a&#39;_n\\}\\) y \\(\\{b&#39;_n\\}\\) a las sucesiones que se obtienen sustituyendo en \\(\\{a_n\\}\\) y\\(\\{b_n\\}\\) respectivamente los N primeros términos por 0. Entonces \\(b&#39;_n ≤ a&#39;_n\\) para todo N y esto quiere decir que la serie de \\(\\{b&#39;_n\\}\\) es convergente. Llamemos \\(Sb&#39;\\) a esta serie. Es fácil ver que \\(Sb = Sb&#39; + Sb_N\\). Luego \\(Sb\\) existe y es finito y la serie de \\(\\{b_n\\}\\) es convergente. Teorema 5.4 Sean dos sucesiones \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\) y la serie de \\(\\{a_n\\}\\) diverge hacia \\(\\infty\\). Si existe un valor \\(N\\) tal que para todo \\(n ≥ N\\) \\(b_n ≥ a_n\\), entonces \\(\\{b_n\\}\\) también diverge hacia \\(\\infty\\). El razonamiento es muy parecido al anterior. Usemos estos criterios en algunos ejemplos. Ejemplo 5.3 Estudie la convergencia de la serie \\[\\sum_{n=1}^\\infty \\frac{n+5}{2n}.\\] Empezamos por calcular el límite se la sucesión: \\[\\lim_{n \\to \\infty} \\frac{n+5}{2n}= \\frac{1}{2}\\] La serie es divergente. Ejemplo 5.4 Estudie la convergencia de la serie \\(\\sum_{n=1}^\\infty\\{\\frac{1}{n}\\}\\). Empezamos por calcular el límite se la sucesión: \\[\\lim_{n \\to \\infty} \\frac{1}{n}= 0\\] La serie puede ser convergente o no. Hemos de seguir. Los primeros términos de la serie son \\[1 + \\frac{1}{2} + \\frac{1}{3}+ \\frac{1}{4}+ \\frac{1}{5}+ \\frac{1}{6} + \\frac{1}{7} + \\frac{1}{8}+\\cdots\\] Vamos a crear otra sucesión cuyos terminos son todos menores o iguales a las de esta: \\[1 + \\frac{1}{2} + \\frac{1}{4}+ \\frac{1}{4}+ \\frac{1}{8}+ \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8}+\\cdots\\] Hemos cogido dos términos y los hemos cambiado por \\(1/4\\), los 4 siguientes por \\(1/8\\), y cogeríamos los 8 siguientes y los sustituiríamos por \\(1/16\\), los 16 siguientes por \\(1/32\\) y así sucesivamente. Pero los dos téminos \\(1/4\\) suman \\(1/2\\); los 4 términos \\(1/8\\) suman \\(1/2\\), los 8 téminos \\(1/16\\) suman \\(1/2\\) y así sucesivamente. Luego la suma de esta serie es \\[1 + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\cdots = \\infty\\] Todos los términos de la sucesión \\(\\{\\frac{1}{n}\\}\\) son mayores o iguales a los términos de una sucesión divergente. Luego la serie de \\(\\{\\frac{1}{n}\\}\\) es divergente. Esta serie se conoce como la serie armónica. Muchos matemáticos han demostrado de forma independiente que esta serie es divergente. Ejemplo 5.5 Estudie la convergencia de la serie de \\(\\{\\frac{1}{n^2}\\}\\). El límite de la sucesión es 0, luego la serie puede ser convergente. Los primeros téminos son: \\[\\frac{1}{2^2} + \\frac{1}{3^2}+ \\frac{1}{4^2}+ \\frac{1}{5^2}+ \\frac{1}{6^2} + \\frac{1}{7^2} + \\frac{1}{8^2}+ \\frac{1}{9^2}+\\cdots\\] Vamos a hacer una sustitución como en el ejemplo anterior. Sustituimos los dos primeros términos por \\(\\frac{1}{2^2}\\), los cuatro siguientes por \\(\\frac{1}{4^2}\\), los 8 siguientes por \\(\\frac{1}{8^2}\\), etc. Esta segunda sucesión tiene todos sus términos mayores o iguales a los de \\(\\{\\frac{1}{n^2}\\}\\). Esta segunda sucesión la podemos sumar. La suma de los dos primeros términos es \\[2 \\frac{1}{2^2} = \\frac{1}{2}\\] La suma de los 4 siguientes términos es: \\[4 \\frac{1}{4^2} = \\frac{1}{4}\\] La suma de los 8 siguientes términos es: \\[8 \\frac{1}{8^2} = \\frac{1}{8}\\] La suma de esta segunda serie es una que ya hemos visto antes \\[\\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} +\\cdots + \\frac{1}{2^n}+\\cdots = 1 \\] Luego la serie \\(\\sum_{k=1}^\\infty \\frac{1}{n^2}\\) tiene todos sus términos menores o iguales a la de una serie que suma 1. Por lo tanto \\[\\sum_{k=1}^\\infty \\frac{1}{n^2}≤ 1\\] El valor de la suma de esta serie se conoce. La calculó Leonhard Euler . Bueno, para ser precisos, Euler empezó en \\(k=0\\): \\(1 + \\frac{1}{4} + \\frac{1}{9} + \\cdots\\). La suma de la serie que calculó Euler es \\(\\frac{\\pi^2}{6}\\), luego la de la serie del ejemplo es \\(\\frac{\\pi^2}{6} - 1 = 0.64493\\). Es sorprendente que aparezca \\(\\pi\\), que es un número que tiene que ver con circulos, en una serie donde lo que tenemos son cuadrados. Es uno de los resultados a los que Euler tenía más estima, lo cual es decir mucho, pues Euler es el matemático más prolífico de la historia y tiene cientos de resultados memorables (por ejemplo, el número \\(e\\) se llama \\(e\\) por Euler). 5.3 Operaciones con series Ya vimos que se pueden operar sucesiones: podemos tener la suma de dos sucesiones, la resta, o multiplicarla por una constante. Nos interesa saber el valor de la serie que es el resultado de una operación de sucesiones. Por suerte, es lo que intuitivamente supondríamos. Sean dos sucesiones \\(\\{a_n\\}\\) y \\(\\{b_n\\}\\), con series \\(Sa\\) y \\(Sb\\). Si ambas convergen entonces la serie de la sucesión \\(\\{a_n + b_n\\}\\) es convergente y vale \\(Sa + Sb\\) y la de la sucesión \\(\\{a_n - b_n\\}\\) también es convergente y vale \\(Sa- Sb\\). Sea una sucesión \\(\\{a_n\\}\\) convergente y con serie \\(Sa\\). Sea la serie \\(\\{b_n = k\\cdot a_n\\}\\), es decir, la sucesión que se consigue multiplicando cada término por una constante. La serie de \\(\\{b_n\\}\\) es convergente y \\(Sb = k\\cdot Sa\\). Sea una sucesión \\(\\{a_n\\}\\) convergente y con serie \\(Sa\\). Creamos una sucesión \\(\\{b_n\\}\\) añadiendo un número finito de términos al inicio de \\(\\{a_n\\}\\). Sea \\(St\\) la suma de estos términos. La serie de \\(\\{b_n\\}\\) es convergente y vale \\(Sb = Sa + St\\). Sea una sucesión \\(\\{a_n\\}\\) convergente y con serie \\(Sa\\). Creamos una sucesión \\(\\{b_n\\}\\) eliminando un número finito de términos del inicio de \\(\\{a_n\\}\\). Sea \\(St\\) la suma de estos términos. La serie de \\(\\{b_n\\}\\) es convergente y vale \\(Sb = Sa - St\\). Nótese que en estos dos últimos resultados sumamos un número finito de términos y lo hacemos al inicio de las series. Sumar por en medio, o sumar un número infinito de términos puede dar lugar a sorpresas. Hay que ir con cuidado. 5.4 Progresiones geométricas Como hemos dicho, en general no es fácil calcular la suma de una serie y nos hemos de conformar con establecer su convergencia. Pero hay una familia de series que son importantes y que sí sabemos calcular su valor. Son las series de las progresiones geométricas, que ya vimos en el apartado 3.3, en las que cada término se obtiene de la anterior multiplicándola por una constante. Llamamos serie geométrica a: \\[\\sum_{n=1}^\\infty ar^{n-1}.\\] Los primeros términos de esta serie son \\[a + ar + ar^2 + ar^3\\] Por ejemplo, para \\(a = \\frac{1}{2}\\) y \\(r = \\frac{1}{2}\\) los primeros términos son \\[\\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\frac{1}{16} +\\cdots\\] Y esta es nuestra conocida serie que ya hemos estudiado y sabemos que vale 1. Nota: El \\(n-1\\) del exponente es debido a que empezamos en \\(n=1\\), otra manera equivalente de escribir esta serie es: \\[\\sum_{n=0}^\\infty ar^{n}.\\] La expresión que se use depende del gusto de cada uno. Vamos a estudiar la convergencia de esta serie. Empecemos por límite de la sucesión: \\[\\lim_{n \\to \\infty} ar^{n-1} \\] Este límite es 0 sólo si \\(|r| &lt; 1\\). Luego la serie diverge si \\(|r|≥1\\). Se puede demostrar que si \\(|r| &lt; 1\\) la serie siempre converge y su valor es \\[\\sum_{n=1}^\\infty ar^{n-1} = \\frac{a}{1-r}\\] Nota: Hemos dicho que hay dos maneras equivalentes de escribir la serie. Naturalmente ambas tienen el mismo valor: \\[\\sum_{n=1}^\\infty ar^{n-1} = \\sum_{n=0}^\\infty ar^{n} = \\frac{a}{1-r}.\\] Hay que tener cuidado de ajustar el valor inicial y el exponente. Si no, se puede incurrir en error, pues \\[\\sum_{n=1}^\\infty ar^{n} ≠ \\frac{a}{1-r}.\\] Pueden deducir con facilidad lo que vale esta serie. Ejemplo 5.6 Sea la sucesión \\(\\{\\frac{0.9}{10^{n-1}}\\}\\). Estudie la convergencia de la serie y, si es convergente, halle su valor. Los primeros términos de la sucesión son \\(0.9, 0.09, 0.009,…\\) Ya vemos que la serie va a ser \\(0.999\\dots\\), pero vamos a formalizarlo como una serie geométrica. Hemos de ponerla en la forma \\(ar^{n-1}\\). No es difícil: \\[\\sum_{n=1}^\\infty 0.9 \\left(\\frac{1}{10}\\right)^{n-1}\\] Esta es una serie geométrica con \\(a = 0.9\\) y \\(r = 0.1\\). Como \\(r&lt;1\\) es convergente y la serie es \\[\\frac{a}{1-r} = \\frac{0.9}{1-0.1} = \\frac{0.9}{0.9} = 1\\] Esta es otra demostración (hay muchas) de que \\(0.9999… = 1\\). Ejemplo 5.7 Sea la sucesión \\[-1, \\frac{1}{2}, -\\frac{1}{4}, \\frac{1}{8}, -\\frac{1}{16}, …, \\frac{-1^{n}}{2^{n-1}},…\\] Estudie la convergencia de la serie y, si es convergente, halle su valor. Hemos de ponerla en forma de serie geométrica. No es difícil, pero hay que tener cuidado con los signos. Quizá sea más sencillo empezar con \\(n = 0\\): \\[\\sum_{n = 0}^\\infty -1 \\left(\\frac{-1}{2}\\right)^n\\] (si no lo ven claro, calculen despacio los primeros términos) Esta es una serie geométrica con \\(a = -1\\) y \\(r = -(1/2)\\), luego la serie vale: \\[\\frac{a}{1-r} = \\frac{-1}{1- \\frac{-1}{2}} = \\frac{-1}{\\frac{3}{2}} = -\\frac{2}{3}\\] Hay veces que el término general no parece el de una serie geométrica, pero sí lo es. Ejemplo 5.8 Estudie la convergencia de la serie \\[\\sum_{n = 1}^{\\infty} 2^{2n}3^{1-n}\\] Como ambos términos tienen un \\(n\\) en el exponente nos sopechamos que lo podemos escribir como una serie geométrica. Como el exponente del segundo factor tiene un \\(-n\\) lo pasamos al denominador cambiándole de signo: \\[\\sum_{n = 1}^{\\infty} \\frac{2^{2n}}{3^{n-1}}\\] Ahora cambiamos el \\(2^{2n}\\) por \\((2^2)^n = 4^n\\): \\[\\sum_{n = 1}^{\\infty} \\frac{4^n}{3^{n-1}}\\] Y ahora necesitamos que ambos exponentes sean \\(n-1\\): \\[\\sum_{n = 1}^{\\infty} \\frac{4 \\cdot 4^{n-1}}{3^{n-1}}\\] Y ya está: \\[\\sum_{n = 1}^{\\infty} 4 \\cdot\\left(\\frac{4}{3}\\right)^{n-1}\\] Tenemos una serie geométrica con \\(a = 4\\) y \\(r = 4/3\\). Como \\(r&gt;1\\) esta serie es divergente. "],
["aplim.html", "Capítulo 6 Funciones: definición y límites 6.1 Definición de función 6.2 Operaciones con funciones 6.3 Límites de funciones 6.4 Cálculo de límites 6.5 Límites laterales", " Capítulo 6 Funciones: definición y límites El concepto de función es central a las matemáticas como las entendemos hoy, y en particular al cálculo. Sin el concepto de función no existen el de derivada ni el de integral. Aunque lo que nos interesa al final es saber derivar e integrar, para llegar hasta allí debemos pasar por los conceptos de límite y de continuidad. El concepto de límite no es diferente al del límite de sucesiones, aunque aplicado a otro contexto y con características nuevas. El de continuidad es muy intuitivo, y permite establecer teoremas potentes y necesarios. 6.1 Definición de función Informalmente, podemos definir función como una regla que asigna a cada uno de ciertos números reales un número real. Veamos algunos ejemplos Se asigna al número 2 el número 3 y al número 3 el número 2. Se asigna a todo número par el número \\(\\pi\\) y a todo número impar el número \\(e\\) Se asigna a todo número real \\(x\\) el número \\(3x^2 + 2\\) Se asigna a cada peso \\(P\\) de un producto su precio \\(C = 1,95 P\\) Se asigna a cada número \\(y\\) su valor absoluto, es decir \\[ \\left\\{\\begin{array}{rl} y &amp; \\mbox{si } y ≥ 0\\\\ -y &amp; \\mbox{si } y &lt; 0 \\end{array}\\right.\\] Se asigna a cada número real \\(t\\) el número \\(\\frac{t}{t-1}\\) Vemos que estas reglas pueden ser específicas para cada número o generales a un conjunto de números o a todos los números. Al conjunto de números para los que está definida la regla se llama el dominio de la función. A menudo los dominios no se especifican, sino que son implícitos. En nuestros ejemplos, los dominios son los números 2 y 3 los números enteros exceptuando el 0 (el 0 no es par ni impar) todos los números reales todos los números reales positivos (no hay pesos negativos) todos los números reales todos los números reales menos el 1. Hemos visto también que podemos dividir cada regla en subreglas: las reglas (1), (2) y (5) están divididas en dos subreglas. En este caso decimos que la función está definida a trozos. Un ejemplo un poco más complejo de función definida a trozos es: Se asigna a todo número \\(x\\) \\[\\left\\{\\begin{array}{cl} 0 &amp; \\mbox{ si } y &lt; 0\\\\ y &amp; \\mbox{ si } 0 ≤ y &lt; 2\\\\ -\\frac{y}{2} + 3 &amp; \\mbox{ si } 2 ≤ y &lt; 6\\\\ 0 &amp; \\mbox{ si } y ≥ 6 \\end{array}\\right.\\] Su gráfica es: Hay dos cosas importantes a notar en esta definición. La primera es que la regla asigna el valor 0 a los valores de \\(y\\) que son menores que 0 o mayores que 6. Esto no es lo mismo que asignar valores sólo entre 0 y 6. En nuestra función el dominio va desde \\(-\\infty\\) a \\(infty\\) y todos los números reales tiene asignado un valor. Por ejemplo, el valor asignado a \\(-1\\) es 0. En el segundo caso el dominio sería de 0 a 6 y no se asignaría nungún valor a \\(y = -1\\). La segunda es que hemos ido con mucho cuidado en no asignar dos valores a ningún valor del dominio: hemos asignado 0 a los valores \\(y &lt; 0\\) e \\(y\\) a los valores \\(y ≥ 0\\). Porque una de las características fundamentales de un función es que sólo se asigna un único valor a cada valor del dominio. Por ejemplo, una descripción de una curva que no es una función es la del círculo: \\(x^2 + y^2 = r^2\\), donde \\(r\\) es el radio. Hay dos valores de \\(y\\) posibles para cada valor de \\(x\\). Por ejemplo, para \\(x = 0\\), \\(y\\) puede valer \\(r\\) y \\(-r\\). Ahora que tenemos una idea intuitiva de qué es una función, vamos a dar una definición formal de función y de dominio. Definición 6.1 Una función es una colección de pares de números reales con la siguiente propiedad: Si \\((a, b)\\) y \\((a, c)\\) pertenecen a la colección entonces \\(b = c\\); es decir, la colección no debe contener dos pares distintos con el mismo primer elemento. Definición 6.2 Si \\(f\\) es una función, el dominio de \\(f\\) es el conjunto de todos los \\(a\\) para los que existe algún \\(b\\) tal que \\((a, b)\\) está en \\(f\\). Este \\(b\\) debe ser único y se designa por \\(f(a)\\). De estas definiciones extraemos la notación habitual. Dado un elemento \\(x\\) del dominio, el valor asignado a este \\(x\\), normalmente llamado el valor de \\(f\\) en \\(x\\) se designa por \\(f(x)\\). 6.2 Operaciones con funciones Los valores de \\(f\\) son números, y por lo tanto pueden ser operados. Esto nos permite definir de forma natural operaciones aritméticas entre funciones siguiendo los conceptos de operaciones entre números. Definición 6.3 Sean \\(f(x)\\) y \\(g(x)\\) dos funciones. Definimos las siguientes operaciones entre funciones: \\((f + g)(x) = f(x) + g(x)\\) \\((f - g)(x) = f(x) - g(x)\\) \\((f \\cdot g)(x) = f(x) \\cdot g(x)\\) \\(\\frac{f}{g}(x) = \\frac{f(x)}{g(x)}\\) Los dominios de estas nuevas funciones están compuestos por los valores de \\(x\\) en donde tiene sentido la expresión aritmética “\\(f(x)\\) operado con \\(g(x)\\)”. Es decir, son los valores \\(x\\) tales que \\(f(x)\\) y \\(g(x)\\), ambos, existen. En el caso de la división hay una restricción más: no sólo deben existir \\(f(x)\\) y \\(g(x)\\), sino que también debe cumplirse que \\(g(x) ≠ 0\\). Estamos muy acostumbrados a ver expresiones del estilo \\(\\cos(x^2)\\). La asignación que describe esta expresión es la siguiente: a cada valor \\(x\\) primero se le asigna el valor \\(x^2\\); y a este valor se le asigna el valor \\(\\cos(x)\\). Si llamamos \\(f(x)\\) a la función \\(x^2\\) y \\(g(x)\\) a la función \\(\\cos(x)\\), lo que hemos calculado es \\(g(f(x))\\). A esto se llama la composición de \\(f\\) con \\(g\\) y se simboliza con \\((g \\circ f)\\): \\[(g \\circ f)(x) = g(f(x))\\] Una de las particularidades de esta operación es que se lee de “dentro a afuera”: \\((g \\circ f)(x)\\) es “\\(f\\) compuesto con \\(g\\)” y no al revés, como con las otras operaciones. Para complicar las cosas un poco más, esta operación no es conmutativa: \\((g \\circ f)(x) ≠ (f \\circ g)(x)\\). No es lo mismo \\(\\cos(x^2)\\) que \\(\\cos^2(x)\\). Hemos de ir con mucho cuidado al escribir y leer composiciones. 6.3 Límites de funciones La idea básica de límite de una función no es diferente de la de límite de una sucesión que vimos en el apartado 3.6. Para sucesiones, el límite es el valor al que se acerca la sucesión cuando \\(n \\to \\infty\\), para funciones es el valor al que se acerca la función cuando \\(x \\to a\\). La diferencia es que en una sucesión sólo tiene sentido hablar de límite en el “extremo” de la sucesión, mientras que para una función tiene sentido hablar de límite en cualquier punto del dominio. Esto da lugar a algunos cambios en la definición y a problemas nuevos. Recordemos la definición formal de límite de una sucesión 3.1: Sea una sucesión \\(\\{a_n\\}\\). Decimos que esta sucesión tiene límite \\(L\\) cuando \\(n\\) tiende a infinito, y lo escribimos como \\[\\lim_{n \\to \\infty} a_n = L\\] si para cualquier número positivo \\(\\varepsilon\\), podemos encontrar un entero positivo \\(N\\), dependiente de \\(\\varepsilon\\), tal que \\(|a_n – L| &lt; \\varepsilon\\) para todos los enteros \\(n &gt; N\\). Veamos los cambios que tenemos que hacer: En vez de la sucesión \\(\\{a_n\\}\\) tenemos la función \\(f(x)\\) En vez de tender \\(n\\) a infinito, \\(n \\to \\infty\\), tenemos \\(x\\) que tiende a una valor que llamaremos \\(a\\): \\(x \\to a\\) Estos dos cambios dan lugar a que escribamos el límite como \\[\\lim_{x \\to a} f(x) = L\\] Veamos qué mas cambios hay que hacer. En vez de \\(|a_n – L| &lt; \\varepsilon\\) hemos de escribir \\(|f(x) - L| &lt; \\varepsilon\\) En vez de “podemos encontrar un positivo \\(N\\)” hemos de escribir … ¿? Este es el único punto donde el cambio no es obvio. Pero la solución la tenemos en la definición misma. ¿Cómo lo hacíamos para expresar que los términos de la sucesión se acercan a \\(L\\) tanto como queremos? Introducimos un valor que llamamos \\(\\varepsilon\\) y exigimos que \\(|a_n – L| &lt; \\varepsilon\\). Pues ahora hacemos lo mismo: introducimos un nuevo valor que llamaremos \\(\\delta\\), positivo, y exigiremos que \\(0 &lt; |x - a| &lt; \\delta\\). El “\\(&gt; 0\\)” es necesario, para impedir la “trampa” \\(\\delta = 0\\). Y con esto podemos escribir la definición formal de límite de una función: Definición 6.4 Sea una función \\(f(x)\\). Decimos que esta función tiene límite \\(L\\) cuando \\(x\\) tiende a \\(a\\), y lo escribimos como \\[\\lim_{x \\to a} f(x) = L\\] si para cualquier número positivo \\(\\varepsilon &gt; 0\\), podemos encontrar un valor \\(\\delta\\) &gt; 0, tal que para todo \\(x\\), si \\(0 &lt; |x - a| &lt; \\delta\\) entonces \\(|f(x) – L| &lt; \\varepsilon\\). Y ahora cito un libro clásico, el Cálculus de Spivak: Esta definición es tan importante (todo lo que emprendamos a partir de ahora va a depender de ella) que sería vano pasar adelante sin saberla. ¡Apréndala el lector de memoria si es necesario, como si fuera un poema! Veamos dos ejemplos de aplicación de esta definición. Primero uno muy sencillo: Ejemplo 6.1 Sea \\(f(x) = x\\). Demuestra que \\(\\lim_{x \\to 2} f(x) = 2\\). Tenemos que \\(a = 2\\), \\(f(x) = x\\) y \\(L = 2\\). Si reescribimos la definición para este caso concreto tenemos que demostrar que para cualquier número positivo \\(\\varepsilon &gt; 0\\), podemos encontrar un valor \\(\\delta\\) &gt; 0, tal que para todo \\(x\\), si \\(0 &lt; |x - 2| &lt; \\delta\\) entonces \\(|x - 2| &lt; \\varepsilon\\). Evidentemente esto se cumple si \\(\\delta = \\varepsilon\\). Ahora vayamos a un caso más complicado. Ejemplo 6.2 Sea \\(f(x) = x^2\\). Demuestra que \\(\\lim_{x \\to 3} f(x) = 9\\). Lo que tenemos que hacer ahora es dado el \\(\\varepsilon\\) encontrar un \\(\\delta\\) tal que si \\(0 &lt; |x - 3| &lt; \\delta\\) entonces \\(|x^2 - 9| &lt; \\varepsilon\\). Como es más complicado, cojamos un valor concreto de \\(\\varepsilon\\), por ejemplo \\(\\varepsilon = 0.1\\). Entonces queremos que \\[|x^2 - 9| &lt; 0.1\\] Vamos a empezar por suponer que \\(x &gt; 3\\), entonces \\[|x^2 - 9| = x^2 - 9 &lt; 0.1\\] y obtenemos que \\(x^2 &lt; 9.1\\), es decir que \\(x &lt; \\sqrt{9.1}\\). Hacemos lo mismo si \\(x &lt; 3\\). Ahora \\[|x^2 - 9| = 9 - x^2 &lt; 0.1\\] y tenemos que \\(x &gt; \\sqrt{8.9}\\). Luego si \\(\\sqrt{8.9} &lt; x &lt; \\sqrt{9.1}\\), aseguramos que \\(|x^2 - 9| &lt; 0.1\\). Hemos de escoger un \\(\\delta\\) que nos asegure que \\(\\sqrt{8.9} &lt; x &lt; \\sqrt{9.1}\\). Por ejemplo, \\(\\delta = 0.015\\) nos va bien. Esto que hemos hecho para un \\(\\varepsilon\\) concreto, lo podemos generalizar fácilmente. Para que \\(|x^2 - 9| &lt; 0.1\\) tiene que pasar que \\[\\sqrt{9 - \\varepsilon} &lt; x &lt; \\sqrt{9 + \\varepsilon}\\] Restamos 3 a todo y tenemos que: \\[\\sqrt{9 - \\varepsilon} - 3 &lt; x -3 &lt; \\sqrt{9 + \\varepsilon}- 3\\] Y a poco que lo piensas ves que el valor de \\(\\delta\\) debe ser menor que el más cercano a 3 de los dos valores: \\[ \\delta ≤ \\min(|\\sqrt{9 - \\varepsilon} - 3| , |\\sqrt{9 + \\varepsilon}- 3)|\\] Luego para cualquier \\(\\varepsilon\\) podemos encontrar un \\(\\delta\\) tal que si \\(0 &lt; |x - 3| &lt; \\delta\\) entonces \\(|x^2 – 9| &lt; \\varepsilon\\). Queda demostrado. 6.3.1 Límites cuando \\(x \\to \\infty\\) Hemos supuesto hasta ahora que \\(x\\) tiende a un valor finito \\(a\\). Pero también podemos tener un límite cuando \\(x \\to \\infty\\). Esto es mucho más parecido al caso de las sucesiones: ya no necesitamos el parámetro \\(\\delta\\), sino un valor \\(X\\) tal que si \\(x &gt; X\\), \\(|f(x) - L| &lt; \\varepsilon\\). No diremos más. 6.3.2 Existencia de límites Al igual que en el caso de sucesiones, el límite puede no existir. Hay tres motivos por los cuales puede no haber límite, de los que dos ya los vimos en el caso de límites de sucesiones. El primero es que la función crezca de forma ilimitada. En ese caso normalmente decimos, algo incorrectamente, que el límite es \\(\\infty\\) o \\(-\\infty\\). El segundo es que la función oscile y no se acerque a ningun valor concreto. Es fácil imaginar casos cuando \\(x \\to \\infty\\), pero también puede pasar cuando \\(x\\) tiende a un valor finito. El ejemplo típico es la función \\(\\sin(1/x)\\) cuando \\(x \\to 0\\). A medida que la función se acerca a 0 oscila cada vez más alocadamente: Como dije, hay un tercer caso, que no aparecía en los límites de sucesiones, pero que explicaremos más adelante. 6.3.3 Operaciones con límites Vimos en el apartado 3.7 que si teníamos sucesiones que se podían obterner de operaciones de otras sucesiones, los límites se obtenían operando los límites. Lo mismo pasa con los límites de funciones. Es fácil demostrar que dadas dos funciones \\(f(x)\\) y \\(g(x)\\), y siendo \\[\\lim_{x \\to a} f(x) = A \\quad \\mbox{ y } \\quad \\lim_{x \\to a} g(x) = B\\] entonces: \\[\\begin{align} \\lim_{x \\to a} (f + g)(x) &amp;= \\lim_{x \\to a} f(x) + \\lim_{x \\to a} g(x) = A + B\\\\ \\lim_{x \\to a} (f - g)(x) &amp;= \\lim_{x \\to a} f(x) - \\lim_{x \\to a} g(x) = A - B\\\\ \\lim_{x \\to a} (f \\cdot g)(x) &amp;= \\lim_{x \\to a} f(x) \\cdot \\lim_{x \\to a} g(x) = A \\cdot B\\\\ \\lim_{x \\to a} \\frac{f}{g}(x) &amp;= \\frac{\\lim_{x \\to a} f(x)}{\\lim_{x \\to a} g(x)} = \\frac{A}{B}\\\\ \\lim_{x \\to a} (f^g)(x) &amp;= \\lim_{x \\to a} f(x) ^{\\lim_{x \\to a} g(x)} = A^B \\end{align}\\] Al igual que pasaba en el caso de las sucesiones, en el caso de la división y potenciación podíamos no tener límites si el límite resulta ser infinito, y también podemos tener una indeterminación. 6.4 Cálculo de límites En la inmensa mayoría de los casos el cálculo del límite de un función es trivial, tan trivial que ni lo consideramos el cálculo de un límite. Por ejemplo, \\(\\lim_{x \\to 2} x + 2 = 4\\) \\(\\lim_{x \\to 0} \\frac{x^2 + 5}{2x -1} = -5\\) \\(\\lim_{x \\to \\pi/2} \\cos (x) = 1\\) \\(\\lim_{x \\to 1} \\frac{x}{(x-1)^2} = \\infty\\) Los únicos casos en donde es necesario esforzarse, en los únicos casos en los que le dedicamos tiempo y atención, es cuando tenemos una indeterminación. Ya vimos las indeterminaciones en el apartado 3.9. Recordamos que hay 7: \\[\\infty - \\infty \\qquad \\frac{\\infty}{\\infty} \\qquad 1^\\infty \\qquad 0\\cdot \\infty \\qquad \\infty^0 \\qquad \\frac{0}{0} \\qquad 0^0\\] Todo lo que se vio de cálculo de límites entonces, es aplicable ahora, en particular la jerarquía de infinitos que se explicaron en el apartado 3.10.2. Veamos cómo se aplica al caso de funciones con agunos ejemplos. Ejemplo 6.3 ¿Cuál es el límite de \\(\\frac{x^3 + 3}{e^{x/1000}}\\) cuando \\(x\\) tiende a infinito? Tenemos aquí una indeterminación del tipo \\(\\frac{\\infty}{\\infty}\\). La exponencial es un infinito de orden superior, luego \\[\\lim_{x \\to \\infty} \\frac{x^3 + 3}{e^{x/1000}} = \\lim_{x \\to \\infty} \\frac{1}{e^{x/1000}} = 0\\] Ejemplo 6.4 ¿Cuál es el límite de \\(f(x) = \\frac{1}{x} - \\frac{1}{x^2}\\) cuando \\(x\\) tiende a 0? Tenemos aquí una indeterminación del tipo \\(\\infty - \\infty\\). El término \\(\\frac{1}{x^2}\\) es un infinito de orden superior, luego \\[\\lim_{x \\to 0} \\frac{1}{x} - \\frac{1}{x^2} = \\lim_{x \\to 0} - \\frac{1}{x^2} = -\\infty\\] En el caso de la indeterminación del tipo \\(1^\\infty\\) vimos que dada cualquier sucesión \\(\\{a_n\\}\\) tal que \\(\\lim_{n \\to \\infty} a_n = \\pm\\infty\\), la sucesión \\(\\{c_n = (1 + \\frac{1}{a_n})^{a_n}\\}\\) tiene por límite el número \\(e\\). Esto lo podemos generalizar al caso de funciones. Dada una función \\(f(x)\\) tal que \\(\\lim_{x \\to a} f(x) = \\pm\\infty\\), entonces \\[\\lim_{x \\to a} \\left(1 + \\frac{1}{f(x)}\\right)^{f(x)} = e\\] Usemos este resultado. Ejemplo 6.5 ¿Cuál es el límite cuando de \\((1 + 2x)^{(1/x)}\\) cuando \\(x\\) tiende a 0? Esta expresión la podemos escribir como \\[\\left(1 + \\frac{1}{1/2x}\\right)^{1/x}\\] Y esta expresión es fácil transformarla a la forma que queremos: \\[\\left(1 + \\frac{1}{1/2x}\\right)^{(1/2x) \\cdot 2}\\] Aplicamos el límite: \\[\\lim_{x \\to 0}\\left(\\left(1 + \\frac{1}{1/2x}\\right)^{1/2x}\\right)^2 = \\left(\\lim_{x \\to 0}\\left(1 + \\frac{1}{1/2x}\\right)^{1/2x}\\right)^2 = e^2\\] Veamos ahora cómo resolver otros tipos de indeterminaciones 6.4.1 Indeterminación \\(\\frac{0}{0}\\) Si tenemos un indeterminación de tipo \\(\\frac{0}{0}\\) y \\(f(x)\\) y \\(g(x)\\) son ambos polinomios, podemos descomponer los polinomios en factores y simplificar. Ejemplo 6.6 Calcula \\[\\lim_{x\\to 0}\\frac{x^3 - 8}{x-2}\\] Descomponemos \\(x^3 - 8\\). Sabemos que \\(x=2\\) es una raíz (si no, no tendríamos la indeterminación), luego \\[x^3 - 8 = (x-2)(ax^2 + bx + c)\\] Desarrollamos el lado izquierdo e igualamos los componentes de cada potencia y tenemos que \\(a = 1\\), \\(b = 2\\) y \\(c = 4\\). Luego nos queda \\[\\lim_{x\\to 0}\\frac{x^3 - 8}{x-2} = \\lim_{x\\to 0}\\frac{(x-2)(x^2 + 2x + 4)}{x-2} = \\lim_{x\\to 0} x^2 + 2x + 4 = 0\\] Si no son polinomios, podemos usar la regla de L’Hôpital. 6.4.2 Regla de l’Hôpital La regla de L’Hôpital recibe su nombre de Guillaume Françoise Antoine, Marqués de L’Hôpital. La regla la descubrió y demostró Johann Bernoulli, pero el marqués le pagó para que le pusiera su nombre. Poderoso caballero es Don Dinero… Esta regla es muy útil para resolver indeterminaciones del tipo \\(\\frac{0}{0}\\). Teorema 6.1 Sean las funciones \\(f(x)\\) y \\(g(x)\\) y sean sus derivadas \\(f^{\\prime}(x)\\) y \\(g^{\\prime}(x)\\). Supongamos que \\[\\lim_{x \\to a} f(x) = 0 \\quad \\mbox{y} \\quad \\lim_{x \\to a} g(x) = 0\\] y supongamos también que existe \\(\\lim_{x \\to a} f^{\\prime}(x)/g^{\\prime}(x)\\). Entonces, existe \\(\\lim_{x \\to a} f(x)/g(x)\\) y \\[\\lim_{x \\to a} \\frac{f(x)}{g(x)} = \\lim_{x \\to a} \\frac{f^{\\prime}(x)}{g^{\\prime}(x)}\\] Veamos cómo esta regla nos resuelve el límite calculado anteriormente, sin necesidad de descomponer el polinomio. Ejemplo 6.7 Calcula \\[\\lim_{x\\to 0}\\frac{x^3 - 8}{x-2}\\] Aplicamos la regla de L’Hôpital, derivando numerador y denominador: \\[\\lim_{x\\to 0}\\frac{x^3 - 8}{x-2} = \\lim_{x\\to 0} \\frac{3x^2}{1} = 0\\] Y también nos sirve si no tenemos polinomios: Ejemplo 6.8 Calcula \\[\\lim_{x \\to 1} \\frac{\\sin \\pi x}{x^2 - 1}\\] Es una indeterminación del tipo \\(\\frac{0}{0}\\). Aplicamos la regla de L’Hôpital: \\[\\lim_{x \\to 1} \\frac{\\pi \\cos \\pi x}{2x} = \\frac{\\pi\\cdot (-1)}{2} = -\\frac{\\pi}{2} \\] 6.4.3 Otras indeterminaciones Un camino, si no podemos calcular una indeterminación directamente, es convertirla en una de otro tipo y seguir probando. Por ejemplo, si tenemos una función \\(f(x)\\) cuyo límite cuando \\(x\\) tiende a \\(a\\) es 0 y una función \\(g(x)\\) cuyo límite cuando \\(x\\) tiende a \\(a\\) es \\(\\infty\\), la función \\(f(x)\\cdot g(x)\\) presenta una indeterminación cuando \\(x\\) tiende a \\(a\\) del tipo \\(0\\cdot \\infty\\). Si no la sabemos resolver, podemos arreglar la función: \\[ f(x)\\cdot g(x) = \\frac{f(x)}{1/g(x)}\\] cambiando la indeterminación por una del tipo \\(\\frac{0}{0}\\) y ahora podemos usar la regla de L’Hôpital. Otra manera de transformar tipos de indeterminación es aplicar logaritmos y recordar que \\(\\log x^y = y\\log x\\). Veamos un ejemplo. Ejemplo 6.9 Calcula \\(\\lim_{x \\to \\infty} (1/x)^{(1/x)}\\). Esta es una indeterminación del tipo \\(0^0\\). Vamos a transformarla aplicando logaritmos. Supongamos que \\[ L = \\lim_{x \\to \\infty} (1/x)^{(1/x)}\\] aplicando logaritmos a ambos lados tenemos que \\[ \\log L = \\lim_{x \\to \\infty}(\\log ((1/x)^{(1/x)})\\] Y ahora \\[\\log L= \\lim_{x \\to \\infty} (1/x) \\log (1/x) = \\lim_{x \\to \\infty} \\frac{\\log(1/x)}{x} = \\lim_{x \\to \\infty} \\frac{\\log(1) - \\log x}{x} = \\lim_{x \\to \\infty} \\frac{- \\log x}{x}\\] Esto es ahora una indeterminación del tipo \\(\\frac{\\infty}{\\infty}\\). Como el denominador tiene un infinito de orden superior, entonces el límite es 0. Y nos queda \\(\\log L = 0\\) lo que significa que \\(L = 1\\). 6.5 Límites laterales En los límites de secuencias, en los que \\(n\\) tiende a infinito, uno sólo podía acercarse al infinito desde valores inferiores, \\(n &lt; \\infty\\). Pero en los límites de funciones, en los que \\(x\\) tiende a \\(a\\), uno puede acercarse a \\(a\\) desde valores inferiores a \\(a\\) y desde valores superiores. Hasta ahora, en los ejemplos que hemos visto, esto no ha sido un problema, pero hay veces que lo es. Supongamos que encendemos un aparato electrónico en un instante \\(t = 0\\). A partir de entonces tenemos una tensión de 1 voltio. Es decir, la función es: \\[ V(t) = \\left\\{\\begin{array}{rl} 0 &amp; \\mbox{si } t &lt; 0\\\\ 1 &amp; \\mbox{si } t ≥ 0\\end{array}\\right.\\] Si nos acercamos a \\(t = 0\\) desde valores negativos, desde la izquierda, la función tiende a 0, y si no miramos lo que pasa para tiempos positivos, parece que el límite es 0. Pero si nos acercamos a \\(t = 0\\) desde valores positivos, desde la derecha, la función tiende a 1, y si no miramos lo que pasa para tiempos negativos, parece que el límite es 1. Separece un poco a la idea de valores oscilantes y nuestra intuición nos dice, correctamente, que esta función no tiene límite cuando \\(t\\) tiende a 0. Este es el tercer caso de inexistencia de límites que mencionábamos en el apartado 6.3.2. Pero este concepto de límites laterales es útil y necesaria, y por lo tanto vamos a definirlas con precisión. Definición 6.5 Sea una función \\(f(x)\\). Decimos que esta función tiene límite \\(L\\) cuando \\(x\\) tiende a \\(a\\) por la izquierda, y lo escribimos como \\[\\lim_{x \\to a^-} f(x) = L\\] si para cualquier número positivo \\(\\varepsilon &gt; 0\\), podemos encontrar un valor \\(\\delta\\) &gt; 0, tal que para todo \\(x\\), si \\(0 &lt; a - x &lt; \\delta\\) entonces \\(|f(x) – L| &lt; \\varepsilon\\). Definición 6.6 Sea una función \\(f(x)\\). Decimos que esta función tiene límite \\(L\\) cuando \\(x\\) tiende a \\(a\\) por la derecha, y lo escribimos como \\[\\lim_{x \\to a^+} f(x) = L\\] si para cualquier número positivo \\(\\varepsilon &gt; 0\\), podemos encontrar un valor \\(\\delta\\) &gt; 0, tal que para todo \\(x\\), si \\(0 &lt; x - a &lt; \\delta\\) entonces \\(|f(x) – L| &lt; \\varepsilon\\). Como vemos, es casi la misma definición del límite comun, sólo que quitamos el valor absoluto a \\(x-a\\) para describir que estamos sólo considerando valores menores que \\(a\\) si es por la izquierda, o valores mayores que \\(a\\) si es por la derecha. Estos límites laterales pueden no existir por ir hacia infinito u oscilar. Pero si ambos existen y tienden al mismo valor \\(L\\), este valor tiene que ser el del límite “normal”. Esto lo enunciamos con el siguiente teorema. Teorema 6.2 Sea una función \\(f(x)\\) y sean \\(L\\) y \\(a\\) números reales. El límite de \\(f(x)\\) cuando \\(x\\) tiende a \\(a\\) es \\(L\\) si y solo si \\[ \\lim_{x \\to a^-} f(x) = \\lim_{x \\to a^+} f(x) = L\\] Este concepto de límites laterales nos permite distinguir dos casos, que si no vamos con cuidado, podemos confundir. Consideremos primero la función \\(f(x) = \\frac{1}{(x-1)^2}\\). Cuando \\(x\\) tiende a 1 esta función crece ilimitadamente y podemos decir, aunque sea un poco incorrectamente, que \\(\\lim_{x \\to 1} f(x) = \\infty\\). Consideremos ahora la función \\(f(x) = \\frac{1}{x-1}\\), Cuando \\(x\\) tiende a 1, esta función crece ilimitadamente en magnitud, pero si \\(x &lt; 1\\) los numeros son negativos, mientras que si \\(x &gt; 1\\) los números son positivos. Con nuestro nuevo concepto de límites laterales, podemos decir que el límite por la izquierda es \\(-\\infty\\) y el límite por la derecha es \\(+\\infty\\). Pero si decimos que el límite de esta función es infinito ya no estamos cometiendo una pequeña incorrección, sino un error garrafal. Esta función no tiene límite cuando \\(x\\) tiende a 1. Vemos en la gráfica que la función se acerca por ambos lados a la recta vertical \\(x = 1\\). Y también se acerca a la recta horizontal \\(y = 0\\). Las rectas a las que la gráfica de un función se aproxima continuamente, de manera que la distancia tiende hacia cero a medida que se extienden reciben el nombre de asíntotas. La recta \\(x = 1\\) es una asíntota vertical de esta función y la recta \\(y = 0\\) es una asíntota horizontal. "],
["funciones-continuidad.html", "Capítulo 7 Funciones: continuidad 7.1 Definiciones 7.2 Discontinuidad evitable 7.3 Continuidad con operaciones de funciones 7.4 Importancia de la continuidad", " Capítulo 7 Funciones: continuidad Como vimos en el apartado 6, casi siempre vamos a tener que \\(\\lim_{x \\to a}f(x) = f(a)\\). Pero a veces esto no pasa. Por ejemplo, tenemos la función \\[\\frac{\\sin \\pi x}{x^2 - 1}\\] Vimos que el límite existe: \\[\\lim_{x \\to 1}\\frac{\\sin \\pi x}{x^2 - 1} = -\\frac{\\pi}{2}\\] pero como \\(f(1)\\) no está definido, \\(\\lim_{x \\to 1} f(x) ≠ f(1)\\). También estudiamos la función \\[f(x) = \\frac{1}{(x-1)^2}.\\] En este caso el límite no existe, o algo incorrectamente decimos que es infinito, luego tampoco pasa en este caso que \\(\\lim_{x \\to 1} f(x) = f(1)\\). Un tercer caso es la función escalón \\[ f(x) = \\left\\{\\begin{array}{rl} 0 &amp; \\mbox{si } x &lt; 0\\\\ 1 &amp; \\mbox{si } x ≥ 0\\end{array}\\right.\\] La función está bien definida en 0, pero como los límites laterales son distintos, el límite no existe. En este tercer caso tampoco sucede que \\(\\lim_{x \\to 0} f(x) = f(0)\\). Es natural considerar como “anormal” estos comportamientos y como “normal” cuando \\(\\lim_{x \\to a}f(x) = f(a)\\). Y nos gustaría dar un nombre a estas funciones que tiene este comportamiento normal. Las llamamos funciones continuas. 7.1 Definiciones Como es casi siempre el caso en matemáticas, vamos a empezar por dar definiciones rigurosas a los conceptos que aparecen. Definición 7.1 Decimos que la función \\(f(x)\\) es continua en el punto \\(a\\) si \\[\\lim_{x \\to a}f(x) = f(a)\\] Esta definición nos da la continuidad en un punto. Nuestra idea intuitiva gráfica de continuidad es una función que no se “rompe”, que podemos trazar en un solo trazo. Pero nuestra definición de continuidad es de continuidad en un punto. Para conjuntar nuestra idea intuitiva con nuestra definición, hemos de definir continuidad en un intervalo. Empecemos por definir dos tipos de intervalos: Definición 7.2 Definimos el intervalo abierto \\((a, b)\\) como todos los puntos entre \\(a\\) y \\(b\\), pero sin contar con los extremos \\(a\\) y \\(b\\), es decir, todos los puntos \\(x\\) tal que \\(a &lt; x &lt; b\\). Definición 7.3 Definimos el intervalo cerrado \\([a, b]\\) como todos los puntos entre \\(a\\) y \\(b\\), incluyendo los extremos \\(a\\) y \\(b\\), es decir, todos los puntos \\(x\\) tal que \\(a ≤ x ≤ b\\). Ahora podemos definir continuidad en ambos tipos de intervalo: Definición 7.4 Decimos que una función \\(f(x)\\) es continua en el intervalo abierto \\((a, b)\\) si es continua en todos los puntos de \\((a, b)\\). Definición 7.5 Decimos que una función \\(f(x)\\) es continua en el intervalo cerrado \\([a, b]\\) si es continua en el intervalo abierto \\((a, b)\\) y se cumple que \\[\\lim_{x\\to a^+}f(x) = f(a) \\quad \\mbox{y} \\lim_{x\\to b^-}f(x) = f(b).\\] En esta última definición hemos de usar los límites laterales ya que no queremos exigir nada fuera del intervalo. 7.1.1 Ejemplos de funciones continuas Casi todas las funciones que usamos habitualmente son continuas en todos o casi todos los puntos. En particular son continuas: Las funciones polinómicas \\(f(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1 x + a_0\\); Las funciones racionales \\(f(x) = \\frac{p(x)}{q(x)}\\), donde \\(p(x)\\) y \\(q(x)\\) son funciones polinómicas, excepto en los puntos donde \\(q(x) = 0\\); Las funciones de potencias \\(f(x) = \\sqrt[n]{x}\\); Las funciones exponenciales \\(f(x) = e^x\\) y logarítmicas \\(f(x) = \\log(x)\\). En el caso de la logarítmica, es continua en su dominio: \\(x &gt; 0\\); Las funciones trigonométricas \\(\\sin x\\) y \\(\\cos x\\). La función \\(\\tan x\\) es continua en todos los puntos excepto \\(x = (2n + 1)\\frac{\\pi}{2}\\). 7.2 Discontinuidad evitable Hemos visto que una función puede no ser continua en \\(a\\) por tres motivos. Una es porque no hay límite en \\(a\\), pues los límites laterales son diferentes. El ejemplo que vimos es la función escalón. Otra, como por ejemplo la función \\(f(x) = \\frac{1}{(x-1)^2}\\), es porque el límite en \\(a\\) es infinito.El tercer motivo es porque, aunque el límite en \\(a\\) existe, no coincide con el valor de \\(f(a)\\), normalmente porque no está definida en ese punto. El ejemplo que hemos visto de este tercer motivo es la función \\[f(x) = \\frac{\\sin \\pi x}{x^2 - 1}.\\] Si la discontinuidad es por alguno de los dos primeros motivos, no hay nada que hacer. Pero si es por el tercero, podemos “arreglarlo” y decimos que la discontinuidad es evitable. Dado que el problema es que \\(\\lim_{x \\to a} f(x) ≠ f(a)\\) lo arreglamos creando otra función en la que \\(\\lim_{x \\to a} f(x) = f(a)\\). Para nuestro ejemplo: \\[ g(x) = \\left\\{ \\begin{array}{rl} \\frac{\\sin \\pi x}{x^2 - 1} &amp; \\mbox{si } x ≠ 1\\\\ -\\frac{\\pi}{2} &amp; \\mbox{si } x = 1 \\end{array}\\right.\\] La función \\(g(x)\\) es continua en \\(x = 1\\). Sigue teniendo un problema en \\(x = -1\\), donde tampoco está definida. Pero como el límite existe, se puede arreglar de la misma manera. 7.3 Continuidad con operaciones de funciones Si \\(f(x)\\) y \\(g(x)\\) son continuas en un cierto intervalo, entonces también son continuas en ese intervalo \\((f+g)(x)\\) \\((f-g)(x)\\) \\((f \\cdot g)(x)\\) \\((f/g)(x)\\) excepto en los puntos donde \\(g(x) = 0\\) \\((f^g)(x)\\) El caso de la composición de funciones es lo que es de esperar, pero un poco más complicado de expresar: \\((g \\circ f)(x)\\) es continua en \\(a\\) si \\(f(x)\\) es continua en \\(a\\) y \\(g(x)\\) es continua en \\(f(a)\\). Ejemplo 7.1 Estudia la continuidad de \\(\\tan x^2\\) en el intervalo \\([0, 5]\\). En este caso \\(f(x) = x^2\\) y \\(g(x) = \\tan x\\). La función \\(f(x)\\) no nos da problemas: es continua en todo \\([0, 5]\\). Ahora bien, \\(\\tan x\\) es continua si \\(x ≠ (2n + 1)\\frac{\\pi}{2}\\). Luego \\(\\tan x^2\\) tiene discontinuidades en los puntos \\(x^2 = (2n + 1)\\frac{\\pi}{2}\\): Es decir, la función \\(\\tan x^2\\) es continua en todo el intervalo \\([0, 5]\\) excepto en los puntos \\[x = \\sqrt{(2n + 1)\\frac{\\pi}{2}}.\\] 7.4 Importancia de la continuidad Las funciones continuas son importantes porque hay muchas funciones interesantes que lo son y porque las funciones continuas tienen unas características que las hacen muy útiles en la ciencia e ingeniería. Veamos dos teoremas importantes. Teorema 7.1 (Teorema de Bolzano) Sea f(x) una función continua en \\([a, b]\\) y \\(f(a)\\) y \\(f(b)\\) toman valores de signo diferente, entonces existe al menos un punto \\(c\\) del intervalo abierto, \\((a, b)\\) tal que \\(f(c) = 0\\). En otras palabras, existe al menos un cero de \\(f(x)\\) en \\((a, b)\\). Este teorema nos permite identificar lugares en donde una función continua tiene un cero. Y también nos da un método para calcular los ceros de una función continua. Ejemplo 7.2 La función \\(f(x) = \\sin \\sqrt{x} - \\log x^2\\) tiene un cero en el intervalo \\([1, 2]\\). Calcúlalo con una precisión de dos decimales. Empecemos por asegurarnos que tiene un 0 en el intervalo. Efectivamente \\(f(1) = 0.84\\) y \\(f(2) = -0.40.\\) Hay un cambio de signo, por lo tanto el teorema de Bolzano nos asegura que hay al menos un 0 en el intervalo. Cojamos el punto medio, \\(x = 1.5\\) y evaluemos la función en ese punto. Tenemos que \\(f(1.5) = 0.13\\). Es positivo, luego el cambio de signo, y por lo tanto el 0, está entre 1,5 y 2. Cojamos el punto medio, \\(x = 1.75\\). Tenemos que \\(f(1.75) = - 0.15\\). Luego el cambio de signo está entre \\(1.5\\) y \\(1.75\\). Cogemos el punto medio, \\(x = 1.625\\)… Vamos repitiendo este proceso hasta conseguir dos decimales exactos. Al cabo de unas cuantas iteraciones llegamos a que el cambio de signo, y por lo tanto el 0, está entre \\(1.611\\) y \\(1.613\\). Por lo tanto, con dos decimales de precisión, sabemos que el cero es \\(1.61\\). Aunque hay procedimientos mejores, este procedimiento es muy simple y fácil de programar en un ordenador. Pasemos al segundo teorema. Teorema 7.2 (teorema de Weierstrass) Toda función continua en un intervalo cerrado [a, b] tiene un máximo y un mínimo absolutos en ese intervalo. Es decir, existen dos puntos \\(x_M\\) y \\(x_m\\) tales que para todo \\(x\\) en \\([a, b]\\) podemos asegurar que \\(f(x_m)≤ f(x) ≤ f(x_M)\\). A menudo vamos a quere calcular los valores másximos o mínimos de un función en un intervalo. Si la función es continua, el teorema de Weierstrass nos asegura que estos máximos y mínimos existen. Si no es continua, podrían no existir. Más adelante veremos cómo se calculan estos máximos y mínimos. "],
["derivadas-e-integrales.html", "Capítulo 8 Derivadas e integrales 8.1 Interpretación geométrica de la derivada: tangentes 8.2 Interpretación física de la derivada: velocidad 8.3 Equivalencia de las dos interpretaciones 8.4 Definición de derivada 8.5 Interpretación geométrica de la integral: área bajo una curva 8.6 Interpretación física de la integral: espacio recorrido por un coche 8.7 Equivalencia de las dos interpretaciones 8.8 Definición de integral 8.9 Teorema fundamental del cálculo", " Capítulo 8 Derivadas e integrales Podemos decir que el cálculo nació cuando nacieron los conceptos de derivada y de integral, en el S. XVII. Nacieron al mismo tiempo, y desarrollado por los mismos matemáticos: Fermat, Leibniz, Newton, los hermanos Bernoulli, Euler… Hoy los vemos como dos partes de un todo, dos operaciones inversas. Pero la derivada y la integral nacieron para resolver dos problemas muy diferentes y fue después, y supongo que con mucha sorpresa, que se descubrió su relación. Antes de entrar, en detalle y por separado, en cada una de estas dos operaciones, vamos a ver su interpretación geométrica y física, y mostrar la relacion que tienen. 8.1 Interpretación geométrica de la derivada: tangentes Una tangente a una curva es una recta que toca a la curva en un solo punto, pero no la atraviesa. La idea de tangente es tan antigua como la geometría y ya la desarrollaron los matemáticos griegos. Pero en el S. XVI Descartes convirtió a la geometría en un problema algebraico y numérico, mostrando cómo se puede describir una curva con una ecuación. Encontrar una tangente a una curva dejaba de ser un problema de dibujo y se convertía en un problema algebraico: ¿cuál es la ecuación de la recta que es tangente a una determinada curva en un punto? El concepto de límite nos permite plantear este problema de forma adecuada. Sea una curva cualquiera y cogemos un punto \\(A\\) sobre la curva, de coordenadas \\((A_x, A_y)\\) y otro punto \\(B\\), también sobre la curva, pero que está a una distancia de 1 sobre el eje X. Es decir, las coordenadas de \\(B\\) son \\((A_x + 1, B_y)\\). Trazamos la recta que pasa por esos dos puntos: Describir algebraicamente esa recta es fácil: es la recta que pasa por el punto \\(A\\) y cuya pendiente es \\(m = (B_y - A_y)/(A_x + 1 - A_x) = (B_y - A_y)/1\\). Seguimos con \\(A\\) y cogemos ahora un punto \\(C\\) que está más cerca de \\(A\\), a una distancia de 0,5 sobre el eje X: \\(C = (A_x + 0.5, C_y)\\) y trazamos la recta que pasa por estos dos puntos. La ecuación de la recta es la de aquella que pasa por el punto \\(A\\) y cuya pendiente es \\(m = (C_y - A_y)/0.5\\). Y repetimos con un punto \\(D\\) que ahora está a distancia 0.25 de \\(A\\) sobre el eje X. La recta que pasa por estos dos puntos es aquella que pasa por \\(A\\) y tiene pendiente \\(m = (D_y - A_y)/0.25\\). Podemos repetir este proceso tantas veces como queramos, siempre y cuando no lleguemos a \\(A\\). Si llegamos a \\(A\\) no tenemos la recta que pasa por 2 puntos, sino la que pasa por 1 punto, y ahí nos perdemos. Pero mientras nos vayamos acercando, por pequeña que sea la distancia entre \\(A\\) y el punto, mientras no sea 0, podemos calcular la pendiente de la recta. Pues definimos como pendiente de la recta tangente a la curva en \\(A\\) como el límite de las pendientes de las rectas que hemos trazado. El problema se parece al de las discontinuidades evitables que vimos en el apartado 7.2. La función no existe en un punto, pero sí existe el límite cundo nos acercamos al punto. Aquí pasa lo mismo: este método no nos da la pendiente en el punto \\(A\\), pero sí que podemos calcular el límite cuando nos acercamos al punto \\(A\\). A esta pendiente que hemos encontrado de esta forma, la llamamos la derivada de la función en el punto \\(A\\). Esta es la interpretación geométrica de la derivada. 8.2 Interpretación física de la derivada: velocidad Tenemos un coche desplazándose en linea recta. Y tenemos en el coche un GPS ideal que nos da en todo momento la posición del coche con precisión absoluta tanto de la posición como del tiempo. Queremos saber cuál es la velocidad del coche en un instante dado. Vamos a utilizar la letra \\(s\\) para las posiciones y la letra \\(t\\) para los tiempos. Para no ir arrastrando \\(s_0\\) y \\(t_0\\) por todo el texto, ponemos el origen de espacio y tiempo en el punto que nos interesa y en el instante que nos interesa: es decir, \\(s_0 = 0\\) y \\(t_0 = 0\\). Si preguntamos al GPS dónde estaba el coche en el instante \\(t = 0\\) nos responderá que en \\(s = 0\\). Si le preguntamos cuánto se ha movido en ese instante exacto, nos dirá que nada. Es lógico: en 0 segundos se ha movido 0 metros. Pero eso no quiere decir que el coche estaba quieto: sabemos que se movía. A estas alturas ya sabemos qué tenemos que hacer. Preguntamos al GPS dónde estaba el coche en el instante \\(t = 1\\mbox{ s}\\) y nos dice que en \\(s = s_1\\mbox{ m}\\). Luego la velocidad media en ese segundo era de \\(\\frac{s_1}{1}\\mbox{ m/s}\\). Ahora preguntamos al GPS dónde estaba el coche en el instante \\(t = 0.5\\mbox{ s}\\) y nos dice que en \\(s = s_{0.5}\\mbox{ m}\\). Luego la velocidad media en ese medio segundo era de \\(\\frac{s_{0.5}}{0.5}\\mbox{ m/s}\\). Y ahora le preguntamos al GPS donde estaba en el instante \\(t = 0.25\\mbox{ s}\\), y en el instante \\(t = 0.125\\mbox{ s}\\), etc. y podemos ir calculando las velocidades medias de intervalos de tiempo cada vez más pequeños. Esas velocidades van a tener un límite, luego ahora definimos la velocidad en el instante \\(t = 0\\) como el límite de esas velocidades medias a medida que \\(t\\) tiende a 0. Definimos la velocidad como la derivada de la posición respecto del tiempo. Hemos cogido un caso concreto, posición y velocidad de un objeto. Pero cada vez que en física aparece una derivada, podemos hacer una interpretación análoga. Si por ejemplo estamos considerando la evaporación de agua en un estanque y queremos saber cuánto se evapora en un instante, medimos cuánto se evapora de media en 1 segundo, 0.5 segundos, etc. y podemos tener la evaporación instantánea. 8.3 Equivalencia de las dos interpretaciones Hemos dado dos definiciones de derivada. Supongo que no sorprenderá a nadie saber que ambas definiciones son equivalentes (si no lo fueran, tendríamos un problema grave). Veámoslo. Vamos a convertir la interpretación física a la geométrica. Para ello dibujamos la curva del espacio en función del tiempo, es decir, \\(s(t)\\). Para calcular la velocidad media en 1 segundo, cogimos \\(s(1)\\), que llamamos \\(s_1\\) y \\(s(0)\\), que era 0, y calculamos \\((s(1) - s(0))/1\\). Pero eso es precisamente la expresión de la pendiente de la recta que pasa por esos dos puntos. Es decir, lo mismo que hicimos en la interpretación geométrica. Y el coger intervalos de tiempo cada vez más cortos, es coger puntos cada vez más cercanos al punto de partida. Que es lo mismo que hicimos con la interpretación geométrica. Y llegamos a la concusión que la velocidad en el instante \\(t = 0\\) la podemos interpretar como la pendiente de la tangente a la curva de posición en el punto \\((s_0, t_0)\\). Las dos interpretaciones son equivalentes. 8.4 Definición de derivada Después de considerar estas dos interpretaciones, vamos a dar una definición matemática de lo que es una derivada. Nos basaremos en la interpretación geométrica. Tenemos una función \\(f(x)\\) que es continua en un intervalo \\([u, v]\\). Dibujamos la gráfica de la función y tenemos una curva. Cogemos un punto \\(A\\) de esta curva, cuyas coordenadas son \\((a, f(a))\\). Vamos a dar un “empujoncito” de tamaño 1 al punto \\(x = a\\) y veamos qué hace la función. Cogemos, pues, un punto \\(B\\) sobre al curva, que está a una distancia de 1 sobre el eje X. Las coordenadas de \\(B\\) son \\((a + 1, f(b)) = (a+1, f(a+1))\\). Podemos saber cómo varía la función tras este empujoncito mirando la pendiente de la recta que pasa por los dos puntos: \\[m_1 = \\frac{f(a+1) - f(a)}{(a+1) - a} = \\frac{f(a+1) - f(a)}{1}.\\] Vamos a dar un empujoncito más pequeño, de tamaño 0.5. Esto nos da un punto \\(C\\), sobre la curva, que está a distancia 0.5 de \\(A\\) sobre el eje X. Podemos saber cómo varía la función tras este empujoncito mirando la pendiente de la recta que pasa por los dos puntos: \\[m_{0.5} = \\frac{f(a+0.5) - f(a)}{(a+0.5) - a} = \\frac{f(a+0.5) - f(a)}{0.5}.\\] En general, damos un empujoncito pequeño de tamaño \\(dx\\) y miramos cómo varía la función calculando la pendiente que pasa por los dos puntos. Es facil calcular que es \\[m = \\frac{f(a+dx) - f(a)}{dx}.\\] La pendiente de la tangente en \\(A\\), es decir, la derivada de la función \\(f(x)\\) en \\(x = a\\), es el límite cuando los puntos tienden a \\(A\\), o lo que es lo mismo, el límite cuando el empujoncito \\(dx\\) tiende a 0: \\[\\frac{df}{dx}(a) = f^{\\prime}(a) = \\lim_{dx \\to 0}\\frac{f(a+dx) - f(a)}{dx}\\] Por lo tanto vemos que la derivada nos dice cómo varía la función \\(f(x)\\) cuando le damos un “empujoncito” cada vez más pequeño, que tiende a 0, a la variable \\(x\\). A veces a \\(dx\\) se le llama un infinitesimal o una cantidad infinítamente pequeña. Ese es un error que a veces causa confución. Es mejor pensar en \\(dx\\) como una cantidad pequeña, pero existente, pero entendiendo que lo que nos interesa es lo que pasa cuando \\(dx\\) tiende a 0. Hemos definido la derivada para un punto concreto de la curva \\(A = (a, f(a))\\). Podemos definir ahora la derivada en un intervalo abierto \\((u, v)\\). Sea \\(x\\) en \\((u, v)\\), su derivada es \\[\\frac{df}{dx}(x) = f^{\\prime}(x) = \\lim_{dx \\to 0}\\frac{f(x+dx) - f(x)}{dx}\\] Vemos también que hay dos notaciones, \\(\\frac{df}{dx} (x)\\) y \\(f^{\\prime}(x)\\). Hay quien defiende la primera, llamada notación de Leibniz, y hay quien defiende la segunda. Hay que conocerlas ambas. Aquí usaremos las dos, según convenga. Lo hemos definido en un intervalo abierto \\((u, v)\\), puesto que tenemos problemas para definir las derivadas en los extremos \\(u\\) y \\(v\\) del intervalo, pues no podemos decir nada de loq ue pasa fuera del intervalo (ni siquiera sabemos si la función está definida). Es el mismo problema con el que nos encontramos al definir continuidad en un intervalo. Y se resuelve de la mima manera. 8.4.1 Derivadas laterales Como existen límites laterales, y la derivada se define a partir del límite, es una extensión natural definir derivadas laterales: definimos derivada por la derecha de una función \\(f(x)\\) en un punto \\(a\\) como \\[f^{\\prime}(a^+) = \\lim_{dx \\to 0^+}\\frac{f(a+dx) - f(a)}{dx}\\] y derivada por la izquierda: \\[f^{\\prime}(a^-) = \\lim_{dx \\to 0^-}\\frac{f(a+dx) - f(a)}{dx}\\] Como en el caso de los límites, para que exista derivada en \\(x = a\\), si existen, ambas derivadas laterales deben iguales: \\(f^{\\prime}(a^+) = f^{\\prime}(a^-) = f^{\\prime}(a)\\). Si no son iguales, entonces no hay derivada en \\(x = a\\). 8.4.2 Existencia de derivadas Hemos definido las derivada a partir del concepto de límite. Sabemos que un límite puedo o no existir. Por lo tanto la derivada en un punto también puede o no existir. Si en un punto \\(a\\) el límite, y por lo tanto la derivada, existe, decimos que la función \\(f(x)\\) es derivable en el punto \\(a\\). Si no existe, entonces decimos que la función \\(f(x)\\) no es derivable en el punto \\(a\\). Y ahora podemos extender la idea de derivable en un punto a derivable en un intervalo: decimos que una función es derivable en un intervalo \\((u, v)\\), si es derivable en todos los puntos del intervalo. Y una vez definidas las derivadas laterales, podemos definir derivada de una función en un intervalo cerrado: Una función es derivable en un intervalo cerrado \\([u, v]\\) si es derivable en el intervalo abierto \\((u, v)\\) y tiene derivada por la derecha en \\(u\\) y derivada por la izquierda en \\(v\\). Ejemplo 8.1 La función \\(f(x) = x\\) es derivable en todo su dominio \\((-\\infty, \\infty)\\). Al ser una recta, su pendiente es constante en todos los puntos, en este caso, la pendiente vale 1. Sin necesidad de hacer los cálculos formales, sabemos entonces que la derivada de \\(f(x) = x\\) es \\(f^{\\prime}(x) = 1\\) en todos los puntos del dominio. Ejemplo 8.2 La función \\(f(x) = |x|\\) es derivable en todo su dominio \\((-\\infty, \\infty)\\) excepto en el punto \\(x = 0\\). Al estar formado por dos rectas, por el mismo argumento que en el ejemplo anterior, sabemos que su derivada es 1 si \\(x &gt; 0\\) y que su derivada es \\(-1\\) si \\(x &lt; 0\\). Esto quiere decir que en el punto \\(x = 0\\) la derivada por la izquierda es \\(f^{\\prime}(0^-) = -1\\) y la derivada por la derecha es \\(f^{\\prime}(0^+) = 1\\). Como las derivadas laterales son distintas, \\(f(x) = |x|\\) no es derivable en \\(x = 0\\). Una vez vistas las derivadas, pasemos a las integrales. 8.5 Interpretación geométrica de la integral: área bajo una curva Tenemos una cierta curva y queremos calcular el área entre la curva y el eje X entre \\(x = 0\\)y \\(x = 2\\). No sabemos hacerlo de forma exacta, pero lo que podemos hacer es crear rectángulos. Sabemos calcular el área de un rectángulo y podemos entonces sumar estas áreas para tener un valor aproximado del área. Llamemos \\(dx\\) a la longitud de la base del rectángulo. Si hacemos rectángulos de base \\(dx = 0.2\\) tenemos: Parece una aproximación un poco cruda. Podemos crear rectángulos más estrechos y la aproximación será mejor. Por ejemplo con rectángulos de base \\(dx = 0.1\\) nos queda: Intuitivamente entendemos que cuanto más estrechos sean los rectángulos, mejor aproximará la suma de rectángulos al área bajo la curva. El área bajo la curva será el límite de la suma de los rectángulos cuando la base \\(dx\\) tienda a cero. A esto se le llama la integral de esta curva entre 0 y 2. El símbolo de la integral, \\(\\int\\), lo diseñó Leibniz. Es una “S” estilizada. S de suma. La palabra “integral” nos debe evocar la idea de suma. 8.6 Interpretación física de la integral: espacio recorrido por un coche Para la interpretación física, volvamos a nuestro coche del apartado 8.2. La diferencia es que ahora, en vez de un GPS que nos da la posición, tenemos un velocímetro ideal, que nos da la velocidad del coche con absoluta precisión, tanto de la velocidad como del tiempo. Así, sabemos la velocidad en cada momento, pero no sabemos cuánto ha recorrido el coche, y queremos calcularlo a partir de los datos de este velocímetro. Otra vez, para no ir arrastrando \\(s_0\\) y \\(t_0\\), suponemos que en el instante \\(t = 0\\) estamos en el origen, es decir, \\(s(0) = 0\\). Vamos a preguntar a nuestro velocímetro la velocidad a la que íbamos a cada intervalo que vamos a llamar \\(dt\\) segundos. Empezamos preguntando a cada segundo, es decir, \\(dt = 1\\). Preguntamos cuál era la velocidad en el tiempo \\(t = 0\\) y nos responde que era \\(v_0\\mbox{ m/s}\\). Vamos a suponer que la velocidad era constante en ese primer segundo. Esto quiere decir que en el primer segundo hemos avanzado \\(v_0\\cdot 1 = v_0\\mbox{ m}\\). Ahora preguntamos al velocímetro cuál era la velocidad en el tiempo \\(t = 1\\). Nos responde que era \\(v_1\\mbox{ m/s}\\). Suponemos, otra vez, que la velocidad era constante en ese segundo y calculamos que hemos avanzado \\(v_1\\cdot 1 = v_1\\mbox{ m}\\) en ese segundo, y que en el total de los 2 segundos hemos avanzado \\(v_0 + v_1\\mbox{ m}\\). Seguimos preguntando a cada segundo y, por ejemplo al cabo de 20 segundos estimamos que hemos avanzado \\(v_0 + v_1 + \\cdots +v_{19}\\mbox{ m}\\). Si queremos mejorar nuestra estima, podemos reducir \\(dt\\) y preguntar cada menos tiempo, por ejemplo cada \\(dt = 0.5\\) segundos. En \\(t=0\\) la velocidad es \\(v_0\\) y en el primer medio segundo hemos avanzado \\(v_0\\cdot 0.5 = 0.5 v_0\\mbox{ m}\\). En \\(t = 0.5\\) la velocidad es \\(v_{0.5}\\) y calculamos que hemos avanzado \\(0.5 v_0 + 0.5 v_0.5 = 0.5(v_0 + v_{0.5})\\mbox{ m}\\). Y al cabo de 20 segundos nuestra estima es \\(0.5 (v_0 + v_{0.5} + v_1 + \\cdots + v_{19} +v_{19.5})\\mbox{ m}\\). Otra vez vemos intuitivamente que cuanto más a menudo preguntemos la velocidad, mejor estimaremos lo que hemos avanzado. Y la posicion exacta será el límite cuando \\(dt\\) tienda a 0. Hemos encontrado la posición como la integral de la velocidad. Este método que hemos descrito se ha usado durante siglos en la navegación de barcos. Cada cierto tiempo se medía la velocidad del barco y se suponía que el barco avanzaba a velocidad constante hasta la siguiente medida. Para medir la velocidad tiraban una cuerda al agua con un flotador en un extremo. En la cuerda había nudos a intervalos regulares y contaban cuantos nudos caían al agua en un cierto tiempo. Por eso la unidad de velocidad de los barcos se llama nudos. 8.7 Equivalencia de las dos interpretaciones Como en el caso de la derivada, vamos a convertir la interpretación física a la geométrica. Consideremos la función \\(v(t)\\), con la velocidad del coche en cada instante \\(t\\). En el caso en el que hicimos \\(dt = 0.5\\) segundos, cogíamos los instantes \\(t = 0, t = 0.5, t = 1, \\dots\\) y al considerar que la velocidad era constante, multiplicábamos \\(v(t) \\cdot dt\\) para estimar cuánto se había desplazado en ese intervalo. Por ejemplo para el intervalo entre \\(t = 1\\) y \\(t = 1.5\\) obteníamos \\(0.5 v(1)\\). Y después sumábamos todo. Pero esa expresión \\(0.5 v(1)\\) es precisamente el área de un rectángulo de altura \\(v(1)\\) y anchura \\(dt = 0.5\\), que es precisamente lo que hacemos en la interpretación geométrica. Y sumar todos los desplazamientos es, por lo tanto, sumar todos los rectángulos. Luego ambas interpretaciones dan lugar a la misma expresión y son equivalentes. 8.8 Definición de integral La integral es inherentemente más difícil que la derivada y así como pudimos dar una definicion rigurosa de la derivada a partir de las ideas básicas, no es posible hacerlo con la integral. La definción que vamos a dar aquí de la integral no es rigurosa y tiene muchos agujeros, pero nos servirá para concretar las ideas intuitivas que hemos visto. Sea una función \\(f(x)\\) continua en el intervalo \\([a, b]\\). Dividimos este intervalo en \\(N\\) subintervalos iguales. La longitud de cada subintervalo es \\(dx = (b-a)/N\\). Cogemos los puntos de inicio de cada subintervalo: \\(a, a +dx, a+2dx, \\dots, a + (N-1)dx\\). Creamos \\(N\\) rectángulos cuya base es cada uno de los subintervalos y cuya altura es la altura de la función al inicio del subintervalo. Las áreas de estos rectángulos son \\(dx\\cdot f(a), dx\\cdot f(a+dx), dx\\cdot f(a+2dx), \\dots\\) y la suma \\(A_N\\) de estas áreas es \\[\\begin{align} A_N &amp;= dx\\cdot f(a) + dx\\cdot f(a+dx)+ dx\\cdot f(a+2dx)+ \\cdots\\\\ &amp;= dx(f(a) + f(a+dx) + f(a+2dx)+ \\cdots)\\\\ &amp;= dx\\sum_{k = 1}^N f(a+(k-1)dx) \\end{align}\\] Definimos (de forma no rigurosa) como integral de \\(f(x)\\) entre \\(a\\) y \\(b\\) al límite de la sucesión de estos valores \\(A_N\\) cuando \\(N\\) tiende a infinito: \\[\\int_a^b f(x)dx = \\lim_{N\\to \\infty} A_N = \\lim_{N\\to \\infty}dx\\sum_{k = 1}^N f(a+(k-1)dx)\\] Nótese que cuando \\(N\\) tiende a infinito, \\(dx\\) tiende a 0 y podríamos igualmente haber definido la integral como el límite cuando \\(dx\\) tiende a 0 de esa expresión. Nótese también que tenemos un \\(dx\\) multiplicando el sumatorio. Es por eso que la expresión correcta es \\(\\int_a^b f(x)dx\\) y no \\(\\int_a^b f(x)\\). Olvidarse del \\(dx\\) es un error grave. Y una tercera nota. Hemos cogido el valor de \\(f(x)\\) al inicio de cada intervalo. Igual podíamos haber cogido el valor de \\(f(x)\\) al final de cada intervalo (o en el punto medio de cada intervalo, o en…). Aunque los valores de las sumas parciales van a ser diferentes, en el límite van a llegar al mismo valor. 8.8.1 Integrales negativas Si miramos la expresión que acabamos de escribir en el apartado anterior, vemos que es perfectamente posible tener integrales negativas: el signo depende de la suma de los valores de \\(f(a+(k-1)dx)\\) y, como \\(f(x)\\) puede ser negativa, la suma, y por lo tanto la integral, también pueden serlo. Pero la idea de un área negativa nos chirría: un área siempre es positiva. ¿no es esto un sinsentido? Vamos a ver que, mirando la interpretación física de la integral, el hablar de integrales negativas tiene todo el sentido del mundo. Seguimos con nuestro ejemplo del coche. En mecánica, la disciplina de la física que se ocupa del movimiento de los objetos, se da un signo a los desplazamientos. La costumbre es que un signo positivo significa que estamos a la derecha del origen y un signo negativo indica que estamos a la izquierda del origen. Por lo tanto \\(s = 1.2\\) quiere decir que estamos 1.2 metros a la derecha del punto que hemos establecido como origen y \\(s = -0.78\\) quiere decir que estamos a 0.78 metros a la izquierda de este punto. Y lo mismo pasa con las velocidades: uan velocidad positiva quiere decir que nos estamos desplazando hacia la derecha del origen y una velocidad negativa quiere decir que nos estamos desplazando hacia la izquierda del origen. Consideremos ahora que la velocidad de nuestro coche es la función \\(5\\sin ((\\pi/10)t)\\): Vemos que el coche avanza hacia la derecha (velocidades positivas) hasta \\(t = 10\\), y después avanza hacia la izquierda (retrocede) hasta \\(t = 20\\), donde se para. Y lo que queremos saber es dónde se para. Recordemos que la superficie bajo la curva nos da el desplazamiento. Vamos a considerar sólo la superficie (es decir, el desplazamiento) entre \\(0\\) y un valor \\(t &lt; 10\\). Por ejemplo, si tenemos \\(t = 6\\) el área es Es fácil ver que a medida que \\(t\\) crece el area es mayor y por lo tanto el coche está más alejado hacia la derecha del origen. El máximo se obtiene cuando \\(t = 10\\). Esto coincide con nuestro conocimiento de lo que hace el coche: hasta \\(t = 10\\) no para de avanzar. ¿Que pasa a partir de \\(t = 10\\)? Vamos a mirar la posición, es decir el área bajo la curva en \\(t = 12.8\\): Tenemos ahora un área “positiva” en azul y un área “negativa” en rojo. Esto quiere decir que pasado \\(t = 10\\) el área total, y por lo tanto la posición, va disminuyendo al ir aumentando \\(t\\). Es decir, el objeto se va acercando al origen. Otra vez, esto coincide con nuestro conocimiento de lo que hace el coche: a partir de \\(t = 10\\) el coche retrocede. ¿Y qué pasa en \\(t = 20\\)? Por simetría vemos que el área por encima del eje X es igual al área por debajo, por lo tanto el área total es 0: el coche ha vuelto al origen. El tener integrales negativas va a resultar muy útil para calcular este tipo de fenómenos. 8.9 Teorema fundamental del cálculo En la interpretación geométrica de las derivada hemos visto que sirve para calcular la pendiente de la tangente a una curva. En la interpretacon geométrica de la integral, hemos visto que sirve para calcular el área bajo una curva. Son dos cálculos diferentes y no parece que tengan mucho que ver la una con la otra. Resulta sorprendente que estén, como sabemos, tan ligadas. Pero si miramos las interpretaciones físicas, ya no es tan sorprendente: si tenemos la función de la posición de un objeto en cada instante de tiempo, hemos visto que la derivada nos da su velocidad. Pero si lo que tenemos es la velocidad del objeto en cada instante de tiempo, la integral de esa función nos da la posición. De forma natural hemos encontrado una relación estrecha entre derivada e integral. El teorema fundamental del cálculo nos dice que la derivada de la integral de una función es esa misma función. Más formalmente, sea una función \\(f(x)\\) que tiene una integral entre \\(a\\) y \\(b\\). Sea un punto \\(x ≤ b\\). Sea \\(F(x)\\) el área bajo la curva entre \\(a\\) y \\(x\\) Sabemos que esto es \\[ F(x) = \\int_a^x f(x)dx.\\] Entonces la derivada de \\(F(x)\\) es \\(f(x)\\): \\[\\frac{dF}{dx}(x) = f(x).\\] Hemos vislumbrado con las interpretaciones físicas que esto es así. Vamos a verlo ahora geométricamente. Al definir la derivada en el apartado 8.4 dijimos que la derivada nos indica cuánto cambia una función al darle un empujoncito a la variable \\(x\\), de tamaño \\(dx\\). En concreto, la derivada es el cambio que calculamos cuando el empujoncito tiende a 0: \\[\\frac{df}{dx}(a) = f^{\\prime}(a) = \\lim_{dx \\to 0}\\frac{f(a+dx) - f(a)}{dx}\\] Tenemos una función cualquiera \\(f(x)\\). Sea \\(F(x)\\) la integral de \\(f(x)\\), es decir su área entre un punto determinado y un punto genérico \\(x\\). En el dibujo siguiente \\(F(x)\\) es el área de la zona verde: ¿Qué pasa si le damos un empujoncito de tamaño \\(dx\\) a \\(F(x)\\)? Es decir, qué pasa con el área si pasamos de \\(x\\) a \\(x + dx\\)? Lo que hacemos es añadir un pequeño rectángulo al área que ya tenemos: Este pequeño rectángulo azul tiene de base \\(dx\\) y de altura \\(f(x)\\), luego su área es \\(f(x)\\cdot dx\\). El área tras el empujoncito es el área que teniamos más el área del rectángulo: \\[F(x+dx) = F(x) + f(x)\\cdot dx\\] Para obtener la derivada hemos de hacer el límite cuando \\(dx\\) tiende a 0: \\[\\begin{align} \\frac{dF}{dx}(x) &amp;= \\lim_{dx \\to 0}\\frac{F(x+dx) - F(x)}{dx}\\\\ &amp;= \\lim_{dx \\to 0}\\frac{F(x) + f(x)\\cdot dx - F(x)}{dx} = \\lim_{dx \\to 0}\\frac{f(x)\\cdot dx}{dx}\\\\ &amp;= f(x) \\end{align}\\] Como habíamos dicho, la derivada de la integral de \\(f(x)\\) es \\(f(x)\\). "],
["derivación.html", "Capítulo 9 Derivación 9.1 Algunas derivadas elementales 9.2 Derivadas de operaciones 9.3 Derivada de composición de funciones: regla de la cadena 9.4 Derivadas sucesivas", " Capítulo 9 Derivación Una vez explicado el concepto de derivada, y vista la definición formal, pasemos al cálculo de las funciones derivadas. A esto se le conoce con el nombre de derivación. Se pueden deducir las funciones derivadas por métodos algebraicos y geométricos. Por su naturaleza, los métodos geométricos son visuales y las gráficas y animaciones son muy útiles. Recomiendo los videos del canal de YouTube de 3 Blue 1 Brown de su serie de Esencia del Cálculo. Especialmente los capítulos 3 y 4. Aquí nos centraremos en el método algebraico. 9.1 Algunas derivadas elementales En el apartado 8.4, definimos derivada tanto en un punto como en un intervalo, sea abierto o cerrado. Vamos a usar esta definición para calcular las funciones derivadas de algunas funciones simples. Ejemplo 9.1 Hállese la derivada de \\(f(x) = ax\\). Hemos de aplicar la definición. En este priemr ejemplo, lo vamos a desarrollar con mucho detalle: \\[\\begin{align} f^{\\prime}(ax) &amp;= \\lim_{dx \\to 0}\\frac{f(x+dx) - f(x)}{dx}\\\\ &amp;= \\lim_{dx \\to 0}\\frac{a(x+dx) - ax}{dx}\\\\ &amp;= \\lim_{dx \\to 0}\\frac{ax + a\\, dx - ax}{dx}\\\\ &amp;= \\lim_{dx \\to 0}\\frac{a\\, dx}{dx}\\\\ &amp;= \\lim_{dx \\to 0}a\\\\ &amp;= a \\end{align}\\] Ahora uno sólo ligeramente más complicado: Ejemplo 9.2 Hállese la derivada de \\(f(x) = x^n\\). Aplicamos la definción: \\[f^{\\prime}(x^n) = \\lim_{dx \\to 0}\\frac{f(x+dx) - f(x)}{dx} = \\lim_{dx \\to 0}\\frac{(x+dx)^n - x^n}{dx}\\] Desarrollamos \\((x+dx)^n\\) por el binomio de Newton. No nos va a hacer falta desarrollarlo todo en detalle pues sabemos que a partir del tercer término tenemos al menos un factor \\(dx^2\\) y lo sacamos factor común: \\[\\lim_{dx \\to 0}\\frac{(x+dx)^n - x^n}{dx} = \\lim_{dx \\to 0}\\frac{(x^n +nx^{n-1}dx + dx^2(\\dots)) - x^n}{dx}\\] Y ahora los \\(x^n\\) se cancelan. Como además el límite de una suma es la suma de los límtes, no queda: \\[\\lim_{dx \\to 0}\\frac{nx^{n-1} dx}{dx} + \\lim_{dx \\to 0}\\frac{dx^2(\\dots)}{dx}\\] Cancelando los \\(dx\\): \\[\\lim_{dx \\to 0}nx^{n-1} + \\lim_{dx \\to 0}dx(\\dots)\\] El primer límite es \\(nx^{n-1}\\) y en el segundo, como lo que hay en el parentesis no es infinito, el límite es 0. Por lo que nos queda que \\[f^{\\prime}(x^n) = \\lim_{dx \\to 0}\\frac{(x+dx)^n - x^n}{dx} = nx^{n-1}\\] Ahora hagamos uno muy importante, pero con un límite que no es simple: Ejemplo 9.3 Hállese la derivada de \\(f(x) = e^x\\). Como siempre, empezamos por aplicar la definción: \\[f^{\\prime}(e^x) = \\lim_{dx \\to 0}\\frac{e^{x+dx} - e^x}{dx}\\] Desarrollamos el primer término y sacamos factor común: \\[\\lim_{dx \\to 0}\\frac{e^x\\cdot e^{dx} - e^x}{dx} = \\lim_{dx \\to 0}\\frac{e^x(e^{dx} - 1)}{dx}\\] Como \\(e^x\\) no depende de \\(dx\\) lo podemos sacar fuera del límite: \\[e^x\\lim_{dx \\to 0}\\frac{(e^{dx} - 1)}{dx}\\] Es un límite de tipo \\(\\frac{0}{0}\\). Nuestro primer impulso sería aplicar L’Hôpital, pero no podemos, pues sería utilizar la derivada de \\(e^x\\) para determinar cuál es la derivada de \\(e^x\\). Es un error de razonamiento circular: hemos de saber cuál es la derivada de \\(e^x\\) para saber cuál es la derivada de \\(e^x\\). Tenemos que usar un camino más largo. Hacemos un cambio de variable: \\(y = e^{dx} -1\\). Entonces \\(dx = \\log(y+1)\\). Es fácil ver que si \\(dx \\to 0\\) entonces \\(y \\to 0\\). Luego: \\[\\lim_{dx \\to 0}\\frac{(e^{dx} - 1)}{dx}= \\lim_{y \\to 0}\\frac{y}{\\log(y+1)}\\] Pasamos el \\(y\\) del numerador al denominador: \\[\\lim_{y \\to 0}\\frac{1}{\\frac{1}{y}\\log(y+1)} = \\frac{1}{\\lim_{y \\to 0}{\\frac{1}{y}\\log(y+1)}}\\] o lo que es lo mismo \\[\\frac{1}{\\lim_{y \\to 0} \\log(y+1)^{(1/y)}}\\] Como el límite de unlogaritmo es lo mismo que el logaritmo del límite: \\[\\frac{1}{\\log(\\lim_{y \\to 0} (y+1)^{(1/y)})}\\] Y el límite es nuestro qeurido número \\(e\\): \\[\\frac{1}{\\log(e)} = \\frac{1}{1} = 1\\] Ahora que ya sabemos el límite, reacapitulamos: \\[f^{\\prime}(e^x) =e^x\\lim_{dx \\to 0}\\frac{(e^{dx} - 1)}{dx} = e^x \\cdot 1 = e^x\\] El procedimiento de calcular la función derivada a veces es fácil y a veces muy complicado. Por suerte es algo que ya han hecho para nosostros y simplemente nos aprendemos de memoria las más habituales (y buscamos en tablas las que no nos sabemos). 9.1.1 Cuadro de derivadas elementales En el cuadro siguiente están algunas de las derivadas elementales más habituales, y que conviene saber de memoria. En el cuadro \\(a\\) es una constante y \\(x\\) es la variable sobre la que derivamos. \\(f(x)\\) \\(f^{\\prime}(x)\\) \\(a\\) 0 \\(x\\) 1 \\(x^n\\) \\(nx^{n-1}\\) \\(\\sqrt{x}\\) \\(\\frac{1}{2\\sqrt{x}}\\) \\(a^x\\) \\(a^x \\log(a)\\) \\(e^x\\) \\(e^x\\) \\(\\log(x)\\) \\(\\frac{1}{x}\\) \\(\\sin(x)\\) \\(\\cos(x)\\) \\(\\cos(x)\\) \\(-\\sin(x)\\) \\(\\tan(x)\\) \\(\\frac{1}{\\cos^2(x)}\\) Nota: Aunque en la derivación que hemos de la derivada de \\(x^n\\) la \\(n\\) es un número entero, no tiene por qué serlo. Funciona para cualquier número racional. Por ejemplo \\[\\frac{dx^{3/4}}{dx} = \\frac{3}{4}x^{-1/4} \\] 9.2 Derivadas de operaciones Sean dos funciones \\(f(x)\\) y \\(g(x)\\). Las derivadas de las operaciones aritméticas de estas funciones son las siguientes: \\[\\begin{array}{l} (a\\cdot f)^{\\prime}(x) = a \\cdot f^{\\prime}(x)\\\\ (f+g)^{\\prime}(x) = f^{\\prime}(x) + g^{\\prime}(x)\\\\ (f-g)^{\\prime}(x) = f^{\\prime}(x) - g^{\\prime}(x)\\\\ (f\\cdot g)^{\\prime}(x) = f^{\\prime}(x)\\cdot g(x) + f(x)\\cdot g^{\\prime}(x)\\\\ (f/g)^{\\prime}(x) = \\frac{f^{\\prime}(x)\\cdot g(x) - f(x)\\cdot g^{\\prime}(x)}{g^2(x)}\\end{array} \\] Un error habitual, sobre todo en novatos, es aplicar reglas de derivación de la multiplicación y de la división cuando no es necesario, convirtiendo una derivada simple y elemental en algo innecesariamente complicado. Veamos un ejemplo. Ejemplo 9.4 Calcula la derivada de \\[f(x) = \\frac{x^2}{5}.\\] Como hay un numerador y un denominador, a primera vista parece que es la derivada de una división: \\[\\left(\\frac{x^2}{5}\\right)^{\\prime} = \\frac{2x\\cdot 5 - x^2\\cdot 0}{25} = \\frac{2x}{5}\\] Pero el denominador es una constante, luego podemos reescribir la función como \\(f(x) = \\frac{1}{5} x^2\\) y entonces: \\[\\left(\\frac{1}{5} x^2\\right)^{\\prime} = \\frac{1}{5} (x^2)^{\\prime} = \\frac{2x}{5}\\] 9.3 Derivada de composición de funciones: regla de la cadena Sean dos funciones \\(f(x)\\) y \\(g(x)\\) y sea la función compuesta \\((g\\circ f)(x)\\). La derivada de esta función compuesta es: \\[(g\\circ f)^{\\prime}(x) = g^{\\prime}(f(x))\\cdot g^{\\prime}(x)\\] A esta expresión se le llama la regla de la cadena. Recordar esta expresión y, sobre todo, aplicarla, puede ser un tanto farragoso. Es más fácil acordarse de las derivadas elementales con la regla de la cadena “incorporada”. Si llamamos \\(u\\) a una expresión, y \\(u^{\\prime}\\) a su derivada, entonces el cuadro de derivadas elementales se convierte en: \\(f(x)\\) \\(f^{\\prime}(x)\\) \\(a\\) 0 \\(x\\) 1 \\(u^n\\) \\(u^{\\prime}nu^{n-1}\\) \\(\\sqrt{u}\\) \\(\\frac{u^{\\prime}}{2\\sqrt{u}}\\) \\(a^u\\) \\(u^{\\prime}a^u \\log(a)\\) \\(e^u\\) \\(u^{\\prime}e^u\\) \\(\\log(u)\\) \\(\\frac{u^{\\prime}}{u}\\) \\(\\sin(u)\\) \\(u^{\\prime}\\cos(u)\\) \\(\\cos(u)\\) \\(-u^{\\prime}\\sin(u)\\) \\(\\tan(u)\\) \\(\\frac{u^{\\prime}}{\\cos^2(u)}\\) Veamos algún ejemplo de aplicación de esta regla. Ejemplo 9.5 ¿Cuál es la derivada de \\(\\cos(x^3)\\)? En este caso \\(u = x^3\\) y del cuadro anterior sacamos que \\((\\cos(u))^{\\prime} = -u^{\\prime}\\sin(u)\\). Como \\(u^{\\prime} = 3x^2\\) nos queda que \\[(\\cos(x^3))^{\\prime} = -3x^2 \\sin(x^3)\\] Ejemplo 9.6 ¿Cuál es la derivada de \\(\\cos^3(\\sqrt{x})\\)? Hemos de aplicar la regla de la cadena varias veces. Para la primera, tenemos que \\(u = \\cos(\\sqrt{x})\\) y tenemos una función de la forma \\(u^n\\). Luego \\[(\\cos^3(\\sqrt{x}))^{\\prime} = (\\cos(\\sqrt{x}))^{\\prime} 3 \\cos^2 (\\sqrt{x}) \\] Ahora debemos volver a palicar la regla de la cadena para hallar la derivada de \\(\\cos(\\sqrt{x})\\). Ahora \\(u = \\sqrt{x}\\) y tenemos una función de la forma \\(\\cos(u)\\). La derivada es: \\[(\\cos(\\sqrt{x}))^{\\prime} = -\\frac{1}{2\\sqrt{x}}\\sin(\\sqrt{x})\\] Juntándolo todo queda: \\[(\\cos^3(\\sqrt{x}))^{\\prime} = -\\frac{1}{2\\sqrt{x}}\\sin(\\sqrt{x}) 3 \\cos^2 (\\sqrt{x}) = -\\frac{3 \\sin(\\sqrt{x}) \\cos^2 (\\sqrt{x})}{2\\sqrt{x}} \\] 9.4 Derivadas sucesivas Hemos visto que dada una función \\(f(x)\\), si es derivable, podemos calcular la función derivada \\(f^{\\prime}(x)\\). Ahora bien, como es una función derivada, la podemos derivar otra vez. A esto le llmamos la derivada segunda, y la escribimos como \\[\\frac{d^2f}{dx^2} (x) = f^{\\prime\\prime}(x)\\] Y naturalmente podemos derivar esta derivada segunda y obtener la derivada tercera: \\[\\frac{d^3f}{dx^3} (x) = f^{\\prime\\prime\\prime}(x)\\] Y repetirlo tantas veces como la función lo permita. A esto se le llama las derivadas sucesivas de \\(f(x)\\). Muchas funciones, por ejemplo los polinomios, las exponenciales o las funciones trigonométricas, son infinitamente derivables. A veces las derivadas sucesivas tienen una interpretación física. Ya vimos que la velocidad es al derivada de la posición: \\(v(t) = s^{\\prime}(t)\\). Como la aceleración es la derivada de la velocidad, entonces es la derivada segunda de la posición: \\(a(t) = s^{\\prime\\prime}(t)\\). "],
["utilidad-del-concepto-de-derivada.html", "Capítulo 10 Utilidad del concepto de derivada 10.1 Curvas infinitamente derivables 10.2 Crecimiento 10.3 Concavidad y convexidad 10.4 Máximos y mínimos 10.5 Dibujo de gráficas 10.6 Polinomios de Taylor", " Capítulo 10 Utilidad del concepto de derivada El concepto de derivada no es un concepto puramente teórico y que sirve para calcular tangentes a curvas, sino que tiene una utilidad directa para muchos problemas. En este capítuo veremos algunos ejemplos. 10.1 Curvas infinitamente derivables 10.1.1 Curvas de carretera Estamos diseñando la curva de una carretera. Queremos que tenga un trazado que los coches puedan seguir a la velocidad estipulada para este tramo. Esto significa que la curva debe ser suficientemente abierta, pero también significa que debe ser infinitamente derivable. Veamos por qué. Empezamos con los dos tramos de recta que queremos unir con la curva: La dos rectas y la curva van a formar una función y queremos saber qué características debe tener esta función. La primera exigencia es que haya carretera en todo el tramo. Es decir, exigimos que la función sea continua. Podríamos prolongar las dos rectas hasta que se encuentren: El problema es que ningún coche puede seguir este trazado, pues exige que en el punto de unión cambie de dirección instantáneamente. La dirección del coche viene dada por la tengente a la curva, luego este cambio instantáneo de dirección en el punto de unión equivale a decir que la función no es derivable en ese punto. Luego ya tenemos una segunda característica: la función debe ser derivable en todos los puntos. La siguiente solución que se nos ocurre es unir las rectas mediante un círculo. Si elegimos el círculo con el radio adecuado para que el coche pueda circular a la velocidad establecida y hacemos la unión con las rectas de manera que éstas sean tangentes a él, entonces aseguramos que es derivable en todos los puntos: Pero un coche tampoco puede seguir este trazado. El motivo es el siguiente. En las rectas las ruedas delanteras deben ir paralelas al eje del coche; pero en la curva, que es un círculo, las ruedas deben formar un cierto ángulo \\(\\alpha\\) con el eje del coche. Una vez en la curva no hay que mover el volante, pues con un ángulo constante en las ruedas el coche traza un círculo, pero en el punto de unión de la recta con el círculo hay que cambiar el ángulo de las ruedas de forma instantánea, y esto es físicamente imposible. Desde el punto de vista de la derivabilidad, la derivada segunda de una recta es 0, pero la derivada segunda de un tramo de círculo es una constante. Luego en los puntos de unión de la recta con el círculo tenemos derivada primera, pero no tenemos derivada segunda. Vemos que la derivada segunda está relacionada con el ángulo que forman las ruedas con el eje del coche. Como ha de ser posible girar el volante con suavidad, debemos exigir que la funcion tenga derivada segunda en todos los puntos. Y podríamos seguir con este análisis y llegar a la aconclusión que la función debe tener derivada tercera en todos los puntos, y derivada cuarta, y quinta, etc. Si no es infinitamente derivable, es físicamente imposible que el coche pueda seguir exactamente el trazado de la carretera. Los ingenieros que diseñan carreteras hacen algo parecido a lo que hemos hecho nosostros: parten de dos rectas, una sección de círculo de radio adecuado para la parte central y después unen el círculo con las rectas mediante una curva llamada clotoide, que es infinitamente derivable y permite una transición que el coche puede seguir. 10.1.2 Levas Una manera habitual de realizar un movimiento repetido de una pieza es mediante una leva. Un ejemplo típico es el accionamiento de las válvulas de un motor. Las levas están montadas sobre un eje, y al girar empuja un seguidor que hace mover la válvula o el mecanismo que sea. Este accionamiento debe ser suave, sobre todo si la leva ha de girar rápido. Por ejemplo en un motor de coche el eje de la leva debe poder girar a 3000 rpm o 4000 rpm. Por argumentos similares al caso de las curvas de carretera se puede concluir que la función del perfil de la leva debe ser infinitamente derivable, pues si no, a velocidades elevadas habría vibraciones indeseadas que dañarían el mecanismo. Pero no todas las levas son así. Hay algunas levas que están diseñadas para ir a poca velocidad y no importa que el mecanismo salte. Incluso están los mecanismos de carraca, que no son siquiera continuas, pues están diseñadas para poder girar en sólo una dirección: En ninguno de los dos sentidos puede el seguidor seguir el perfil de la leva, pero en una dirección simplemente salta, lo que a bajas velocidades no es ningún problema, y en el otro, bloquea al eje impidiendo el movimiento. En resumen, la función de la leva y la velocidad a la que debe ir, exige que los perfiles de las levas sean funciones con ciertas características de continuidad y derivabilidad. 10.2 Crecimiento Vimos que la derivada nos indica la pendiente de una curva. Si la pendiente es positiva, eso quiere decir que la curva crece, si es negativa, quiere decir que decrece. Además, el valor de la derivada nos indica lo rçapido o lento que una curva crece (o decrece): cuanto mayor sea el valor absoluto de la derivada, más rápidamente varía. Por ejemplo, supongamos la función \\(f(x) = x^3+3x^2-x-3\\). Digamos que esta función nos describe el valor (en Pa) de la presión en un cierto circuito hidráulico. Es un polinomio, luego sabemos que es una función continua. Si queremos saber dónde es positiva y dónde es negativa la presión, hemos de saber dónde es positiva y dónde es negativa la función. Igualamos la función a 0: \\[x^3+3x^2-x-3 = 0.\\] Es una ecuación de tercer grado, no es inmediato pero se pueden calcular las raíces (y en todo caso sabemos hacerlo numéricamente, aplicando el teorema de Bolzano, como vimos en el apartado 7.4). Las raíces de esta función están en los puntos \\(x = -3\\), \\(x = -1\\) y \\(x = 1\\). Es fácil ver que \\(\\lim_{x \\to \\infty} x^3+3x^2-x-3 = \\infty\\), luego la función es positiva para \\(x &gt; 1\\), es negativa para \\(-1 &lt; x &lt; 1\\), otra vez positiva para \\(-3 &lt; x &lt; -1\\) y negativa para \\(x &lt; -3\\). ¿Pero dónde es creciente y dónde es decreciente? Para ello hemos de ver dónde es positiva y negativa la derivada de la función. Derivamos y obtenemos \\[f^{\\prime}(x) = 3x^2 + 6x -1.\\] La función será creciente allá dónde la derivada sea positiva. Otra vez, es un polinomio, luego es continua y hemos de hallar sus raíces: \\[3x^2 + 6x -1 = 0.\\] Las raíces son \\(x = \\frac{-13}{6}\\) y \\(x = \\frac{1}{6}\\). Luego la función es creciente para \\(x &gt; \\frac{1}{6}\\), decreciente para \\(\\frac{-13}{6} &lt; x &lt; \\frac{1}{6}\\) y otra vez creciente para \\(x &lt; \\frac{-13}{6}\\). Queremos saber dónde el ritmo de decrecimiento es menor y cuánto vale. En general habría que hacer un análisis de la función derivada, pero en este caso es simple: sabemos que la derivada es una parábola, luego el punto donde el decrecimiento es máximo, es decir dónde la derivada es minima, es en el punto medio entre las raíces, es decir en \\[x = \\frac{\\frac{-13}{6} - \\frac{1}{6}}{2} = -\\frac{7}{6}.\\] Para saber cuánto varía la presión en este punto, calculamos el valor de la derivada en \\(x = -\\frac{7}{6}\\) y tenemos que la presión cae en ese punto del circuito a un ritmo de \\(-3.92\\) Pa/m. 10.3 Concavidad y convexidad Ya hemos visto que la velocidad es la derivada de la posición. Pero la velocidad misma puede crecer o decrecer: si crece decimos que tenemos una aceleración positiva, y si decrece, que tenemos una aceleración negativa. Desde el punto de vista de las derivadas, la aceleración es positiva si la derivada segunda de la posición es positiva y negativa, si es negativa. Esto que, por experiencia, conocemos bien de posiciones, velocidades y aceleraciones, lo podemos extender a cualquier función y cualquier curva. Tenemos una curva y calculamos su pendiente en diferentes puntos. Estamos “acelerando” si la pendiente es cada vez más positiva (o menos negativa). En este caso decimos que la curva es convexa. Si en cambio tenemos una curva en la que las pendientes son cada vez más negativas (o menos positivas) tenemos una curva que llamamos cóncava. Nota. Los nombres de cóncava y convexa son bastante confusos: uno nunca se acuerda de cuál es cuál. Además los he visto usados al revés, llamando cóncava a lo que aquí llamamos convexa y viceversa. También los he visto llamados “cóncava para arriba” y “cóncava para abajo”. En casos confusos como es este, el nombre es menos importante que el concepto. Cómo calcular la concavidad o convexidad de una curva se deduce fácilmente de la definición: si es convexa va “acelerando”, es decir, que la derivada primera es cada vez mayor, lo que quiere decir que la derivada segunda es positiva; si es cóncava va “decelerando”, luego la derivada primera es cada vez menor y la derivada segunda es negativa. En resumen, dada una función \\(f(x)\\), si \\(f^{\\prime\\prime}(x) &gt; 0\\) en una región, entonces decimos que la función es convexa en esa región. Si en cambio \\(f^{\\prime\\prime}(x) &lt; 0\\) en una región, decimos que \\(f(x)\\) es cóncava en esa región. Una función puede ser cóncava en unas regiones y convexa en otras. Fijémonos en la gráfica de la función \\(f(x) = 0.05(x^3 - 21x -20)\\): Claramente es cóncava en la parte izquierda y convexa en la parte derecha. En algún punto alrededor de \\(x = 0\\) pasa de cóncava a convexa. Ese punto se llama un punto de inflexión. Es algo que estasw muy acostumbrado a notar. Si estás trazando curvas enlazadas en un coche, moto o bicicleta, hay un punto en el que pasas de estar en una curva a izquierdas a una a derechas: ese es el punto de inflexión. Calcular el punto de inflexión es fácil: si es el punto en el que se pasa de convexa a cóncava, o lo que es lo mismo, de \\(f^{\\prime\\prime}(x) &gt; 0\\) a \\(f^{\\prime\\prime}(x) &lt; 0\\) (o viceversa), debe ser el punto donde \\(f^{\\prime\\prime}(x) = 0\\). Vamos a practicar estos conceptos Ejemplo 10.1 Calcula las regiones de concavidad y convexidad de la función \\(f(x) = 0.05(x^3 - 21x -20)\\). Empezamos por calcular la derivada segunda: \\[\\begin{align} f^{\\prime}(x) &amp;= 0.05(3x^2 -21)\\\\ f^{\\prime\\prime}(x) &amp;= 0.05(6x) = 0.3 x \\end{align}\\] Vemos que \\(f^{\\prime\\prime}(x)\\) es positiva para \\(x &gt; 0\\) y negativa para \\(x &lt; 0\\), luego la función es convexa para \\(x &gt; 0\\) y cóncava para \\(x &lt; 0\\) y tiene un punto de inflexión en \\(x = 0\\). 10.4 Máximos y mínimos Hay un dicho mallorquín que dices “Entre poc i massa, sa mesura passa” (“Entre poco y demasiado pasa la buena medida”). En otros idiomas hay dichos similares. Puede haber demaisado de algo y puede haber demasiaso poco de ese algo y lo que buscamos es la cántidad óptima de ese algo. Una de la utilidades mayores de las derivadas es poder calcular estos valors óptimos. Un ingeniero, al diseñar un producto, constantementese hace preguntas del estilo ¿cuál es el valor que minimiza el coste?¿cuál es la forma que maximiza su rigidez?¿cuál es el valor que minimiza las emisiones?¿Cuál es el valor que maximiza la satisfacción de los usuarios? Gracias a las derivadas podemos calcular estos valores óptimos. No es difícil ver que en un máximo la derivada debe ser 0. Tenemos una función que va creciendo, creciendo, hasta que en algún momento deja de crecer y empieza a decrecer. En ese momento es cuando es máximo. Como crecer quiere decir que la derivada es positiva, y decrecer quiere decir que la derivada es negativa, entonces es máximo en el punto donde la derivada es 0. Y análogamente con los mínimos: va decreciendo (derivada negativa) hasta que empieza a crecer (derivada positiva), luego en el mínimo la derivada es 0. Esto se ve muy bien gráficamente: Debe notarse que hemos mostrado que si hay un máximo o mínimo local, podemos asegurar que la derivada es 0, es decir, que la pendiente es horizontal. Pero puede ser que la derivada sea 0 y no tengamos un máximo o mínimo local, como se ve en la siguiente gráfica: En este caso la función crece, para de crecer un instante, y después sigue creciendo, sin decrecer en ningún momento. Podemos observar que lo que ha cambiado es la concavidad y convexidad de la curva. Tenemos un punto de inflexión de pendiente horizontal. 10.4.1 Cálculo de máximos y mínimos De esta discusión es fácil deducir cómo calcular, a partir de las derivadas de una función, si una función \\(f(x)\\) tiene un máximo o mínimo local. Para empezar, la derivada \\(f^\\prime (x)\\) debe ser 0. Por lo tanto hemos de derivar la función y buscar las raíces de \\(f^\\prime (x)\\). Digamos que en el punto \\(a\\) la derivada es 0, es decir \\(f^\\prime (a)\\). Eso quiere decir que en este punto o tenemos un máximo o un mínimo o un punto de inflexión de pendiente horizontal. ¿Cómo sabemos cuál de los tres? Para ello hemos de mirar la derivada segunda \\(f^{\\prime\\prime} (x)\\). Si tenemos un máximo, la función es cóncava en ese punto, luego ha de pasar que \\(f^{\\prime\\prime} (a) &lt; 0\\); si es un mínimo, la función debe ser convexa, luego ha de pasar que \\(f^{\\prime\\prime} (a) &gt; 0\\); y ya sabemos que si es un punto de inflexión ha de pasar que \\(f^{\\prime\\prime} (a) = 0\\). Esto se puede resumir en el siguiente algoritmo: Algoritmo para hallar máximo y mínimos locales de \\(f(x)\\). Calcula \\(f^{\\prime} (x)\\) y \\(f^{\\prime\\prime} (x)\\) Halla las raíces de \\(f^{\\prime} (x)\\) Para cada de las raíces \\(r_i\\) de \\(f^{\\prime} (x)\\): Calcula \\(f^{\\prime\\prime} (r_i)\\) Si \\(f^{\\prime\\prime} (r_i) &lt; 0\\) es un máximo; si \\(f^{\\prime\\prime} (r_i) &gt; 0\\) es un mínimo; si \\(f^{\\prime\\prime} (r_i) = 0\\) es un punto de inflexión de pendiente horizontal Practiquemos estas ideas. 10.4.2 Un ejemplo Ejercicio 10.1 Calcula los máximos y mínimos de la función \\(f(x) = x^3 -5x^2 + x - 4\\). Apliquemos el algoritmo. Empecemos por calcular las dos primeras derivadas: \\[\\begin{align} f^{\\prime} (x) &amp;= 3x^2 -10x +1\\\\ f^{\\prime\\prime} (x) &amp;= 6x - 10 \\end{align}\\] Hallemos las raíces de \\(f^{\\prime} (x)\\). Es una ecuación de segundo grado y las raíces son \\(r_1 = 0.103\\) y \\(r_2 = 3.230\\). Calculemos el valor de la derivada segunda para cada una de las raíces. Para la primera, \\(f^{\\prime\\prime} (0.103) = -9.38 &lt; 0\\), luego es un máximo, y para la segunda, \\(f^{\\prime\\prime} (3.230) = 9.38 &gt; 0\\), luego es un mínimo. Resultado: La función \\(f(x) = x^3 -5x^2 + x - 4\\) tiene un máximo en \\(x = 0.103\\) y un mínimo en \\(x = 3.230\\). 10.4.3 Otro ejemplo Ejercicio 10.2 Supongamos un recipiente, por ejemplo un barril cilíndrico. Inicialmente está vacío y el centro de gravedad está a media altura. Empezamos a llenarlo de algún líquido. El centro de gravedad inicialmente irá bajando a medida que añadamos líquido, pero cuando esté lleno, el centro de gravedad volverá a estar a media altura. esto quiere decir que en algún momento intermedio el centro de gravedad está a una altura mínima ¿Cuánto líquido hay que añadir para que el centro de gravedad esté lo más bajo posible? Hay muchos parámetros en este problema: el peso y la altura del barril, la superficie de la base del barril, la densidad del líquido, la altura del líquido en el barril… Si los usamos todos, la manipulación algebraica necesaria para resolver el problema se complica mucho. Vamos a simplificarlo. Para empezar, hacemos que el peso del barril sea 1, es decir, usamos el peso del barril como unidad de peso; hacemos lo mismo con la altura del barril: es también 1; la altura del líquido en el barril es \\(h\\), donde \\(h\\) toma un valor entre 0 (está vacío) y 1 (está lleno); el peso del líquido cuando el barril está lleno es \\(p\\): cuando está lleno, el líquido pesa \\(p\\) veces el peso del barril. Este parámetro \\(p\\) es un indicador de la densidad del líquido: cuánto mayor es \\(p\\), mayor es su densidad. Si \\(p &lt; 1\\) quiere decir que cuando está lleno, el líquido contenido pesa menos que el barril; si \\(p = 1\\), quiere decir que con el barril lleno, el líquido pesa lo mismo que el barril; si \\(p &gt; 1\\) entonces, cuando lleno, el líquido pesa más que el barril. Tenemos el barril, con líquido hasta una altura \\(h\\). El centro de gravedad del barril está a una altura 1/2 y el peso del barril es 1; el centro de gravedad del líquido está a una altura \\(h/2\\) y el peso del líquido es \\(p\\cdot h\\). El centro de gravedad del conjunto, \\(C(h)\\), la podemos calcular como la media ponderada de los dos centros de gravedad, con las proprociones de los dos pesos como ponderación: \\[C(h) = \\frac{1}{1 + ph} \\frac{1}{2} + \\frac{ph}{1 + ph} \\frac{h}{2} = \\frac{1 + ph^2}{2 + 2ph}. \\] Ante un problema algo largo y complicado, es conveniente ir haciendo comprobaciones intermedias para eliminar posibles errores. Yo sólo indicaré cuçáles son las comprobaciones que debéis hacer. la primera es asegurarnos que para \\(h = 0\\) y para \\(h = 1\\), el valor de \\(C(h)\\) es 1/2. Para hallar el mínimo, hemos de derivar \\(C(h)\\) y ver dónde es 0: \\[C^{\\prime}(h) = \\frac{-2p + 2p^2h^2 + 4ph}{(2 + 2ph)^2} = 0 \\] Como el denominador nunca es 0, entonces basta igualar a 0 el numerador: \\[-2p + 2p^2h^2 + 4ph = 0\\] lo que arreglando un poco queda \\[2ph^2 + 4h - 2 = 0\\] Esta es una ecuación de segundo grado que podemos resolver. Tiene dos soluciones, una para \\(p\\) negativo, que no tiene sentido en este contexto, y la otra es \\[ h_\\min = \\frac{\\sqrt{p + 1} - 1}{p}.\\] Para comprobar que no nos hemos equivocado al resolver la ecuación, lo que debemos hacer es meter este valor en la ecuación y comprobar que efectivamente da 0. Hacerlo algebraicamente es largo, pero se pueden hacer dos o tres comprobaciones para valores convenientes de \\(p\\), por ejemplo \\(p = 3\\) y \\(p = 8\\). Deberíamos calcular la derivada segunda y ver si es positiva, pero por las características físicas del problema sabemos que ha de ser un mínimo, que no puede ser un máximo. Luego nos ahorramos el trabajo. Vemos que cuanta mayor es la densidad del líquido, menos hemos de meter para bajar al mínimo el centro de gravedad. Para hallar el valor de este centro de gravedad mínimo, introducimos el valor de \\(h_\\min\\) en la expresión de \\(C(h)\\). Tras un poco de álgebra queda \\[C_\\min (p) = \\frac{1 + p -\\sqrt{p+1}}{p\\sqrt{p+1}}.\\] Y podemos hacer otra comprobación de lo razonable de la respuesta: para \\(p = 0\\) (el líquido que hemos metido no pesa nada), el valor mínimo del centro de gravedad debe ser 1/2 (lógico, si el líquido no pesa nada, el centro de gravedad no se mueve de su posición de 1/2 mientras llenamos). Esto exige calcular el límite cuando \\(p\\) tiende a 0, que es de tipo \\(\\frac{0}{0}\\). **Resultado: Hemos calculado que para que el centro de gravedad esté lo más bajo posible, hemos de meter líquido hasta una altura de \\[ h_\\min = \\frac{\\sqrt{p + 1} - 1}{p}.\\] El valor del centro de gravedad mínimo es \\[C_\\min (p) = \\frac{1 + p -\\sqrt{p+1}}{p\\sqrt{p+1}}.\\] 10.5 Dibujo de gráficas Una buena formna de practicar todo lo visto de funciones es aprender a dibujar su gráfica. Uno se puede preguntar para qué analizar y dibujar gráficas de funciones cuando esto te lo hace el ordenador, o incluso la calculadora. Pero es lo mismo que preguntarse para qué conocer una persona si se puede ver una foto de ella. Si uno analiza y dibuja la gráfica de una función aprende mucho más de lla, la entiende mucho mejor, que si simplemente la escribe en el ordenador y mira la curva que sale. Y si uno repite este ejercicio a menudo, se crea una intuición de las funciones –de si es “buena” o “mala”, de sus peligros y lugares donde tener cuidado– que es muy valiosa. Para analizar y dibujar la gráfica de una función vamos a estudiar las siguientes características: Dominio: dónde existe y no existe; Continuidad, derivabilidad y extremos: dónde es continua, dónde es derivable, qué hace la función cuando tiende a infinito Signo: dónde es positiva y dónde negativa; Cruce con los ejes: en qué puntos cruza con los ejes de abscisas y ordenadas; Asíntotas: tanto verticales como horizontales Crecimiento: dónde crece o decrece; Concavidad: dónde es cóncava, dónde convexa, dónde esán los puntos de inflexión; Máximos y minimos:_ qué máximos y minimos locales tiene y donde están situadas; Hagamos dos ejemplos: Ejemplo 10.2 Dibuja la gráfica de la función \\[y = \\frac{\\log(x)}{x}\\] Dominio: El numerador sólo existe si \\(x&gt;0\\) y para el dominio del numerador el denominador siempre es distinto de 0, luego el dominio de \\(y\\) es \\(x &gt; 0\\). Continuidad, derivabilidad y extremos: Tanto el numerador como el denoinador son continuos en todo su dominio, luego la función es continua. Las derivadas son \\[\\begin{align} y^\\prime &amp;= \\frac{1 - \\log(x)}{x^2}\\\\ y^{\\prime\\prime} &amp;= \\frac{2\\log(x) - 3}{x^3} \\end{align}\\] Ambas derivadas existen en todos los puntos del dominio de la función. Como \\(x\\) domina sobre \\(\\log(x)\\), el límite cuando tiende a \\(\\infty\\) es 0. Y el límte cuando \\(x\\) tiende a 0 es \\(\\-infty\\). Signo: El denominador es positivo en todo el dominio, el numerador es positivo si \\(x &gt; 1\\). Luego \\(y\\) es positivo si \\(x &gt; 1\\). Cruce con los ejes: Nunca cruza con el eje \\(Y\\). Cruza con el eje \\(X\\) cuando \\(\\log(x) = 0\\), es decir, en \\(x = 1\\). Asíntotas: Ya hemos visto que \\(\\lim_{x \\to \\infty} = 0\\), luego \\(y = 0\\) es una asíntota horizontal. También hemos visto que \\(\\lim_{x \\to 0^+} = -\\infty\\), luego hay una asíntota vertical en \\(x = 0\\). Crecimiento: Hemos de analizar el signo de \\[y^\\prime = \\frac{1 - \\log(x)}{x^2}\\] El denominador es siempre positivo. El numerador es positivo si \\(\\log(x) &lt; 1\\), luego la función crece (la derivada es positiva) si \\(x &lt; e\\) y decrece si \\(x &gt; e\\). La derivada es 0 en \\(x = e\\). Concavidad: Hemos de analizar el signo de \\[y^{\\prime\\prime} = \\frac{2\\log(x) - 3}{x^3}\\] El denominador es positivo en todo el dominio. El numerador es positivo si \\(2\\log(x) - 3 &gt; 0\\), es decir si \\(log(x) &gt; 3/2\\). Esto pasa si \\(x &gt; e^{3/2} = 4.48\\). Luego es cóncava para \\(x&lt; e^{3/2}\\) y convexa si \\(x &gt; e^{3/2}\\). Hay un punto de inflexión en \\(x = e^{3/2}\\). En ese punto la función vale \\[\\frac{3/2}{e^{3/2}} = 0.335\\] Máximos y minimos: Ya hemos visto que la derivada es 0 en \\(x = e\\). También sabemos que en este punto la función es cóncava, luego es un máximo. En ese punto la función vale \\[y = \\frac{1}{e} = 0.367\\] Y con esta información ya podemos dibujar la función: Ahora hagamos un ejemplo con una función algo más compleja. Ejemplo 10.3 Dibuja la gráfica de la función \\[y = \\frac{x}{\\sqrt[3]{x^2 -1}}\\] Dominio: Es una división de polinomios, luego existe en tods los puntos donde el denominador no sea 0. El dominio es toda la recta real excepto los puntos \\(x = \\pm 1\\). Continuidad, derivabilidad y extremos: Al ser una división de polinomios, es continua en todos los puntos donde el denominador no es 0. En \\(x = \\pm 1\\) los límites tiende a \\(+\\infty\\) por un lado y \\(-\\infty\\) por el otro, luego presenta una discontinuidad no evitable en estos puntos. Calculemos las derivadas primera y segunda. Nota: Quizá es más fácil derivar la función si la escribimos como \\(y = x(x^2 -1)^{-1/3}\\). Las derivadas son \\[\\begin{align} y^\\prime &amp;= \\frac{x^2 -3}{3\\sqrt[3]{(x^2 -1)^4}}\\\\ y^{\\prime\\prime} &amp;= -\\frac{2x(x^2 -9)}{9\\sqrt[3]{(x^2 -1)^7}} \\end{align}\\] Ambas derivadas existen en todos los puntos excepto \\(x = \\pm 1\\). Es inmediato ver que el límite cuando \\(x\\) tiende a \\(\\infty\\) es \\(\\infty\\) y el límite cuando \\(x\\) tiende a \\(-\\infty\\) es \\(-\\infty\\). Signo: El numerador es positivo si \\(x&gt;0\\) y negativo si \\(x &lt; 0\\). El denominador es positivo si \\(x^2 - 1 &gt;0\\), es decir si \\(x &gt; |1|\\), y negativo si \\(x^2 - 1 &lt;0\\), es decir si \\(x &lt; |1|\\). Juntando todo: \\(x &lt; -1\\) \\(-1 &lt; x &lt; 0\\) \\(0 &lt; x &lt; 1\\) \\(x &gt; 1\\) numerador \\(-\\) \\(-\\) \\(+\\) \\(+\\) denominador \\(+\\) \\(-\\) \\(-\\) \\(+\\) \\(y\\) \\(-\\) \\(+\\) \\(-\\) \\(+\\) Cruce con los ejes: El único lugar donde el numerador es 0 es \\(x = 0\\). Es el único cruce con ambos ejes. Asíntotas: Ya hemos visto que los límites en el infinito son infinitos, luego no tiene asíntotas horizontales. El denominador se vuelve 0 en \\(x = \\pm 1\\), y en esos puntos el numerador no es cero, luego tenemos asíntotas verticales en \\(x = \\pm 1\\). Estrictamente, deberíamos calcular los límites laterales en esos puntos, pero como ya sabemos el signo, no es necesario: Tiende a \\(-\\infty\\) cuando se acerca a \\(x = -1\\) por la izquierda y a \\(+\\infty\\) cuando se acerca por la derecha; y tiende a \\(-\\infty\\) cuando se acerca a \\(x = 1\\) por la izquierda y a \\(+\\infty\\) cuando se acerca por la derecha. Crecimiento: Hemos de analizar el signo de \\[y^\\prime = \\frac{x^2 -3}{3\\sqrt[3]{(x^2 -1)^4}}\\] El denominador es siempre positivo, luego basta mirar el signo del numerador, \\(x^2 - 3\\). Es inmediato ver que es positivo para \\(x &lt; -\\sqrt{3}\\), es negativo para \\(-\\sqrt{3} &lt; x &lt; \\sqrt{3}\\) y es otra vez positivo para \\(x &gt; \\sqrt{3}\\). Y va a ser 0 para \\(x = \\pm\\sqrt{3}\\). Concavidad: Hemos de analizar el signo de \\[y^{\\prime\\prime} = -\\frac{2x(x^2 -9)}{9\\sqrt[3]{(x^2 -1)^7}}\\] El denominador en este caso puede ser positivo o negativo. Podemos crear un cuadro similar al que hemos hecho antes. Hemos de tener cuidado con el signo menos que precede a todo. En este caso los puntos de interés son \\(x = 0\\), \\(x = \\pm 1\\) y \\(x = \\pm 3\\). \\(x &lt; -3\\) \\(-3 &lt; x &lt; -1\\) \\(-1 &lt; x &lt; 0\\) \\(0 &lt; x &lt; 1\\) \\(1 &lt; x &gt; 3\\) \\(x &gt; 3\\) numerador \\(-\\) \\(+\\) \\(+\\) \\(-\\) \\(-\\) \\(+\\) denominador \\(+\\) \\(+\\) \\(-\\) \\(-\\) \\(+\\) \\(+\\) \\(y^{\\prime\\prime}\\) \\(+\\) \\(-\\) \\(+\\) \\(-\\) \\(+\\) \\(-\\) Hay puntos de inflexión en los puntos donde el numerador es 0: \\(x = 0\\) y \\(x = \\pm 3\\). En estos puntos el valor de la función es \\[ y(-3) = -1.5; \\qquad y(0) = 0; \\qquad y(3) = 1.5\\] Máximos y minimos: Ya hemos visto que la derivada es 0 en \\(x = \\pm\\sqrt{3}\\). Del cuadro anterior, vemos que \\(y^{\\prime\\prime}(-\\sqrt{3}) &lt;0\\) y que \\(y^{\\prime\\prime}(\\sqrt{3}) &gt;0\\). Luego tenemos un máximo en \\(x = -\\sqrt{3}\\) y un mínimo en \\(x = \\sqrt{3}\\). El valor de la función en estos puntos es \\[y(-\\sqrt{3}) = -1.375; \\qquad y(\\sqrt{3}) = 1.375\\] Y con esta información ya podemos dibujar la función: 10.6 Polinomios de Taylor Los polinomios son funciones muy manejables: son fáciles de integrar y derivar, fáciles de manipular algebraicamente, etc. Hay otras funciones, como por ejemplo las trigonométricas y logarítmicas, que son mucho menos manejables. Es por eso que nos gustaría a menudo poder pasar de una función poco manejable a una aproximación polinómica: si la aproximación es suficientemente buena, perdemos un poco en precisión, pero ganamos mucho en manejabilidad. Los polinomios de Taylor nos permiten encontrar el polinomio del grado que queramos que mejor se aproxima a una función en las inmediaciones de un punto. Veamos cómo se calculan, empezando con dos ejemplos. 10.6.1 Ejemplo 1: \\(f(x) = \\sin(x)\\), en las inmediaciones de \\(x = 0\\) La función de nuestro primer ejemplo es \\(f(x) = \\sin(x)\\) y queremos el polinomio que mejor se aproxima a esta función en las inmediaciones de \\(x = 0\\). Cómo no sabemos de qué grado nos interesa el polinomio, vamos a encontrar cuatro aproximaciones con 4 polinomios: uno de grado 0, \\(P_0(x)\\); uno de grado 1, \\(P_1(x)\\); uno de grado 2, \\(P_2(x)\\); y uno de grado 3, \\(P_3(x)\\). Empecemos con \\(P_0(x) = c_0\\), una constante. La mejor aproximación que podemos hacer es que esa constante \\(c_0\\) sea el valor de la función en \\(x = 0\\), pues si no ni siquiera estamos aqcertanto el valor en el punto. Como \\(\\sin(0) = 0\\), llegamos a la conclusión que el mejor polinomio de grado 0 que mejor aproxima nuestra fución es \\(P_0(x) = 0\\). Sigamos con \\(P_1(x) = c_0 + c_1 x\\), una recta. Queremos de este polinomio, por los mismos motivos de antes, que en el punto \\(x = 0\\) valga lo mismo que nuestra función \\(\\sin(x)\\), es decir que \\(P_1(0) = 0\\). También queremos que la recta crezca o decrezca en \\(x = 0\\) al mismo ritmo que \\(\\sin(x)\\), pues si no, el polinomio se alejaría de la función demasiado raápidamente. Luego queremos que \\(P^\\prime_1(0) = \\sin^\\prime(0) = \\cos(0) = 1\\). Esto da lugar a ese sistema de ecuaciones: \\[\\begin{align} P_1(0) &amp;= c_0 + c_1\\cdot 0 = c_0 = 0\\\\ P^\\prime_1(0) &amp;= c_1 = 1 \\end{align}\\] Luego el polinomio de grado 1 que buscamos es \\(P_1(x) = x\\). Vayamos con el polinomio de grado 2, \\(P_2(x) = c_0 + c_1 x + c_2 x^2\\), que es una parábola. Por los mimos motivos de antes, queremos que \\(P_2(0) = 0\\) y que \\(P_2^\\prime(0) = 1\\). Ahora también queremos que la concavidad o convexidad de \\(P_2(x)\\) en \\(x = 0\\) sea la misma que la de \\(\\sin(x)\\), para que el polinomio no se aleje de \\(\\sin(x)\\) más rápidamente de lo necesario. Sabemos que eso es la derivada segunda: \\(\\sin^{\\prime\\prime}(0) = -\\sin(0) = 0\\). Por lo tanto queremos que \\(P_2^{\\prime\\prime}(0) = 0\\). Esto da lugar al sistema de ecuaciones \\[\\begin{align} P_2(0) &amp;= c_0 + c_1\\cdot 0 + c_2\\cdot 0 = c_0 = 0\\\\ P^\\prime_2(0) &amp;= c_1 + 2c_2 x = c_1 + 2c_2 \\cdot 0 = c_1 = 1\\\\ P_2^{\\prime\\prime}(0) &amp;= 2c_2 = 0 \\end{align}\\] Y el polinomio de grado 2 que mejor aproxima \\(\\sin(x)\\) en las cercaniás de \\(x = 0\\) es \\(P_2(x) = x\\). Para terminar, estudiemos el polinomio de grado 3, \\(P_3(x) = c_0 + c_1 x + c_2 x^2 + c_3x^3\\). Ya sabemos que queremos que \\(P_3(0) = 0\\), \\(P^\\prime_3(0) = 1\\) y P_3^{}(0) = 0$. Ahora también queremos que la derivada tercera de nuestro polinomio sea la misma que la de \\(\\sin(x)\\) en \\(x = 0\\). No tenemos nombre para esto, pero es fácil ver que debe ser así. la derivada tercera de \\(\\sin(x)\\) en \\(x = 0\\) es \\(-1\\). Esto da lugar al sistema de ecuaciones: \\[\\begin{align} P_3(0) &amp;= c_0 + c_1\\cdot 0 + c_2\\cdot 0^2 + c_3\\cdot 0^3= c_0 = 0\\\\ P^\\prime_3(0) &amp;= c_1 + 2c_2 0 + 3c_3 0^2= c_1 = 1\\\\ P_3^{\\prime\\prime}(0) &amp;= 2c_2 + 6c_3\\cdot 0 = 2c_2 =0\\\\ P_3^{\\prime\\prime\\prime}(0) &amp;= 6c_3 = -1 \\end{align}\\] Y el polinomio de tercer grado que mejor se aproxima a \\(\\sin(x)\\) en las cercanías de \\(x = 0\\) es \\(P_3(x) = x - \\frac{1}{6}x^3\\). Conviene notar que al calcular un polinomio de grado superior, se conservan los coeficientes que ya teníamos: los coeficientes \\(c_0, c_1\\) y \\(c_2\\) de \\(P_2(x)\\) son los mismos que en \\(P_3(x)\\). No es casualidad. Si nos fijamos en el proceso seguido, vemos que tiene que ser así. Luego si ahora quisiéramos calcular \\(P_4(x)\\), no tenemos que calcular todos los coeficientes, sino sólo \\(c_4\\), igualando \\(P^{\\prime\\prime\\prime\\prime}(0)\\) con \\(\\sin^{\\prime\\prime\\prime\\prime}(0)\\). Vayamos con otro ejemplo. 10.6.2 Ejemplo 2: \\(f(x) = \\log(x)\\), en las inmediaciones de \\(x = 1\\) Empecemos con \\(P_0(x) = c_0\\), una constante. Sabemos que la mejor aproximación que podemos hacer es que esa constante \\(c_0\\) sea el valor de \\(\\log(x)\\) en \\(x = 1\\). Como \\(\\log(1) = 0\\), llegamos a la conclusión que el mejor polinomio de grado 0 que mejor aproxima nuestra fución es \\(P_0(x) = 0\\). Sigamos con \\(P_1(x) = c_0 + c_1 x\\). Queremos que \\(P(1) = 0\\) y que \\(P^\\prime(1) = \\log^\\prime(1) = 1\\). El sistema de ecuaciones que nos queda es: \\[\\begin{align} P_1(0) &amp;= c_0 + c_1\\cdot 1 = c_0 + c_1 = 0\\\\ P^\\prime_1(0) &amp;= c_1 = 1 \\end{align}\\] Resolviendo nos queda que \\(c_1 = 1\\) y \\(c_0 = -1\\). Pero ahora el coeficiente \\(c_0\\) no es el mismo que el de \\(P_0(x)\\). Esto es un enorme fastidio, pues significa que aunque conozca \\(P_n(x)\\), si quiero \\(P_{n+1}(x)\\) tengo que volver a empezar desde el principio. Si me fijo en por qué esto pasa ahora y no pasaba en el ejemplo anterior, vemos que es porque, al evaluar en \\(x=0\\) sólo uno de los coeficientes permanecía en cada ecuación, pues los demás al multiplicar por 0, desaparecían. Pero ahora, al evaluar en \\(x = 1\\), no desaparecen. Por suerte, esto lo podemos arreglar fácilmente. Ya que estamos aproximando la función alrededor de \\(x = 1\\), “centramos” nuestro polinomio en \\(x = 1\\): \\(P_1(x) = c_0 + c_1(x-1)\\), y así sólo uno de los coeficientes permanecerá en cada ecuación: \\[\\begin{align} P_1(0) &amp;= c_0 + c_1\\cdot (1 -1) = c_0 = 0\\\\ P^\\prime_1(0) &amp;= c_1 = 1 \\end{align}\\] Y el polinomio que mejor aproxima \\(\\log(x)\\) en los alrededores de \\(x = 1\\) es \\(P_1(x) = x-1\\). Nótese que es el mismo polinomio de antes, pero al escribirlo de esta manera, facilita el cálculo de los coeficientes. Calculemos ahora \\(P_2(x) = c_0 + c_1(x-1) + c_2(x-1)^2\\). Sabemos que \\(c_0 = 0\\) y \\(c_1 = 1\\). Hemos de calcular \\(c_2\\). Hemos de igualar las derivadas segundas. La derivada segunda del logaritmo es \\(\\frac{-1}{x^2}\\), y la del polinomio es \\(P_2(x)\\) es \\(2c_2\\). Evaluando en \\(x = 1\\): \\[\\frac{-1}{1^2} = -1 = 2c_2.\\] El polinomio queda \\(P_2(x) = (x-1) - \\frac{1}{2}(x-1)^2\\). Calculemos ahora \\(P_3(x) = c_0 + c_1(x-1) + c_2(x-1)^2 + c_3(x-1)^3\\). Sólo hemos de calcular \\(c_3\\). La derivada tercera del logaritmo es \\(\\frac{2}{x^3}\\) y la del polinomio es \\(6 c_3\\). Evaluando en \\(x = 1\\): \\[\\frac{2}{1^3} = 2 = 6c_3.\\] El polinomio queda \\[P_3(x) = (x-1) - \\frac{1}{2}(x-1)^2 + \\frac{1}{3}(x-1)^3.\\] 10.6.3 Forma general de los polinomios de Taylor Con lo que hemos aprendido de los ejemplos tenemos casi todo lo necesario para obtener la forma general del polinomio de Taylor de cualquier función. Sea \\(f(x)\\) y queremos hallar el polinomio de grado \\(n\\) que mejor aproxima a \\(f(x)\\) en las inmediaciones de \\(x = a\\). Hemos visto que nos conviene que el polinomio tenga la forma \\[ P_n(x) = c_0 + c_1(x-a) + c_2 (x-a)^2 + \\cdots + c_n (x-a)^n.\\] También hemos visto que para obtener los valores de los coeficientes hemos de igualar \\(P_n(a)\\) a \\(f(a)\\); \\(P^\\prime_n(a)\\) a \\(f^\\prime(a)\\); \\(P^{\\prime\\prime}_n(a)\\) a \\(f^{\\prime\\prime}(a)\\); y así hasta la derivada \\(n\\)-sima, \\(P^{(n)}_n(a) = f^{(n)}(a)\\). Además, de la primera ecuación, \\(P_n(a) = f(a)\\), obtendremos el valor de \\(c_0\\), de la ecuación \\(P^\\prime_n(a) = f^\\prime(a)\\), obtendremos el valor de \\(c_1\\) y así sucesivamente. El último detalle que nos falta es el siguiente: \\[\\frac{d^n}{dx^n}c_n(x-a)^n = n!\\,c_n \\] Sabiendo esto, es inmediato ver que la igualdad \\[P^{(n)}_n(a) = f^{(n)}(a)\\] se convierte en \\[n!\\,c_n = f^{(n)}(a).\\] De donde podemos obtener el valor de \\(c_n\\): \\[c_n = \\frac{1}{n!}f^{(n)}(a).\\] Y ya podemos obtener la forma general del polinomio de Taylor: \\[P_n(x) = f(a) + f^\\prime(a)(x-a) + \\frac{1}{2}f^{\\prime\\prime}(a) (x-a)^2 + \\cdots + \\frac{1}{n!}f^{(n)}(a) (x-a)^n.\\] 10.6.4 Hasta dónde llegar: Series de Taylor Si nos fijamos en las gráficas de los polinomios de Taylor de la función \\(\\sin(x)\\) en las cercanías de \\(x = 0\\), podemos observar que \\(P_1(x) = x\\) nos da una buena aproximación si estamos muy cerca de \\(x = 0\\), mientras que \\(P_3(x) = x - \\frac{1}{6}x^3\\) nos da una buana aproximación incluso si nos alejamos algo de \\(x = 0\\). Esto nos da la idea que, si cogemos suficientes términos, podemos obtener una buena aproximación incluso si estamos muy lejos de \\(x = 0\\). Y eso es cierto… a veces. Si cogemos infinitos términos el polinomio de Taylor se convierte en la serie de Taylor. Por ejemplo, la serie de Taylor de \\(\\sin(x)\\) cogiendo los valores en \\(x = 0\\) es \\[x - \\frac{1}{3!}x^3 + \\frac{1}{5!}x^5 - \\frac{1}{7!}x^7 + \\cdots\\] Esta serie converge para todo \\(x\\), y por lo tanto, puedo aproximar adecuadamente el \\(\\sin(x)\\) para cualquier valor de \\(x\\), por grande que sea, mediante un polinomio de Tylor de grado suficiente. Lo mismo pasa con el polinomio de Taylor de \\(e^x\\), tomado en \\(x = 0\\). Es \\[1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\cdots + \\frac{x^n}{n!} + \\cdots\\] También converge para todo valor de \\(x\\) y podemos aproximar con precisión suficiente la función \\(e^x\\), por grande que sea \\(x\\), si cojo una cantidad suficiente de términos. Pero eso no pasa para todas las series de Taylor. Si cogemos la serie del logaritmo, centrado en \\(x = 1\\): \\[(x-1) - \\frac{1}{2}(x-1)^2 + \\frac{1}{3}(x-1)^3- \\frac{1}{3}(x-1)^3\\ + \\cdots\\] Esta serie sólo converge para \\(0 &lt; x &lt; 2\\). Para \\(x &gt; 2\\), diverge (oscila). Luego puedo calcular \\(\\log(1.9)\\) con toda la precisión que yo quiera si cojo un número suficiente de términos, pero no puedo calcular con este polinomio el valor de \\(\\log(2.1)\\) por muchos términos que coja. Cada serie de Taylor tiene su radio de convergencia. Puedo calcular el valor de una función usando su polinomio de Taylor con tanta precisión como yo quiera, siempre que esté dentro del radio de convergencia. Si no, no puedo. No vamos a profundizar más en esta cuestión. Simplemente recordar que no simpre puedo aproximar un valor alejado del centro con un polinomio de Taylor a base de coger muchos términos. "],
["cálculo-de-primitivas.html", "Capítulo 11 Cálculo de primitivas 11.1 Regla de Barrow 11.2 Técnica 1: Cuadro de primitivas elementales 11.3 Técnica 2: Tres teoremas básicos 11.4 Técnica 3: Cambio de variable 11.5 Técnica 4: Integración por partes 11.6 Técnica 5: Integración de funciones racionales 11.7 Integrales impropias 11.8 Integración numérica", " Capítulo 11 Cálculo de primitivas En el apartado 8.8 definimos integral de la función \\(f(x)\\) como el área bajo la curva de esta función. Y vimos en el apartado 8.9 que si \\(F(x)\\) es la función del área bajo la curva desde un punto inicial hasta \\(x\\), entonces \\(F^\\prime(x) = f(x)\\). A esto lo llamamos el Teorema Fundamental del Cálculo. También vimos que la integral se puede usar para mucho más que para calcular areas. En nuestro ejemplo de partida lo usamos para calcular distancias recorridas apartir de la velocidad. Posiblemente el cálculo de areas es una utilidad menor. Las integrales se usan primordialmente para calcular energías, voltajes, masas, temperaturas, dinero, probabilidades… Cualquier cosa que podamos establecer como una suma de muchas (infinitas) cantidades pequeñas. El cálculo de áreas bajo la curva es la abstracción que usan las matemáticas de todos estos problemas más concretos: nos olvidamos de la energías, voltajes, etc, y nos concentramos en una función \\(f(x)\\) y su área. 11.1 Regla de Barrow Hay un primer problema que nos encontramos, que por suerte tiene una solución simple: hemos dicho que \\(F(x)\\) nos da el área dede una cierta posición inicial. ¿Qué posición inicial es esa? Porque para diferentes posiciones iniciales la función será diferente. Resolvamos este primer problema en un ejemplo concreto. Supongamos que nuestra función es una recta, por ejemplo \\(f(x) = x/3\\) y que nuestra posición inicial es \\(x = 0\\). El área a calcular es un triángulo, de base \\(x\\) y de altura \\(f(x) = x/3\\), luego la función, que llamaremos \\(F_0(x)\\), es el área del triángulo desde 0 hasta \\(x\\): \\[F(x) = \\frac{1}{2} x \\frac{x}{3} = \\frac{x^2}{6}\\] Nótese que, como debía pasar, \\(F_0^\\prime(x) = f(x)\\). Si nos interesa el área bajo la curva entre el punto \\(x = 0\\) y \\(x = 5\\), lo calculamos con facilidad: \\(F(5) = \\frac{5^2}{6} = 4.1667\\). pero digamos que no queremos en área entre \\(x = 0\\) y \\(x = 5\\), sino que queremos empezar en \\(x = 3\\), es decir, queremos el área entre \\(x = 3\\) y \\(x = 5\\). La solución es simple: el área entre \\(x = 3\\) y \\(x = 5\\) es el área entre \\(x = 0\\) y \\(x = 5\\) menos el área entre \\(x = 0\\) y \\(x = 3\\): Luego el área que nos interesa es \\[F(5) - F(3) = \\frac{5^2}{6} - \\frac{3^2}{6} = \\frac{16}{6} = 2.667\\] A esto se le llama la regla de Barrow: \\[\\int_a^b f(x)dx = F(b) - F(a) \\] Otra manera de resolver este problema sería crear una nueva función, que podemos llamar \\(F_3(x)\\), que calcula el área, pero empezando en \\(x=3\\). Esta función es \\[F_3(x) = F_0(x) - \\frac{9}{6} = \\frac{x^2}{6} - 1.5\\] Vemos que la derivada de \\(F_3(x)\\) también es \\(f(x)\\). Observamos que no hay una única función \\(F(x)\\) sino toda una familia de la forma \\(F(x) + C\\). A la función \\(F(x)\\) se le llama la primitiva de \\(f(x)\\) y a \\(C\\), la constante de integración. La forma de representar el cálculo de una primitiva es \\[\\int f(x)dx\\] sin límites superior e inferior en el símbolo de la integral. A esto se le llama también una integral indefinida y el resultado es una función. la primitiva. En cambio, si ponemos los límites de integración: \\[\\int_a^b f(x)dx\\] recibe el nombre de integral definida y el resultado es, en general, un número. Para calcular la derivada de una función \\(f(x)\\) teníamos que calcular un límite, lo cual es relativamente simple. Pero para calcular la integral de una función tenemos que calcular una suma (infinita)y esto, salvo casos muy simples, no los sabemos hacer. Por lo tnato lo que se hace es buscar una función \\(F(x)\\) tal que su derivada es \\(f(x)\\). Eso es a menudo posible, pero en general no es fácil. Por suerte hay algunas técnicas que no son excesivamente complicadas y que nos permitirá calcular la mayoría de las integrales que suelen aparecer en la práctica. El objetivo de este capítulo es dominar estas técnicas para así poder calcular con agilidad integrales simples y de complejidad media. 11.2 Técnica 1: Cuadro de primitivas elementales La primera técnica es el punto de partida de todas las demás. Es muy simple, pero aburrida y con poco glamour: consiste en saberse de memoria unas cuantas primitivas elementales. No es simplemente saberlas, hay que dominarlas. La diferencia entre saber y dominar es esta: cuando una simplemente sabe algo, tiene que buscar la solución, pero cuando lo domina, la solución le “salta” a la mente. Cuando un mira una integral y de repnete “ve” que hay que hacerla por partes, es porque domina las primitivas elementales (y tiene práctica). Dominar la tabla es muy fácil: repeteición, repetición, repetición, práctica, práctica, práctica. Sí, es unproceso árido. Pero para llegar al oasis, primero hay que pasar por el desierto. No hay una lista oficial de primitivas elementales, pero con la docena que hay en el cuadro siguiente, tenemos lo suficietne para resolver la mayoría de las integrales que salen habitualmente. \\(f(x)\\) \\(F(x)\\) $dx $ \\(x\\) + C \\(\\int x^{n} dx\\) \\(\\int \\frac{dx}{\\sqrt{x}}\\) \\(2\\sqrt{x}\\) + C \\(\\int a^x dx\\) \\(\\frac{a^x}{\\log(a)}\\) + C \\(\\int e^x dx\\) \\(e^x\\) + C \\(\\int \\frac{dx}{x}\\) \\(\\log(|x|)\\) + C \\(\\int \\sin(x) dx\\) \\(-\\cos(x)\\) + C \\(\\int \\cos(x) dx\\) \\(\\sin(x)\\) + C \\(\\int \\tan(x) dx\\) \\(-\\log(|\\cos(x)|)\\) + C \\(\\int \\frac{dx}{\\cos^2(x)}\\) \\(\\tan(x)\\) + C \\(\\int \\frac{dx}{\\sqrt{1 - x^2}}\\) \\(\\arcsin(x)\\) + C \\(\\int \\frac{dx}{1 + x^2}\\) \\(\\arctan(x)\\) + C Como en el caso de las derivadas, la \\(n\\) de \\(x^n\\) no tiene por qué ser un entero. Por lo tanto, aunque no aparezca explícitamente, tenemos en el cuadro la primitiva de \\(\\sqrt{x} = x^{1/2}\\). Hemos añadido la constante de integración en todas las primitivas elementales. Ya hemos visto que a la hora de caqlcular integrales definidas la constante de integración no se usa. Hay que recordar que está ahí, pero para simplificar la notación, no la añadiremos más. 11.3 Técnica 2: Tres teoremas básicos Muy a menudo las funciones a integrar no tienen exactamente la forma del cuadro de primitivas elementales y hay que manipularlas un poco. Para esto tenemos estos tres teoremas. Si recordamos que una integral es la supericie bajo la curva, son casi evidentes y no vamos a demostrar su veracidad. Sólo demostraremos su uso. Teorema 11.1 \\[\\int cf(x) dx = c \\int f(x) dx\\] Ejemplo 11.1 Calcula \\(\\int 3 \\cos (x) dx\\). La solución en este caso es muy simple: \\[\\int 3 \\cos (x) dx = 3\\int \\cos (x) dx = 3 \\sin(x)\\] Ejemplo 11.2 Calcula \\(\\int \\frac{dx}{\\sqrt{6x}}\\). La solución en este caso es un poco menos obvia: \\[\\int \\frac{dx}{\\sqrt{6x}} = \\int \\frac{dx}{\\sqrt{6}\\sqrt{x}} = \\int \\frac{1}{\\sqrt{6}}\\frac{dx}{\\sqrt{x}} = \\frac{1}{\\sqrt{6}} \\int\\frac{dx}{\\sqrt{x}} = \\frac{1}{\\sqrt{6}}\\, 2\\sqrt{x}\\] El segundo teorema nos permite tratar la suma y resta de funciones. Teorema 11.2 \\[\\int (f(x) \\pm g(x)) dx = \\int f(x) dx \\pm \\int g(x) dx\\] Ejemplo 11.3 Calcula \\(\\int (\\frac{1}{x} + 3e^x) dx\\). Este ejemplo es otra vez muy simple: \\[\\int (\\frac{1}{x} + 3e^x) dx = \\int \\frac{1}{x}dx + \\int 3e^x dx = \\log(|x|) + 3 e^x \\] Ejemplo 11.4 Calcula \\(\\int \\frac{x+5}{x^2} dx\\). Necesitamos una simple manipulación algebraica: \\[\\int \\frac{x+5}{x^2} dx = \\int (\\frac{x}{x^2} + \\frac{5}{x^2}) dx = \\int (\\frac{1}{x} + \\frac{5}{x^2}) dx = \\log(|x|) + 5 \\frac{x^3}{3}\\] Este tercer teorema no es realmente de cálculo de primitivas, sino de cálculo de integrales definidas. Debe aplicarse cuando la función está definda a trozos, o cuando en algún punto tenemos una discontinuidad o la función no es derivable. Teorema 11.3 Dado un valor \\(c\\) tal que \\(a &lt; c &lt; b\\), entonces \\[\\int_a^b f(x) dx = \\int_a^c f(x) dx + \\int_c^b f(x) dx\\] Ejemplo 11.5 Calcula \\(\\int_{-3}^1 |x| dx\\). En el punto \\(x=0\\) la función no es derivable, y debemos dividir nuestra integral en dos: \\[\\int_{-3}^1 |x| dx = \\int_{-3}^0 -x\\, dx \\int_0^1 x\\, dx = \\left.\\frac{-x^2}{2}\\right|_{-3}^0 + \\left.\\frac{x^2}{2}\\right|_0^1 = \\left(0 - \\frac{-9}{2}\\right) + \\left(\\frac{1}{2} - 0\\right) = 5\\] 11.4 Técnica 3: Cambio de variable Cuando derivábamos, partíamos de las derivadas elementales, por ejemplo, derivada de \\(\\sin(x)\\) es \\(\\cos(x)\\), y sabíamos que si lo que había en el paréntesis no era \\(x\\) sino alguna expresión más compleja, que llamábamos \\(u\\), teníamos que aplicar la regla de la cadena: la derivada de \\(\\sin(u)\\) es \\(u^\\prime\\cos(u)\\). En el mundo de las integrales, esta misma idea la llevamos a cabo mediante la técnica del cambio de variable. Digamos que queremos calcular \\(\\int \\cos(3x+1) dx\\). Conocemos la primitiva elemental de \\(\\cos(x)\\), pero lo que tenemos dentro del paréntesis no es \\(x\\), sino \\(3x +1\\). Hacemos el cambio de variable \\(u = 3x +1\\) y así tenemos \\(\\cos(u)\\). En el caso de las integrales tenemos un problema adicional: si la variable es \\(u\\) no podemos tener \\(dx\\) sino que tenemos que tener \\(du\\). Esto se arregla derivando la función \\(u = 3x + 1\\): \\[\\frac{du}{dx} = \\frac{d(3x+1)}{dx} = 3. \\] Despejando el \\(dx\\) nos queda \\[dx = \\frac{1}{3}\\, du.\\] Entonces nuestra integral queda \\[\\int \\cos(3x+1) dx = \\int \\frac{1}{3}\\cos(u) du = \\frac{1}{3}\\sin(u)\\] Y ahora hemos de deshacer el cambio: \\[\\int \\cos(3x+1) dx = \\frac{1}{3}\\sin(3x + 1)\\] Con un poco de práctica estos casos tan simples se hacen de cabeza. Veamos algunos ejemplos más. Ejemplo 11.6 Calcula \\(\\int e^{-x/3} dx\\). Este es un caso muy similar al del coseno hecho antes. El cambio de variable es \\(-x/3 = u\\) lo que implica que \\(dx = -3 du\\). Y entonces nos queda \\[\\int e^{-x/3} dx = \\int -3 e^u du = -3 e^u \\] Deshacemos el cambio de variable: \\[\\int e^{-x/3} dx = -3 e^u = -3 e^{-x/3}\\] Este tipo de integrales aparecen a menudo y uno acaba reconvirtiendo la primitiva elemental a \\(\\int e^{ax} dx = \\frac{1}{a} e^x\\), \\(\\int \\cos(ax) dx = \\frac{1}{a}\\sin(ax)\\), etc. Veamos algún caso un poco más complejo. Ejemplo 11.7 Calcula \\(\\int \\frac{3}{(x/2) - 1} dx\\). El 3 del numerador no nos molesta, lo podemos sacar fuera de la integral. Sabemos que \\(\\int \\frac{dx}{x}\\) es el logaritmo, luego hacemos el cambio de variable \\(\\frac{x}{2} - 1 = u\\), lo que implica que \\(dx = 2\\,du\\). Entonces nos queda \\[\\int \\frac{3}{\\frac{x}{2} - 1} dx = \\int \\frac{3}{u} 2\\,du = 6\\log(|u|). \\] Deshaciendo el cambio de variable nos queda: \\[\\int \\frac{3}{\\frac{x}{2} - 1} dx = 6\\log(|\\frac{x}{2} - 1|). \\] Ejemplo 11.8 Calcula \\(\\int x\\sqrt{3x^2 -5}\\, dx\\). Al ver esta integral es muy fácil que un novato se quede parado. No hay que desesperar, sino ir probando cosas. Hay una raíz cuadrada (o \\(x^{1/2}\\)) y nos sabemos la primitiva inmediata de \\(x^n\\) (si no se dominan las primitivas, es mucho más difícil ver esto). Probamos el cambio de variable \\(u = 3x^2 -5\\), lo que implica que \\(du = 6x\\, dx\\). Tenemos un \\(x\\,dx\\), y a partir de aquí todo es fácil: \\[\\int x\\sqrt{3x^2 -5} \\,dx = \\int \\frac{1}{6} u^{1/2}du = \\frac{1}{6} \\frac{2}{3}u^{3/2} \\] Y ahora deshacemos el cambio de variable: \\[\\int x\\sqrt{3x^2 -5}\\, dx = \\frac{1}{9} \\sqrt{(3x^2 -5)^3}\\] Vemos en este ejemplo que si en la función a integrar está una cosa y su derivada, el cambio de variable puede ser el camino. Ejemplo 11.9 Calcula \\(\\int \\frac{\\log(x)}{x}\\,dx\\). Si dominamos las derivadas, casi nos salta a la vista que tenemos una cosa (\\(\\log(x)\\)) y su derivada (\\(1/x\\)). Esto nos sugiere el cambio de variable \\(u = \\log(x)\\), quedando \\(du = \\frac{dx}{x}\\): \\[\\int \\frac{\\log(x)}{x}\\,dx = \\int u\\, du = \\frac{u^2}{2} = \\frac{log^2(x)}{2} \\] La técnica del cambio de variable permite resolver muchas más integrales, pero no todas, como vemos en el siguiente ejemplo. Ejemplo 11.10 Calcula \\(\\int x^2 \\cos(3x) \\,dx\\). Probamos el cambio de variable \\(3x = u\\) lo que implica que \\(dx = du\\). Desgraciadamente tenemos un \\(x^2\\) que nos impide continuar. Ese cambio de variable no va a resolver esta integral. Esta integral es fácilmente resoluble, pero hemos de utilizar otra técnica: la integración por partes. 11.5 Técnica 4: Integración por partes La integración por partes es un técnica muy útil y que proviene directamente de la derivada del producto. Recordamos que \\[(f\\cdot g)^\\prime = f^\\prime \\cdot g + f\\cdot g^\\prime.\\] De aquí: \\[f\\cdot g^\\prime = (f\\cdot g)^\\prime - f^\\prime \\cdot g .\\] Ahora integramos todo: \\[\\int f\\cdot g^\\prime dx = \\int (f\\cdot g)^\\prime dx - \\int f^\\prime \\cdot g\\, dx = f\\cdot g - \\int f^\\prime \\cdot g\\, dx.\\] Esta expresión normalmente se escribe como \\[\\int u \\, dv = uv - \\int v\\, du\\] A primera vista parece que no hemos ganado mucho: pasamos de una integral, \\(\\int u \\, dv\\) a otra, \\(\\int v\\, du\\). Cuando la aprendí, me pareció una técnica “antipática”. Pero eso es porque no la entendí. Sospecho que el \\(dv\\) y \\(du\\) servían más para confundirme que otra cosa. En esta sección vamos a entender qué hace la integral por partes y después describiremos un método, el método DI, que ayuda utilizar con facilidad esta técnica. En la integral se parte del producto de dos funciones, \\(u\\) y \\(v\\). Pasamos de \\(\\int u \\, dv\\) a \\(\\int v\\, du\\), eso quiere decir que hemos de saber integrar la función \\(v\\) (pasa de \\(dv\\) a \\(v\\)) y derivar la función \\(u\\) (pasa de \\(u\\) a \\(du\\)). Expliquemos su uso con un ejemplo. Tenemos \\(\\int x \\cos(x) \\,dx\\). Dejamos de lado el \\(dx\\) y vemos que tenemos dos funciones: \\(x\\) y \\(\\cos(x)\\). Decidimos derivar \\(x\\) e integrar \\(\\cos(x)\\), es decir, \\(u = x\\) y \\(dv = \\cos(x)\\). La derivada de \\(x\\) es 1, y la primitiva de \\(\\cos(x) = \\sin(x)\\), es decir \\(du = dx\\) y \\(v = \\sin(x)\\). Entonces nos queda \\[\\int x \\cos(x) \\,dx = x\\, \\sin(x) - \\int \\sin(x)\\, dx\\] Nos queda \\(\\int \\sin(x)\\, dx\\), que es inmediata: \\[\\int x \\cos(x) \\,dx = x\\, \\sin(x) + \\cos(x)\\] Esto lo podemos poner en forma tabular: \\[\\begin{array}{cccc} &amp; D &amp; &amp; I\\\\ + &amp; x &amp; &amp; \\cos(x)\\\\ &amp; &amp; \\searrow &amp; \\\\ - &amp; 1 &amp; &amp; \\sin(x) \\end{array}\\] La columna \\(D\\) es la función que vamos derivando, y la columna \\(I\\) es la que vamos integrando. La diagonal (indicado con la flecha) representa el el producto \\(uv\\), mientras que la segunda fila es la integral \\(-\\int 1\\cdot \\sin(x)\\, dx\\). Los signos de la primera columna nos indica que es \\(+uv\\) y \\(- \\int v\\, du\\). Esta tabla DI nos ordena un poco lo que hemos hecho, pero no parece que sea de mucha ayuda. Pero si añadimos otra fila, derivando e integrando lo que tenemos en la segunda fila: \\[\\begin{array}{cccc} &amp; D &amp; &amp; I\\\\ + &amp; x &amp; &amp; \\cos(x)\\\\ &amp; &amp; \\searrow &amp; \\\\ - &amp; 1 &amp; &amp; \\sin(x)\\\\ &amp; &amp; \\searrow &amp; \\\\ + &amp; 0 &amp; &amp; -\\cos(x)\\\\ \\end{array}\\] las dos diagonales nos dan los dos productos, y la tercera fila es la integral, que como es 0, no hay que hacer. Obtenemos el resultado directamente: \\[\\int x \\cos(x) \\,dx = + x\\, \\sin(x) - 1\\cdot (- \\cos(x)) = x\\, \\sin(x) + \\cos(x)\\] No he explicado por qué he decidido integrar \\(\\cos(x)\\) y derivar \\(x\\). Podíamos haberlo escogido al revés. Vamos a crear la tabla DI con esta otra elección (ya sin las flechas) y ver qué pasa: \\[\\begin{array}{ccc} &amp; D &amp; I\\\\ + &amp; \\cos(x) &amp; x\\\\ - &amp; -\\sin(x) &amp; \\frac{x^2}{2}\\\\ + &amp; -\\cos(x) &amp; \\frac{x^3}{6}\\\\ \\end{array}\\] Vemos que con esta elección cada fila es más complicada que la anterior y no llegamos a ninguna parte. Vamos a ver 3 ejemplos de integración con el método DI, cada uno con sus características propias. Ejemplo 11.11 Calcula \\(\\int 5 x^2 \\sin(3x) dx\\). Este es una función similar a la vista. Vamos a derivar \\(x^2\\) y a integrar \\(\\sin(3x)\\). No es una integral inmediata, pero casi. Creamos la tabla DI: \\[\\begin{array}{ccc} &amp; D &amp; I\\\\ + &amp; x^2 &amp; \\sin(3x)\\\\ - &amp; 2x &amp; -\\frac{1}{3}\\cos(3x)\\\\ + &amp; 2 &amp; -\\frac{1}{9}\\sin(3x)\\\\ - &amp; 0 &amp; \\frac{1}{27}\\cos(3x) \\end{array} \\] Paramos porque hemos obtenido un 0 en la columna \\(D\\) y ya tenemos nuestra integral multiplicando las diagonales con su signo (sin olvidarnos del 5): \\[\\int 5 x^2 \\sin(3x) dx = 5 (- x^2 \\frac{1}{3}\\cos(3x) + 2x \\frac{1}{9}\\sin(3x) + 2 \\frac{1}{27}\\cos(3x))\\] En este caso hemos parado cuando hemos obtenido un 0 en la fila \\(D\\). Esto no pasa siempre. Veamos un caso en el que tenemos otra condición de parada diferente. Ejemplo 11.12 Calcula \\(\\int x^2 \\log(x) dx\\). Como no sabemos (todavía) integrar \\(\\log(x)\\), vamos a integrar \\(x^2\\) y derivar \\(\\log(x)\\). Creamos la tabla DI: \\[\\begin{array}{ccc} &amp; D &amp; I\\\\ + &amp; \\log(x) &amp; x^2\\\\ - &amp; \\frac{1}{x} &amp; \\frac{x^3}{3} \\end{array} \\] Recordamos que cada fila representa a una integral. Sabemos integrar la segunda fila, luego podemos parar aquí. Nos queda: \\[\\begin{align} \\int x^2 \\log(x) dx &amp; = \\log(x) \\frac{x^3}{3} -\\int \\frac{1}{x} \\frac{x^3}{3} \\,dx \\\\ &amp;= \\frac{x^3\\log(x)}{3} - \\frac{1}{3}\\int{x^2}\\, dx \\\\ &amp;= \\frac{x^3\\log(x)}{3} - \\frac{x^3}{9} \\end{align}\\] La parada en esta caso la hemos hecho cuando hemos obtenido una fila que sabíamos integrar. Veamos una tercera condición de parada. Ejemplo 11.13 Calcula \\(\\int e^{2x} \\cos(x) dx\\). Vamos a integrar \\(e^{2x}\\) y derivar \\(\\cos(x)\\) (probad a hacerlo al revés). La tabla DI queda: \\[\\begin{array}{ccc} &amp; D &amp; I\\\\ + &amp; \\cos(x) &amp; e^{2x} \\\\ - &amp; -\\sin(x) &amp; \\frac{1}{2}e^{2x} \\\\ + &amp; -\\cos(x) &amp; \\frac{1}{4}e^{2x} \\end{array} \\] Vemos que la última fila es, salvo constantes y signos, igual que la primera. Esto quiere decir que hemos vuelto a llegar al punto de partida. Eso es bueno: \\[\\int e^{2x} \\cos(x) dx = \\cos(x)\\frac{1}{2}e^{2x} - (-\\sin(x))\\frac{1}{4}e^{2x} + \\int -\\frac{1}{4}e^{2x}\\cos(x) dx \\] Pasamos la integral al otro lado: \\[\\int e^{2x} \\cos(x) dx + \\frac{1}{4}\\int e^{2x} \\cos(x) dx = \\frac{\\cos(x)e^{2x}}{2} + \\frac{\\sin(x) e^{2x}}{4}\\] Despejamos la integral, arreglamos un poco y nos queda: \\[\\int e^{2x} \\cos(x) dx = \\frac{4}{5} \\frac{e^{2x}}{2} \\left(\\cos(x) + \\frac{1}{2}\\sin(x)\\right) \\] Para resolver una integral por partes usando el método DI debemos: Escoger qué vamos a integrar y qué vamos a derivar Crear la tabla DI, con signos alternados, derivando una columna e integrando la otra Paramos cuando se dé una de estas tres condiciones Tenemos un 0 en la columna D Sabemos integrar la fila La fila es igual, salvo signo o constantes, a una fila anterior A partir de las diagonales y, si es necesario, la integral de la última fila, resolvemos la integral de partida. Si nunca se da ninguna de las condiciones de parada es que esta integral no se resuelve por partes, al menos no con la elección que hemos hecho de lo que vamos a derivar y lo que vamos a integrar. Para acabar, vamos a integrar por partes algo que parece que no es un producto de dos funciones. Ejemplo 11.14 Calcula \\(\\int \\log(x) dx\\). Aunque parece que sólo hay una función, tenemos dos: \\(\\log(x)\\) y \\(1\\). Vamos a derivar \\(\\log(x)\\) y a integrar el 1. Nos queda: \\[\\int \\log(x) dx = x \\log(x) - \\int x \\frac{1}{x}\\, dx = x \\log(x) - x\\] Con las técnicas vistaas hasta ahora podemos resolver la mayoría de las integrales que nos aparecen. Veamos una última técnica para resolver cierto tipo de integrales que aparecen mucho en ingeniería. las funciones racionales. 11.6 Técnica 5: Integración de funciones racionales Una función racional es una función que es el cociente de dos polinomios, por ejemplo \\[f(x) = \\frac{P(x)}{Q(x)} = \\frac{3x^2 + 2}{x^3 - 4x^2 - 7x + 10}.\\] Integrar estas funciones tiene una parte algebraica, que es fácil, pero larga y pesada, y después la parte de cálculo que es simple. Pasaremos rápidamente por la parte algebraica, y nos detendremos un poco más en la parte de cálculo. 11.6.1 Descomposición en fracciones simples Para poder integrar una función racional hemos de descomponer como una suma de fracciones simples, fracciones cuyo denominador son de la forma \\(1\\) (es decir, sin denominador), \\((x-a)\\), \\((x-a)^n\\) para algún entero \\(n\\) o un polinomio cuadrático \\(x^2 + bx + c\\) sin raíces reales. Esto siempre es posible. Es un proceso pesado, pero sin trampas. En nuestro ejemplo el grado del numerador \\(P(x)\\), es menor que el del denominador \\(Q(x)\\). Vamos a empezar por este caso. Lo primero que tenemos que hacer es encontrar las raíces de \\(Q(x)\\). Eso puede ser más o menos fácil. En este caso tiene 3 raíces reales, \\(x = -2\\), \\(x = 1\\) y \\(x = 5\\). Esto quiere decir que \\(Q(x) = (x+2)(x-1)(x-5)\\). Sabiendo las raíces, podemos escribir nuestra función como \\[\\frac{3x^2 + 2}{x^3 - 4x^2 - 7x + 10} = \\frac{A}{x+2} + \\frac{B}{x-1}+\\frac{C}{x-5}\\] y es cuestión de encontrar los valores de \\(A\\), \\(B\\) y \\(C\\). Para ello juntamos la suma de las tres fracciones en una: \\[\\frac{A}{x+2} + \\frac{B}{x-1}+\\frac{C}{x-5} = \\frac{A(x-1)(x-5) + B(x+2)(x-5) + C(x+2)(x-1)}{(x+2)(x-1)(x-5)}\\] Luego \\[\\frac{3x^2 + 2}{x^3 - 4x^2 - 7x + 10} = \\frac{A(x-1)(x-5) + B(x+2)(x-5) + C(x+2)(x-1)}{(x+2)(x-1)(x-5)}\\] Los dos denominadores son iguales, luego los dos numeradores deben serlo también. Desarrollamos el numerador e igualamos. Esto nos da lugar a un sistema de ecuaciones cuya solución es \\[A = \\frac{2}{3}; \\qquad B = \\frac{-5}{12}; \\qquad C = \\frac{11}{4}.\\] (En este caso hay un método más simple que resolver el sistema, pero no lo explico). Luego tras descomponer nuestra función racional en fraccions simples tenemos que \\[\\frac{3x^2 + 2}{x^3 - 4x^2 - 7x + 10} = \\frac{1/3}{x+2} - \\frac{5/12}{x-1}+\\frac{11/4}{x-5}\\] Y esta expresión es la que veremos cómo se integra. En el caso general podemos tener raíces simples, como las que hemos visto en el ejemplo anterior, raíces múltiples de la forma \\((x-a)^n\\) y polinomios de segundo grado sin raíces reales. Supongamos que nuestro denominador \\(Q(x)\\) tiene una raíz simple en \\(x = 2\\), una de multiplicidad 3 en \\(x = -1\\) y una ecuación de segundo grado sin raíces reales \\(x^2 -4x+5\\). Esto quiere decir que podemos escribir \\(Q(x)\\) como \\((x-2)(x+1)^3(x^2 -4x+5)\\). Entonces la descomposición de fraciones simples tiene la forma \\[\\frac{P(x)}{Q(x)} = \\frac{A}{x-2} + \\frac{B_1}{x+1} + \\frac{B_2}{(x+1)^2} + \\frac{B_3}{(x+1)^3} + \\frac{Mx + N}{x^2 -4x+5}\\] Para hallar los coeficientes juntamos todo en una única fracción, desarrollamos el numerador y lo igualamos a \\(P(x)\\). Esto nos da un sistema de 6 ecuaciones con 6 incógnitas, que resolvemos y obtenemos \\(A, B_1, B_2, B_3, M y N.\\) Largo y tedioso, pero no difícil. Es importante saber cómo hacer esta descomposición, pero después dejaremos estas tareas tediosas y que consumen mucho tiempo al ordenador. *** Hemos exigido que el grado del denominador sea estrictamente menor que el del numerador. ¿Qué hacemos si es mayor? En este caso hay que dividir los polinomios. Supongamos que tenemos la función racional \\[f(x) = \\frac{x^4 + 3x^2 + x - 1}{x^3 + 2x^2}.\\] Esto lo queremos poner de la forma \\[D(x) + \\frac{P(x)}{x^3 + 2x^2}.\\] Como el denominador es de grado 3 y \\(P(x)\\) debe tener menor grado que el denominador, debe ser de grado 2. Como \\(D(x)\\cdot (x^3 + 2x^2)\\) debe tener el mismo grado que el numerador original, entonces \\(D(x)\\) debe ser de grado 1. Luego nos queda la ecuación \\[\\frac{x^4 + 3x^2 + x - 1}{x^3 + 2x^2} = A_1x + A_0 + \\frac{B_2x^2 + B_1x + B_0}{x^3 + 2x^2}.\\] Recomponemos en una fracción la parte de la derecha y queda \\[\\frac{x^4 + 3x^2 + x - 1}{x^3 + 2x^2} = \\frac{(A_1x + A_0)(x^3 + 2x^2) + (B_2x^2 + B_1x + B_0)}{x^3 + 2x^2}.\\] Desarrollamos, igualamos los polinomios de los numeradores y resolvemos el sistema de ecuaciones. Nos queda que \\[\\frac{x^4 + 3x^2 + x - 1}{x^3 + 2x^2} = x -2 + \\frac{7x^2 + x - 1}{x^3 + 2x^2}.\\] Y ahora estamos preparados para descomponer la segunda parte en fracciones simples. 11.6.2 Integración de las fracciones simples Una vez hecha la parte algebraica, integrar es fácil. Nos quedan 3 tipos de fracciones que debemos integrar. Dos son inmediatas. Ejemplo 11.15 Calcula \\(\\int \\frac{A}{x-a} dx\\). Se puede hacer el cambio de variable \\(u = x-a\\), pero realmente ya deberíamos ver a simple vista que la solución es \\[\\int \\frac{A}{x-a} dx = A \\log(|x-a|) \\] Ejemplo 11.16 Calcula \\(\\int \\frac{A}{(x-a)^n} dx\\). Quizá se ve mejor si reescribimos la integral como \\(\\int A(x-a)^{-n} dx\\). Se puede hacer el cambio de variable \\(u = x-a\\), pero, otra vez, deberíamos ver a simple vista que la solución es \\[\\int \\frac{A}{(x-a)^n} dx = \\frac{-A}{(n-1)(x-a)^{n-1}} \\] El tercer tipo de fracción es un poco más complicada. Queremos calcular \\(\\int \\frac{Mx + N}{(x^2 + bx + c)} dx\\). Hemos supuesto que el término en \\(x^2\\) tiene coeficiente 1. Si es otra cosa, es cuestión de multiplicar o dividir, lo que sea más fácil. También hemos supuesto que este polinomio no tiene raíces reales. Esto quiere decir que el discriminante \\(b^2 - 4c\\) es negativo. En este caso, podemos reescribir el polinomio como \\[(x- \\frac{b}{2})^2 + \\frac{4c - b^2}{4}.\\] Como nos estamos quedando sin letras, aunque sea un poco confuso, lo escribiremos como \\((x-a)^2 + b\\). Pueden comprobar efectivamente que \\[x^2 + 2x + 4 = \\left(x + \\frac{2}{2}\\right)^2 + \\frac{4\\cdot 4 - 2^2}{4} = (x+1)^2 + 3.\\] Hemos de distinguir entre dos casos. El primer caso es que al resover el sistema de ecuaciones hemos obtenido \\(M = 0\\), es decir, que nuestra fracción simple es del tipo \\[\\frac{N}{(x-a)^2 + b}.\\] Si miramos la lista de primitivas inmediatas se parece a la del arctan(x). Necesitamos un 1 en el denominador. Para ello dividimos todo por \\(b\\). Nos queda: \\[\\frac{N}{b} \\int \\frac{1}{\\left(\\frac{x-a}{\\sqrt{b}}\\right)^2 + 1} \\,dx\\] El cambio de variable que necesitamos es \\[ u = \\frac{x-a}{\\sqrt{b}}\\] y tenemos que \\(dx = \\sqrt{b}\\,du\\). La integral queda \\[\\frac{N}{b} \\int \\frac{\\sqrt{b}}{u^2 + 1}\\,du.\\] Y esta ya es inmediata. Resolviendo y deshaciendo el cambio de variable nos queda \\[\\int \\frac{N}{(x-a)^2 + b}\\,dx = \\frac{N}{\\sqrt{b}} \\arctan\\left(\\frac{x-a}{\\sqrt{b}}\\right).\\] El segundo caso es cuando \\(M ≠ 0\\). Tenemos \\[\\int \\frac{Mx + N}{(x-a)^2 + b}\\,dx\\] Queremos hacer el cambio de variable \\((x-a)^2 + b = u\\). Más adelante se entenderá el porqué de este cambio de variable. Este cambio da lugar a \\(2(x-a)dx = du\\). Luego queremos un 2 multiplicando en el numerador a la \\(x\\). Eso es fácil: \\[\\frac{2}{M} \\int \\frac{2x + \\frac{2N}{M}}{(x-a)^2 + b}\\,dx\\] Como queremos un \\(2(x-a) = 2x - 2a\\) en el numerador, sumamos y restamos \\(2a\\): \\[\\frac{2}{M} \\int \\frac{2x - 2a + \\frac{2N}{M} +2a}{(x-a)^2 + b}\\,dx\\] Y ahora dividimos la integral en 2: \\[\\frac{2}{M} \\int \\frac{2x - 2a}{(x-a)^2 + b}\\,dx + \\frac{2}{M} \\int \\frac{\\frac{2N}{M} +2a}{(x-a)^2 + b}\\,dx\\] La segunda integral es la del \\(\\arctan\\) que acabamos de hacer. Vayamos con la primera. Hacemos el cambio de variable: \\[\\frac{2}{M} \\int \\frac{2x - 2a}{(x-a)^2 + b}\\,dx = \\frac{2}{M} \\int \\frac{du}{u}.\\] Ahora se entiende el cambio de variable: esto es un logaritmo: \\[\\frac{2}{M} \\int \\frac{du}{u} = \\frac{2}{M} \\log(|u|).\\] Deshacemos el cambio de variable: \\[\\frac{2}{M} \\int \\frac{2x - 2a}{(x-a)^2 + b}\\,dx = \\frac{2}{M} \\log(|(x-a)^2 +b|)\\] Vemos que integrar funciones racionales es un pproceso sin misterios, pero que puede ser largo y tedioso. A veces muy largo y muy tedioso. Pero en algunas áreas estas integrales son muy habituales y hay que saber hacerlas (aunque luego se las “encarguemos” al ordenador). Acabemos con un último ejemplo. Ejemplo 11.17 Calcula \\[\\int \\frac{3x^3 - 3x^2 + 16x -17}{x^4 - 2x^3 + x^2 + 12x +8} \\, dx\\] Probando vemos que tiene una raíz en \\(x = 1\\) (que resulta ser doble), y no tiene más raíces reales. Podemos escribir la función como \\[\\frac{A_1}{x+1} + \\frac{A_1}{(x+1)^2} + \\frac{Mx + N}{x^2 - 4x + 8}\\] Encontramos los valores de los coeficientes y nos queda: \\[\\frac{1}{x+1} - \\frac{3}{(x+1)^2} + \\frac{2x -1}{(x-2)^2 +4}\\] Las primera integral es inmediata: \\[\\int \\frac{dx}{x+1} = \\log(|x+1|)\\] y la segunda también: \\[\\int \\frac{-3}{(x+1)^2}\\,dx = \\frac{3}{x+1}\\] Vamos a arreglar la tercera. Queremos hacer el cambio de variable \\(u = (x-2)^2 +4\\). Esto nos deja \\(du = (2x - 4)\\, dx\\). Arreglamos el numerador: \\[\\int \\frac{2x -1}{(x-2)^2 +4}\\, dx = \\int \\frac{2x -4 + 3}{(x-2)^2 +4}\\, dx\\] Y ahora dividimos en dos y resolvemos cada integral por separado. Empecemos con la primera: \\[\\int \\frac{2x -4}{(x-2)^2 +4}\\, dx.\\] Hacemos el cambio de variable \\(u = (x-2)^2 +4\\) y resolvemos \\[\\int \\frac{2x -4}{(x-2)^2 +4}\\, dx = \\int \\frac{du}{u} = \\log(|u|) = \\log((x-2)^2 +4)\\] (Podemos olvidarnos del valor absoluto, pues es siempre positivo). Vamos con la segunda integral: \\[\\int \\frac{3}{(x-2)^2 +4}\\, dx\\] Hemos de arreglarlo para tener un 1 en el numerador y que se sume 1 en el denominador: \\[\\frac{3}{4}\\int \\frac{dx}{\\left(\\frac{x-2}{2}\\right)^2 + 1}\\] Hacemos el cambio de variable \\(u = \\frac{x-2}{2}\\) lo que implica que \\(dx = 2\\,du\\). Sacamos de la integral (y simplificamos) 2 que ha aparecido en el numerador y queda: \\[\\frac{3}{2}\\int \\frac{du}{u^2 + 1}\\] Y ahora es inmediata \\[\\frac{3}{2}\\int \\frac{du}{u^2 + 1} = \\frac{3}{2}\\arctan(u) = \\frac{3}{2}\\arctan\\left(\\frac{x-2}{2}\\right)\\] Juntamos todo: \\[\\begin{array}{l} \\int \\frac{3x^3 - 3x^2 + 16x -17}{x^4 - 2x^3 + x^2 + 12x +8} \\, dx = \\\\ \\qquad \\log(|x+1|) + \\frac{3}{x+1} + \\log((x-2)^2 +4) + \\frac{3}{2}\\arctan\\left(\\frac{x-2}{2}\\right)\\end{array}\\] 11.7 Integrales impropias Hemos supuesto hasta ahora, aunque no lo hemos dicho explícitamente, que la función a integrar es continua en todo \\([a, b]\\) y que este intervalo \\([a, b]\\) es finito. Pero imaginemos que quiero calcular \\(\\int_{-1}^{1} \\frac{1}{x^2} \\,dx\\), que tiene una discontinuidad en \\(x = 0\\) o que quiero calcular \\(\\int_0^\\infty e^{-x} dx\\). Estas integrales aparecen en problemas reales y las áreas que estamos calculando puedes ser finitas. A este tipo de integrales se les llaman integrales impropias. Empecemos por la integral \\(\\int_{-1}^{1} \\frac{1}{x^2} \\,dx\\). Aunque tenemos esa discontinuidad en \\(x=0\\) podría ser que el área bajo la curva sea finita. Como claramente la función es simétrica alrededor del eje Y, vamos a calcular sólo \\(\\int_{0}^{1} \\frac{1}{x^2} \\,dx\\). No podemmos calcular la primitiva y aplicar la regla de Barrow, pues habría que evaluar la función en un punto en el que no existe. ¿Qué podríamos hacer? La solución es la misma que ya hemos aplicado otras veces: coger un punto \\(\\varepsilon\\), positivo, cercano a 0, calcular la integral entre \\(\\varepsilon\\) y 1, y después calcular el límite cuando \\(\\varepsilon\\) tiende a 0. Hagámoslo: \\[\\int_\\varepsilon^ 1 \\frac{1}{x^2}\\, dx = \\left. -\\frac{1}{x}\\right|_\\varepsilon^1 = -\\frac{1}{1}+\\frac{1}{\\varepsilon} = \\frac{1-\\varepsilon}{\\varepsilon}\\] Y ahora calculamos el límite: \\[\\lim_{\\varepsilon \\to 0^+}\\frac{1-\\varepsilon}{\\varepsilon} = \\infty\\] Esta integral no existe (el área es infinita). Uno podría pensar que siempre que la función tiende a , el área también lo va a hacer. Pero no es así. Ejemplo 11.18 Calcula \\[\\int_0^2 \\frac{1}{\\sqrt{4-x^2}} \\, dx.\\] Tenemos una discontinuidad en \\(x=2\\), luego escogemos un valor \\(\\varepsilon\\) menor que 2, calculamos la integral entre 0 y \\(\\varepsilon\\), y después el límite cuando \\(\\varepsilon\\) tiende a 2. La integral es, casi, una de nuestra lista de inmediatas. \\[\\int_0^\\varepsilon \\frac{1}{\\sqrt{4-x^2}} \\, dx = \\left.\\arcsin\\left(\\frac{x}{2}\\right)\\right|_0^\\varepsilon = \\arcsin\\left(\\frac{\\varepsilon}{2}\\right) - \\arcsin(0) = \\arcsin\\left(\\frac{\\varepsilon}{2}\\right)\\] Y ahora \\[\\lim_{\\varepsilon \\to 2^-}\\arcsin\\left(\\frac{\\varepsilon}{2}\\right) = \\arcsin(1) = \\frac{\\pi}{2}\\] Ahora vamos con el caso de que uno de los extremos de la integral es . Calculemos \\(\\int_0^\\infty e^{-x} \\,dx.\\) Vamos a calcular la integral entre 0 y \\(t\\) y después hacemos que \\(t\\) tienda a infinito: \\[\\int_0^t e^{-x} \\,dx = \\left.-e^{-x}\\right|_0^t = -e^{-t} + e^0 = 1 - e^{-t}\\] Ahora hacemos el límite cuando \\(t\\) tiende a \\(\\infty\\): \\[\\lim_{t \\to \\infty}(1 - e^{-t}) = 1 - 0 = 1\\] 11.8 Integración numérica Como hemos visto, encontrar la primitiva de una función puede ser muy difícil, a veces casi imposible. Pero si tengo una función, aunque no tenga la primitiva, puedo calcular aproximadamente el área bajo la curva. Es lo que se llama integración numérica. La idea básica es la misma que ya vimos al definir integral en el apartado8.8: aproximar el área bajo la curva mediante figuras geométricas de las que sé calcular el área. No podemos hacer el límite, luego no podremos saber el valor exacto, pero a base de aumentar el número figuras, que serán cada vez más pequeñas, puedo aproximarme al valor real tanto como quiera. Cuando había que hacer los cálculos a mano, no era una solución maravillosa: casi te costaba menos seguir buscando la primitiva. Pero ahora hay ordenadores. En el apartado 8.5 usamos rectángulos para aproximar el área. Era el caso más simple de explicar y no íbamos a hacer los cálculos. Pero hay maneras mejores, que nos aproxima el área de forma más eficiente y con menos cálculos. Veámoslos. 11.8.1 Aproximación por rectángulos Tenemos una función \\(f(x)\\) y queremos calcular numérricamente la integral definida \\(\\int_a^b f(x) \\, dx\\). Lo primero que se nos puede ocurrir es aproximar el área mediante rectángulos: Para ello partimos el intervalo \\([a, b]\\) en \\(N\\) partes iguales. Vamos a llamar a los puntos de esta partición \\(x_0, x_1, \\dots, x_{n-1}, x_n\\). Naturlamente \\(x_0 = a\\) y \\(x_n = b\\). La distancia entre estos puntos es \\(h = (b-a)/N\\). Por lo tanto \\(x_1 = x_0 + h\\), \\(x_2= x_0 + 2h\\) y en general \\(x_i = x_0 + i\\cdot h\\). La superficie de cada rectángulo es \\(f(x_i)\\cdot h\\). La suma de todos los rectángulos nos aproxima la integral: \\[\\int_a^b f(x) \\, dx \\approx f(x_0)\\cdot h + f(x_1)\\cdot h + f(x_2)\\cdot h + \\cdots + f(x_{n-1})\\cdot h \\] (El símbolo “\\(\\approx\\)” significa “es aproximadamente igual”). Sacamos \\(h\\) factor común y lo expresamos como un sumatorio: \\[\\int_a^b f(x) \\, dx \\approx h\\sum_{i = 0}^{n-1} f(x_0+i\\cdot h)\\] El algoritmo resultante es: Decidimos el número \\(N\\) de partes Calculamos \\(h = (b-a)/N\\) Evaluamos la función en los puntos \\(f(x_0 + i\\cdot h)\\) para \\(0 ≤ i ≤ n-1\\) y sumamos los valores Multiplicamos la suma obtenida por \\(h\\). Cuánto menor es \\(h\\) mejor nos vamos a aproximar al valor real de la integral, pero hay que hacer más sumas y, aunque lo haga el ordenador, más tardaremos en obtener el resultado. Hay un límite a lo pequeño que puede ser \\(h\\): si es muy pequeño, el error de redondeo puede ser tan grande que haga que la aproximación obtenida sea peor. Veamos lo bueno que es este método. Ejemplo 11.19 Calcula mediante una aproximación por rectángulos \\(\\int_{0.25}^{1} \\frac{dx}{x}\\) Sabemos que el valor exacto de esta integral es \\(\\log(1) - \\log(0.25) = 1.386294\\). Vamos a coger 3 valores de \\(N\\): 10, 100 y 1000. Para \\(N = 10\\) obtenemos el valor 1.505761, no muy bueno. Para \\(N = 100\\) mejoramos, 1.397615, aunque se desvía ya en el segundo decimal. Para \\(N = 1000\\) el valor obtenido es 1.38742. Hemos mejorado, pero parece poca mejor para tanto esfuerzo. No parece un método muy bueno. Vamos a intentar mejorarlo. 11.8.2 Aproximación por trapecios Si aproximamos mediante rectángulos, es claro que nos alejamos de la curva y erramos en el área. A veces el rectángulo es menor que el área bajo la curva, otras veces es mayor. Puede que tengammos suerte y se compense, pero mejor usar otro método que no fiarnos de la suerte. La primera posible mejora es obvia: unir mediante segmentos los puntos de la curva. Esto da lugar a trapecios, y entonces calculamos el área de estos trapecios. El área de un trapecio es la semisuma de las bases por la altura. En este caso la altura es \\(h\\) y las bases son los valores de \\(f(x)\\) en los puntos de nuestra partición. La suma queda: \\[\\int_a^b f(x) \\, dx \\approx \\frac{f(x_0)+f(x_1)}{2}\\, h + \\frac{f(x_1)+f(x_2)}{2}\\, h + \\frac{f(x_2)+f(x_3)}{2}\\, h +\\cdots + \\frac{f(x_{n-1})+f(x_n)}{2}\\, h \\] Notamos que, salvo para los extremos, cada término \\(\\frac{f(x_i)}{2}\\) aparece dos veces. Luego nos queda: \\[\\int_a^b f(x) \\, dx \\approx h\\left(\\frac{f(x_0)}{2} + \\frac{f(x_n)}{2} + \\sum_{i = 1}^{n-1} f(x_0+i\\cdot h)\\right)\\] El algoritmo resultante es: Decidimos el número \\(N\\) de partes Calculamos \\(h = (b-a)/N\\) Evaluamos la función en los puntos \\(f(x_0 + i\\cdot h)\\) para \\(0 ≤ i ≤ n\\) Sumamos los valores de \\(f(x_i)\\) en los puntos \\(x_1, x_2, \\dots, x_{n-1}\\) y le sumamos \\(f(x_0)/2\\) y \\(f(x_n)/2\\) Multiplicamos la suma obtenida por \\(h\\). Veamos si es mejor que el de los rectángulos. Ejemplo 11.20 Calcula mediante una aproximación por trapecios \\(\\int_{0.25}^{1} \\frac{dx}{x}\\) Sabemos que el valor exacto de esta integral es \\(\\log(1) - \\log(0.25) = 1.386294\\). Vamos a coger 3 valores de \\(N\\): 10, 100 y 1000. Para \\(N = 10\\) obtenemos el valor 1.393261, que es mucho mejor que con los rectángulos. Para \\(N = 100\\) tenemos 1.386365, que ya tiene 3 decimales exactos. Para \\(N = 1000\\) el valor obtenido es 1.386295, que sólo varía en el sexto decimal. Vemos que en este ejemplo, el método de los trapecios es muchísimo mejor que el de los rectángulos para el mismo esfuerzo de cálculo. 11.8.3 Método de Simpson Hemos planteado estos métodos como el uso de rectángulos y trapecios. Pero también lo podíamos haber planteado de otra manera: en el método de los rectángulos hemos aproximado la función en cada parte como una constante (un polinomio de grado 0) mientras que en el método de los trapecios hemos aproximado la función en cada parte como una recta (polinomio de grado 1). El siguiente paso parece ser aproximar cada parte con un polinomio de grado 2 (una parábola). Es una idea similar a la de los polinomiode Taylor, aunque los polinomios que hemos usado no son los de Taylor, sino los que pasan por ciertos puntos de la función. A esto se le llama una interpolación. El caso de la aproximación por polinomios de grado 2 se le conoce como el método de Simpson. Para los polinomios de grado 0 sólo necesitábamos un punto, \\(x_i\\); para los de grado 1 necesitábamos dos puntos, \\(x_i\\) y \\(x_{i+1}\\): para el grado 2 necesitamos tres puntos: \\(x_i\\), \\(x_{i+1}\\) y \\(x_{i+2}\\). En cada parte, usaremos los dos puntos de los extremos y el punto del medio. Esto quiere decir que aunque tengamos \\(N\\) puntos, tendremos \\(N/2\\) partes. Esto obliga a que \\(N\\) sea par. Para simplificar la notación, llamaremos \\(y_i\\) a \\(f(x_i)\\). La manera de obtener el valor numérico aproximado es la siguiente. Tenemos \\(x_i\\), \\(x_{i+1}\\) y \\(x_{i+2}\\) y los valores de la función en esos puntos son \\(y_i\\), \\(y_{i+1}\\) e \\(y_{i+2}\\). El polinomio de grado 2 es de la forma \\(y = ax^2 + b^x + c\\) y queremos averiguar los valores de \\(a\\), \\(b\\) y \\(c\\) que hacen que la parábola pase por \\((x_i, y_i)\\), \\((x_{i+1}, y_{i+1})\\) y \\((x_{i+2}, y_{i+2})\\). Esto da lugar al sistema de ecuaciones \\[\\begin{align} y_i &amp;= ax_i^2 + bx_i + c\\\\ y_{i+1} &amp;= ax_{i+1}^2 + bx_{i+1} + c\\\\ y_{i+2} &amp;= ax_{i+2}^2 + bx_{i+2} + c \\end{align}\\] Resolviendo este sistema obtenemos los valores de \\(a\\), \\(b\\) y \\(c\\). Una vez conocidos etos parámetros, hemos de calcular el valor del área bajo la parábola. Es un polinomio que podemos integrar fácilmente: \\[\\int_{x_i}^{x_{i+2}} (ax^2 + b^x + c) \\, dx = \\frac{a}{3}(x_{i+2}^3 - x_i^3) - \\frac{b}{2}(x_{i+2}^2 - x_i^2) + c(x_{i+2} - x_i)\\] Y una vez que se tiene el área de esta parte, se va a la siguiente y se vuelve a empezar. Esto parece horrible, pero teniendo en cuenta que \\(x_{i+1} = x_i + h\\) y que \\(x_{i+2} = x_i + 2h\\), todo se simplifica bastante y nos queda que \\[\\int_a^b f(x) \\, dx \\approx \\frac{h}{3} \\left(y_0 + y_n + 4 (y_1 + y_3 + \\cdots + y_{n-1}) + 2(y_2 + y_4 + \\cdots + y_{n-2})\\right)\\] El algoritmo resultante es: Decidimos el número \\(N\\) de puntos. \\(N\\) debe ser par. Calculamos \\(h = (b-a)/N\\) Evaluamos la función en los puntos \\(f(x_0 + i\\cdot h)\\) para \\(0 ≤ i ≤ n\\) Sumamos los valores de \\(f(x_i)\\) en los puntos \\(x_1, x_3, \\dots, x_{n-1}\\). Multiplicamos esta suma por 4. Sumamos los valores de \\(f(x_i)\\) en los puntos \\(x_2, x_4, \\dots, x_{n-2}\\). Multiplicamos esta suma por 2. Sumamos las dos cantidades obtenidas con \\(f(x_0)\\) y \\(f(x_n)\\). Multiplicamos la suma obtenida por \\(h/3\\). El coste computacional del método de Simpson es prácticamente el mismo que el de los trapecios o el de los rectángulos. Veamos si es mejor. Ejemplo 11.21 Calcula mediante una aproximación por trapecios \\(\\int_{0.25}^{1} \\frac{dx}{x}\\) Sabemos que el valor exacto de esta integral es \\(\\log(1) - \\log(0.25) = 1.386294361119\\) (vamos a necesitar todos estos decimales) Vamos a coger 3 valores de \\(N\\): 10, 100 y 1000. Para \\(N = 10\\) obtenemos el valor 1.38652, que con tan pocos puntos ya tiene 3 decimales exactos. Para \\(N = 100\\) tenemos 1.38629438, que ya tiene 8 decimales exactos. Para \\(N = 1000\\) el valor obtenido es 1.386294361122, con 12 decimales buenos. Dado que con \\(N=10\\) el método de Simpson consigue resultados casi tan buenos que el de los trapecios con \\(N = 100\\), vemos que un buen algoritmo te puede ahorrar el 90% de tu trabajo. "],
["ecuaciones-diferenciales.html", "Capítulo 12 Ecuaciones diferenciales 12.1 Introducción 12.2 Clasificación de las ecuaciones diferenciales 12.3 Ecuaciones diferenciales de variables separables 12.4 Ecuaciones diferenciales lineales de primer orden", " Capítulo 12 Ecuaciones diferenciales 12.1 Introducción Al mirar la interpretación física de las derivadas, partíamos de una función, por ejemplo la velocidad de un objeto, y derivando la velocidad podíamos obtener la aceleración del objeto. Pero casi siempre el problema que tenemos es el contrario: sabemos las fuerzas sobre el objeto, que gracias a la segunda ley de Newton nos da la aceleración, y a partir de aquí queremos obtener su velocidad y posición. Es el problema inverso al que hemos visto hasta ahora. Estudiémoslo. Empecemos con un caso muy simple. Supongamos que la aceleración \\(a(t)\\) es constante. Entonces \\[\\frac{dv(t)}{dt} = a\\] No hemos de derivar la función, sino que tenemos que encontrar una función cuya derivada es la constante \\(a\\). Es un caso muy simple, casi obvio: \\[v(t) = at + C\\] Ahora no estamos calculando un área o sumando, sino hallando una función, luego la constante de integración es necesaria. Para obtener el valor de esta constante hemos de conocer la velocidad en algún momento Típicamente, sabemos la velocidad en el instante inicial: \\(v(0) = v_0\\). Luego nos queda la función \\[v(t) = v_0 + at.\\] Si ahora queremos saber la función de la posición del objeto, \\(s(t)\\), hemos de encontrar una función que al derivarla nos dé la velocidad: \\[\\frac{ds(t)}{dt} = v_0 + at\\] Otra vez, es un caso muy simple: \\[s(t) = v_0t + \\frac{1}{2}at^2 + C.\\] Para hallar el valor de la constante necesitamos saber la posición en algún instante concreto. Típicamente, la sabemos en el instante inicial, \\(s(0) = s_0\\) y obtenemos así: \\[s(t) = s_0 + v_0t + \\frac{1}{2}at^2.\\] Hemos deducido las ecuaciones del movimiento uniformemente acelerado. Seguramente casi todos se han dado cuenta que lo que hemos hecho es integrar dos veces. Este es un problema tan simple que hemos podido encontrar las funciones simplemente integrando. Pero normalmente las situaciones son más complicadas. Supongamos que dejamos caer una pelota. Sabemos que la gravedad actúa sobre ella, con una fuerza constante \\(F = -mg\\) (seguimos la convención que hacia arriba es positivo y hacia abajo, negativo). Hay también un rozamiento aerodinámico, que se opone al movimiento, que es proporcional al cuadrado de la velocidad. La suma de ambas fuerzas es \\[F = -mg - kv(t)^2.\\] Aplicando la ley de Newton tenemos \\[ma(t) = -mg - kv(t)^2.\\] Dada que la posición es vertical, la llamaremos \\(y(t)\\). La velocidad es la primera derivada de la posición, y la aceleración es la segunda derivada de la posición. La ecuación queda: \\[m\\frac{d^2y(t)}{dt^2} = -mg - k\\left(\\frac{dy(t)}{dt}\\right)^2.\\] Para saber cómo se mueve muestra pelota, hemos de encontrar una función \\(y(t)\\) que cumpla esta ecuación. Ahora ya no basta con integrar. En estas ecuaciones aparece no sólo la función, sino también una o más derivadas de la función. Por eso reciben el nombre de ecuaciones diferenciales. Definición 12.1 Una ecuación diferencial es una ecuación en la que aparece no sólo la función \\(f\\), sino también sus derivadas. Las leyes físicas, como la segunda ley de Newton, dan lugar de forma natural a ecuaciones diferenciales. Plantear un problema de mecánica, electricidad o termodinámica se convierte en encontar la ecuación diferencial asociada. Resolver el problema se convierte así en resolver la ecuación diferencial. Plantear ecuaciones diferenciales es relativamente sencillo. Resolverlas es, en general, enormemente complicado. Se saben resolver muy pocas. Por eso, aparte de la resolución de ecuaciones diferenciales, hay métodos para entender las características de las ecuaciones sin tener que resolverlas. Podemos saber bajo qué condiciones un sistema se estable o inestable, si oscila o no, si tiende a ciertos valores o no. Muchas de estas características se pueden deducir de las ecuaciones diferenciales sin necesidad de resolver la ecuación. Y si es necesario resolverla, hay métodos numéricos que nos pueden ayudar. Son métodos mucho más complicados que los que vimos para el cálculo de integrales, y con resultados más inciertos. El mundo de las ecuaciones diferenciales es muy complicado, pero es la base de la física y la química, y por lo tanto de la ingeniería. Hemos de adentrarnos en él. En esta breve introducción vamos a conocer las características de una ecuación diferencial y vamos a aprender a resolver algunas especialmente sencillas. 12.1.1 Notación Ya vimos que podemos escribir una derivada como \\(\\frac{dy}{dx}\\) o como \\(y^\\prime(x)\\). Esto da lugar a que se pueda escribir una ecuación diferencial de varias maneras. Como las ecuaciones diferenciales se usan mayoritariamente para saber cçomo evoluciona un sistema en el tiempo, a menos que especifiquemos otra cosa, vamos a suponer que la variable es el tiempo \\(t\\). A la función la denotaremos con \\(x(t)\\). Sabiendo esto, para simplificar la notación, no escribiremos la variable de la función: usaremos \\(x\\) o \\(x^\\prime\\) y no \\(x(t)\\) o \\(x^\\prime(t)\\). Hay 3 notaciones ampliamente usadas para escribir una ecuación diferencial. Una es la notación de Leibniz. Es la que hemos usado arriba. Una ecuación diferencial en esta notación tiene la forma \\[m\\frac{d^2 x}{dt^2} + b\\frac{dx}{dt} + kx = 0.\\] La segunda notación es la notación primada: \\[mx^{\\prime\\prime} + b x^{\\prime} + kx = \\sin(t)\\] La tercera notación habitual es la notación de Newton que, por motivos históricos, se usa en mecánica. Un punto sobre la variable significa su derivada, dos puntos la derivada segunda, etc.: \\[m\\ddot{x} + b\\dot{x} + kx = \\cos(\\omega t + \\phi)\\] También es costumbre poner a la izquierda todos los téminos que tienen que ver con \\(x(t)\\) y su derivada, y a la derecha los que son constantes o dependen sólo de \\(t\\). A esto se llama la forma general de la ecuación. 12.2 Clasificación de las ecuaciones diferenciales Podemos clasificar las ecuaciones diferenciales según algunas características. Orden: El orden de una ecuación diferencial es el orden mayor de las derivadas involucradas en la ecuación. Por ejemplo \\[m\\frac{d^2 x}{dt^2} + b\\frac{dx}{dt} + kx = 0\\] es una ecuación de segundo orden, ya que hay una derivada segunda, mientras que \\[m\\frac{dv}{dt} + k v^2 = -mg\\] es una ecuación diferencial de primer orden, pues sólo hayuna derivada primera. Grado: El grado de una ecuación diferencial es la potencia a la que está elevada la derivada de mayor orden. Por ejemplo \\[m\\frac{d^2x}{dt^2} + k\\left(\\frac{dx}{dt}\\right)^2= -mg\\] es una ecuación de primer grado, mientras que \\[(x^\\prime x t)^3 -7x = t\\] es una ecuación diferencial de tercer grado. Linealidad: Un ecuación diferencial de orden \\(n\\) es lineal si es lineal en \\(x, x^\\prime, x^{\\prime\\prime}, \\dots, x^{(n)}\\). Es decir, toma la forma \\[a_n(t)x^{(n)} + a_{n-1}(t)x^{(n-1)} + \\cdots + a_1(t)x^\\prime + a_0(t)x = g(t).\\] Nótese que las \\(a_i(t)\\) pueden depender de \\(t\\) pero no pueden depender de \\(x\\). Si alguno dependiera de \\(x\\) ya no sería lineal. Si todos los coeficientes \\(a_i\\) son constantes (no dependen ni de \\(x\\) ni de \\(t\\)), se dice que es una ecuación diferencial lineal de coeficientes constantes. Homogeneidad: Una ecuación lineal es homogénea si \\(g(t) = 0\\), es decir, si no hay “nada” en el lado derecho de la ecuación. Por ejemplo \\[m\\frac{d^2 x}{dt^2} + b\\frac{dx}{dt} + kx = 0\\] es una ecuación diferencial lineal de coeficientes constantes y homogénea, mientras que \\[x^{\\prime\\prime} + t x^{\\prime} + kx = \\sin(t)\\] es una ecuación diferencial lineal, pero ni tiene coeficientes constantes, ni es homogénea. Ejemplo 12.1 La ecuación diferencial \\[ml \\frac{d\\theta^2}{dt^2} + kl\\frac{d\\theta}{dt} + mg\\sin(\\theta) = 0\\] es una ecuación de segundo orden y de primer grado, pero no es lineal porque tenemos \\(\\sin(\\theta)\\). Es una ecuación diferencial muy difícil de resolver. Si nos limitamos a valores pequeños de \\(\\theta\\) podemos aproximar \\(\\sin(\\theta)\\) por su polinomio de Taylor: \\(\\sin(\\theta) \\approx \\theta\\). La ecuación resultante es \\[ml \\frac{d\\theta^2}{dt^2} + kl\\frac{d\\theta}{dt} + mg\\theta = 0.\\] Esta ecuación diferencial es lineal, de coeficientes constantes y homogénea y es mucho más fácil de resolver. Como hemos dicho varias veces, resolver ecuaciones diferenciales es en general muy difícil. Vamos a aprender a resolver dos casos, posiblemente los dos más simples. Ecuaciones diferenciales de primer orden de variables separables y ecuaciones diferenciales de primer orden lineales. 12.3 Ecuaciones diferenciales de variables separables Tenemos una ecuación diferencial de primer orden que tiene la forma \\[\\frac{dx}{dt} = g(x)h(t).\\] Decimos que esta ecuación deiferencial es de variables separables. Para resolverla pasamos todo lo que tiene \\(x\\) a un lado y todo lo que tiene \\(t\\) al otro: \\[\\frac{dx}{g(x)} = h(t)\\,dt.\\] Y ahora podemos integrar cada lado: \\[\\int\\frac{dx}{g(x)} = \\int h(t)\\,dt.\\] La posibilidad de resolver esta ecuación deferencial depende de la posibilidad de encontrar las primitivas de ambas integrales. Las ecuaciones que hemos deducido del movimiento uniformemente acelerado partían de ecuaciones diferenciales de variables separables. La primera era: \\[\\frac{dv}{dt} = a\\] que resolvimos separando las variables: \\[\\int dv = \\int a\\, {dt}.\\] Y la segunda ecuación era \\[\\frac{dx}{dt} = v_0 + at\\] que también resolvimos separando las variables: \\[\\int dx = \\int (v_0 + at)\\,dt\\] Este caso era muy fácil. Otros no lo son tanto. Ejemplo 12.2 Tenemos un controlador de velocidad, para mantener una velocidad constante especificada \\(v_e\\). Este controlador ejerce una fuerza sobre el objeto proporcional a la diferencia de velocidad entre la que lleva y la especificada: \\[F = k(v_e - v).\\] Nótese que si la velocidad es inferior a \\(v_e\\) la fuerza es positiva (acelera), mientras que si es mayor que la especificada, la fuerza es negativa (decelera). Queremos saber cómo varía la velocidad si inicialmente es \\(v_0\\). Aplicando la segunda ley de Newton tenemos la ecuación diferencial \\[m\\frac{dv}{dt} = k(v_e - v)\\] Tal y como está, no es una ecuación diferencial de variables separadas, pues en el lado derecho tenemos \\(kv_e - kv\\), que es una resta de funciones, no un producto, que es lo que nos gustaría. Lo podemos resolver haciendo un cambio de variable, usando la diferencia de velocidad respecto a \\(v_e\\) en vez del valor absoluto de la velocidad. Es decir, el cambio es \\(v_d(t) = v_e - v(t)\\). Derivando vemos que \\(\\frac{dv_d}{dt} = - \\frac{dv}{dt}\\). Nos queda la ecuación diferencial \\[\\frac{dv_d}{dt} = -\\frac{k}{m}v_d\\] Y esta sí que es de variables separables: \\[\\frac{dv_d}{v_d} = -\\frac{k}{m}dt\\] Integramos \\[\\log(|v_d|) = -\\frac{k}{m}t + C\\] que lo podemos escribir como \\[v_d = e^{-\\frac{k}{m}t + C}.\\] Deshacemos el cambio: \\[v_e - v(t) = e^{-\\frac{k}{m}t + C}\\] Es decir, \\[v(t) = v_e - e^{-\\frac{k}{m}t + C}\\] Para hallar el valor de \\(C\\) imponemos la condición inicial: \\[v(0) = v_0 = v_e - e^{-\\frac{k}{m}0 + C} = v_e - e^C\\] Es decir: \\[v_e - v_0 = e^C\\] Recordando que \\(e^{a+b} = e^a e^b\\) nos queda \\[v(t) = v_e - (v_e - v_0)e^{-\\frac{k}{m}t}\\] Lo arreglamos un poco para sumar en vez de restar: \\[v(t) = v_e + (v_0 - v_e)e^{-\\frac{k}{m}t}\\] Derivando esta función e introduciéndola en la ecuación diferencial vemos que es una solución a la ecuación de partida. Hagamos algunas gráficas. Supongamos que \\(v_e = 5\\). Cogemos dos velocidades iniciales, \\(v_0 = 1\\) y \\(v_0 = 6\\). Podemos ver que siempre tiende la velocidad hacia este valor especificado. También se observa que cuánto más lejos estamos de \\(v_e\\) más rápidamente cambia la velocidad (más fuerza hace el regulador), y que al acercarnos cambia de forma más lenta. De esta ecuación podemos ver que cuánto mayor es \\(k\\), es decir mayor es la fuerza que puede aplicar el regulador, más rápidamente se acerca a \\(v_e\\). Finalmente obervamos que cuanta mayor es la masa, al tener mayor inercia, se acerca más lentamente a \\(v_e\\). 12.4 Ecuaciones diferenciales lineales de primer orden Tras haber aprendido a integrar las ecuaciones diferenciales de variables separables, vamos a aprender a integrar las lineales de primer orden: \\[a_1(t)\\frac{dx}{dt} + a_0(t) x = g(t).\\] Se puede deducir paso a paso cómo obtener una solución a este tipo de ecuaciones diferenciales, pero aquí se va a dar como un procedimiento y comprobaremos que la solución obtenida es solución de la ecuación. Lo primero que vamos a hacer es dividir todo por \\(a_1(t)\\): \\[\\frac{dx}{dt} + \\frac{a_0(t)}{a_1(t)} x = \\frac{g(t)}{a_1(t)}.\\] Para no tener fracciones, vamos a cambiar los nombres de los parámetros y de la función: \\[\\frac{dx}{dt} + P(t) x = f(t).\\] A esto se le llama la forma estándar de la ecuación diferencial. El primer paso es calcular \\[e^{\\int P(t)dt}.\\] A esto se le llama el factor integrante. Mutiplicamos ambos lados de la ecuación por este factor integrante: \\[\\frac{dx}{dt}e^{\\int P(t)dt} + P(t) e^{\\int P(t)dt} x = e^{\\int P(t)dt}f(t).\\] Lo que tenemos al lado izquierdo es la derivada del producto \\(xe^{\\int P(t)dt}\\). Luego podemos reescribir la ecuación como \\[\\frac{d}{dt}\\left(xe^{\\int P(t)dt}\\right) = e^{\\int P(t)dt}f(t).\\] Integramos ambos lados y tenemos \\[x e^{\\int P(t)dt} = \\int e^{\\int P(t)dt}f(t) \\, dt.\\] Y ahora despejando \\(x(t)\\) tenemos la solución a nuestra ecuación. El método es simple. Lo fácil o difícil que es resolver esta ecuación diferencial depende de lo fácil o difícil que sea resolver las integrales que aparecen. Veamos un ejemplo. Ejemplo 12.3 Resuelve la ecuación diferencial \\[m\\frac{dv}{dt} = k(v_e - v).\\] Antes la resolvimos por el método de separación de variables. Pero la podemos escribir como una ecuación diferencial lineal. La reescribimos en forma estándar: \\[\\frac{dv}{dt} + \\frac{k}{m}v = \\frac{k}{m}v_e.\\] Entonces \\(P(t) = k/m\\) y \\(f(t) = \\frac{k}{m}v_e.\\) Vemos que es una ecuación diferencial lineal de coeficientes constantes. Obtenemos el factor integrante: \\[e^{\\int\\frac{k}{m} \\,dt} = e^{\\frac{k}{m} t}\\] Multiplicamos ambos lados de la ecuación por el factor integrante: \\[ \\frac{dv}{dt} e^{\\frac{k}{m} t} + \\frac{k}{m}e^{\\frac{k}{m} t}v = e^{\\frac{k}{m} t}\\frac{k}{m}v_e\\] o lo que es lo mismo \\[ \\frac{d}{dt} \\left(v e^{\\frac{k}{m} t}\\right) = e^{\\frac{k}{m} t}\\frac{k}{m}v_e.\\] De donde, integrando: \\[v e^{\\frac{k}{m} t} = \\int v_e \\frac{k}{m} e^{\\frac{k}{m} t} \\,dt= v_e e^{\\frac{k}{m} t} + C\\] Imponemos la condición inicial \\(v(0) = v_0\\) para obtener \\(C\\): \\[v_0 e^{\\frac{k}{m} 0} = v_0 = v_e e^{\\frac{k}{m} 0} + C = v_e + C\\] De donde \\(C = v_0-v_e\\). Introducimos el valor de \\(C\\) y despejamos \\(v(t)\\). El resultado es: \\[v(t) =v_e + (v_0-v_e) e^{-\\frac{k}{m} t}. \\] Es, efectivamente, el mismo resultado que el obtenido anteriormente. Sucede con cierta frecuencia que una ecuación diferencial se pueda resolver de varias maneras. El método a escoger depende del gusto de cada uno. Veamos otro ejemplo. Ejemplo 12.4 Resuelve la ecuación diferencial \\(x^\\prime t = 2x + t^3 \\cos(t)\\). Sabemos que en \\(t = 1\\) el valor de \\(x\\) es 0. A primera vista no parece una ecuación diferencial lineal, pero sí que lo es. La reescribimos en forma estándar para asegurarnos: \\[x^\\prime - \\frac{2}{t} x = t^2 \\cos(t)\\] Es una ecuación diferencial lineal, con \\(P(t) = - \\frac{2}{t}\\) y \\(f(t) = t^2 \\cos(t)\\). Calculamos el factor integrante: \\[e^{\\int -\\frac{2}{t} \\,dt} = e^{-2 \\log(t)} = e^{\\log\\left(\\frac{1}{t^2}\\right)} = \\frac{1}{t^2}\\] Multiplicamos ambos lados de la ecuación por el factor integrante: \\[\\frac{x^\\prime}{t^2} - \\frac{2}{t^3} x = \\cos(t)\\] Ya sabemos que la segunda parte es la derivada del producto \\(x(1/t^2)\\), por lo que integrando ambos lados queda: \\[\\frac{x}{t^2} = \\int \\cos(t)\\, dt = \\sin(t) + C\\] Despejamos \\(x(t)\\): \\[x(t) = t^2 \\sin(t) + C t^2\\] Aplicamos la condición (que en este caso no es inicial) para hallar \\(C\\): \\[ 0 = \\sin(1) + C\\] Y nos queda que \\(C = -\\sin(1) = - 0.841\\) (el ángulo está en radianes). Y la función queda: \\[x(t) = t^2 (\\sin(t) - \\sin(1))\\] "],
["funciones-de-varias-variables.html", "Capítulo 13 Funciones de varias variables 13.1 Funciones vectoriales de variable real 13.2 Funciones reales multivariable 13.3 Derivadas parciales 13.4 Derivadas direccionales 13.5 Integrales múltiples 13.6 Funciones vectoriales multivariable", " Capítulo 13 Funciones de varias variables Las funciones que hemos estudiado hasta ahora toman como entrada un número real y dan como salida un número real. La forma de representar este hecho es \\[f:{\\rm I\\!R} \\to {\\rm I\\!R}.\\] Las hemos llamado simplemente “funciones”, pero si queremos ser más precisos deberíamos llmarlas “funciones reales de varibale real”. Pero en ciencia e ingeniería a menudo nos encontramos que la salida no es un número, sino un vector. Esto es el caso si la salida fuese un campo eléctrico, o una fuerza, que tienen magnitud y sentido. En este caso, tendríamos un numero real de entrada y un vector de \\(n\\) componentes de salida. Lo representamos como \\[f:{\\rm I\\!R} \\to {\\rm I\\!R}^n.\\] Una función de estas características la llamamos una “función vectorial de variable real”. Hablar de números y vectores puede dar lugar a ambigüedades. Por ejemplo, cada componente de un vector es un número. Por eso, cuando hay vectores presentes y posibles ambigúedades, a un vector de una única posición (lo que hasta ahora hemos designado como “número”), se le da el nombre de escalar. *** Podriamos tener otro caso: necesitar varios números de entrada para obtener un único número de salida. Este caso se nos da, por ejemplo, si queremos saber ela temperatura en una superficie. Necesitamos dos valores de entrada, las dos componentes necesarias para designar el punto de la superficie, y obtenemos un único valor de salida. Esto ser representa como \\[f:{\\rm I\\!R}^m \\to {\\rm I\\!R}.\\] A esto se le llama una “función real multivarible”. Finalmente, podemos tener una función con \\(m\\) variables de entrada y que produce un vector de \\(n\\) componentes de salida. Un ejemplo sería el viento que hay sobre una superficie, por ejemplo en un campo de regatas. Esto se representa como \\[f:{\\rm I\\!R}^m \\to {\\rm I\\!R^n},\\] y se le llama una “función vectorial multivariable”. El análisis de una función de varias variables es, como era de esperar, más compleja que el de una variable. En esta introducción vamos a mostrar cómo se extienden los conceptos y operaciones que hemos visto en las funciones reales de una variable: ímites, continuidad, derivadas, integrales. 13.1 Funciones vectoriales de variable real Supongamos que tenemos un joven que va conduciendo un coche. Por un lado nos interesa la veocidad a la que va el coche en cada instante. Y por otro nos interesa el diámetro de las pupilas del conductor en cada instante de tiempo. Esto lo podemos representar como dos funciones reales de una variable real: \\(v(t)\\) y \\(d(t)\\). Sabemos analizar cada función: podemos determinar si es continua o no, calcular (s existe) el límite en cualquier punto, derivar, integrar… Como la variable de entrada es la misma, lo podemos combinar en un vector, que llamaremos \\(\\vec{y}(t)\\), con la velocidad como primera componente y con el diámetro de la pupila de segundo: \\(\\vec{y}(t) = (v(t), d(t)).\\) Quizá lo hacemos porque nos simplifica la programación de cálculos y gráficas en el ordenador o por el motivo que sea. Lo que aprece obvio, es que por el heco de “empaquetar” las dos funciones en una, la continuidad, derivabilidad, etc de cada función por separado no cambia: si en \\(t = 12\\) la derivada de \\(v(t)\\) es 2, no por haberlo empaquetado en un vector va a pasar a ser 3. Y lo mismo con la dilatación de las pupilas. Nuestra lógica nos dice que todas las cuestiones de la función vectorial se pueden obtener mirando cada componente por separado. Entonces \\[\\lim_{t \\to a} \\vec{y(t)} = (\\lim_{t \\to a}v(t), \\lim_{t \\to a}d(t)),\\] y \\[\\vec{y^\\prime(t)} = \\left(v^\\prime (t), d^\\prime (t)\\right),\\] y también \\[\\int \\vec{y(t)} dt = \\left(\\int v(t) dt, \\int d(t) dt\\right).\\] Y con el mismo razonamiento poemos deducir que la función \\(\\vec{y}(t)\\) es continua en \\(t = a\\) si ambas funciones \\(v(t)\\) y \\(d(t)\\) son continuas en \\(t = a\\), etc. En este ejemplo se han escogido dos funciones, \\(v(t)\\) y \\(d(t)\\), que parecen independientes una de otra. Pero si escogemos, por ejemplo una fuerza en un espacio tridimensional, \\(\\vec{F} = (F_x, F_y, F_z)\\), sabemos que podemos escribir ecuaciones de cada componente por separado, luego estamos en el mismo caso. Luego si tenemos una viga que podemos considerar unidimensional, la fuerza que se ejerce en cada punto de la viga será \\(\\vec{F}(x)\\). Analizar esta función va a consistir en analizar por separado cad a función \\(F_x(x)\\), \\(F_y(x)\\) y \\(F_z(x)\\). En resumen, analizar las funciones vectoriales de una variable real es más largo que si es una función real de variable real, pues hay que repetir el análisis para cada componete por separado. Pero no son más complicadas pues no hay cálculos ni conceptos nuevos. Desgraciadamente, no se puede decir lo mismo de las funciones reales multivariable. 13.2 Funciones reales multivariable Hemos visto el caso de función más simple: un número de entrada, un número de salida. Pero en general, para saber algo necesitamos más de un número. Un caso simple es el volumen de una caja, que depende del alto, ancho y alto. O tenemos la Ley de Coulomb: \\[F(q, q^\\prime, r) = \\frac{1}{4π\\varepsilon_0}\\frac{q\\,q^\\prime}{r^2}\\] que vemos que depende de tres valores: las dos cargas y la distancia entre ellas. Una función real de \\(n\\) variables reales es una función que toma \\(m\\) números y produce un número: \\[f:{\\rm I\\!R}^n \\to {\\rm I\\!R}.\\] A las \\(n\\) variables de entrada se le llaman variables independientes y a la variable de salida se le llama variable dependiente. Ejemplo 13.1 El volumen de un cono se calcula con la expresión \\[V = \\frac{1}{3}π R^2 h.\\] Vemos que es una función de dos variables independientes: el radio \\(R\\) y la altura \\(h\\). Una gran ventaja de las funciones de una variable es que tienen una gráfica fácil de dibujar, lo que permite “ver” la función, lo que suele ser una gran ayuda en su análisis. Una función de dos variables se puede representar gráficamente, aunque, debido a la perspectiva, ya no se ve tan bien: Una alternativa a la representación en perspectiva es el uso de curvas de nivel: Ambas representaciones tienen sus ventajas e inconvenientes. Si la función es de más de dos variables, ya no tenemos ninguna forma de representar su gráfica. Por eso, el análisis de las funciones multivariable es simbólico y formal y menos intuitivo que el de una variable. Es una dificultad con el que hay que aprender a trabajar 13.2.1 Funciones polinómicas y racionales multivariables Los olinomios y funcione racionales son fuciones de una varaible que aparecen mucho. No es obvio cómo se extiende estos tipos de funciones al caso multivariable. Empecemos con las funciones polinómicas. Vamos a suponer primero que tenemos dos variables independientes, \\(x\\) e \\(y\\). Un ejemplo de función polinómica de dos variables sería \\[f(x,y) = 3 x + 2y^2 - 3xy^3 - 5.\\] Tenemos varios términos y cada uno de ellos o es una constante o aparecen \\(x\\) o \\(y\\) o ambos, cada uno elevado a un entero. Podemos generalizar esto a \\(n\\) variables: una función polinómica \\(f(x_1, x_2, …,x_n)\\) es una función que está comprendida por una suma de términos donde cada uno de estos términos es de la forma \\(kx_1^{m_1}x_2^{m_2}…x_n^{m_n}\\), siendo \\(m_1, m_2, … m_n\\) enteros mayores o iguales a 0. Una definidas las funciones polinómicas, es fácil defiinir las racionales: una función racional es un cociente de dos funciones polinómicas. Un ejemplo sería \\[f(x_1, x_2, x_3, x_4) = \\frac{3 + x_1x_3^2 + x_4}{x_2 + 5x_1x_3x_4^3}\\] 13.2.2 Límites Habíamos definido límite de una función, \\(\\lim_{x \\to a}f(x)\\), como el valor al que tendía la función \\(f(x)\\) cuando \\(x\\) tendía a \\(a\\). Esta idea informal se sigue manteniendo cuando tenemos varias variables, pero ahora la formalización de esta idea es más complicada En el caso de una variable, veíamos que \\(x\\) podía tender a \\(a\\) de dos maneras: desde valores inferiores (desde la izquierda) o desde valores superiores (desde la derecha). Sólo si ambos límites existía y coincidían decíamos que la función tenía límite en \\(x = a\\). Vamos a ver el caso de dos variables, \\(f(x_1, x_2)\\). Ahora el punto al que tiende no es un número, \\(x \\to a\\), sino dos, \\((x_1, x_2) \\to (a_1, a_2)\\). El problema es que ahora nos podemos aproximar a \\((a_1, a_2)\\) de infinitas maneras: desde la izquierda, desde la derecha, desde arriba, desde abajo, desde una diagonal, … y no solamente nos podemos acercar con un recta: nos podemos acercar con una curva o con una espiral. Diremos que existe el límite \\(\\lim{(x_1, x_2) \\to (a_1, a_2)} f(x_1, x_2)\\) si los valores de los límites por todos estos infinitos caminos existen y son iguales. Demostrar la existencia de un límite se ha convertido en algo mucho más complicado, pero no hace falta asustarse: casi siempre es lo que nos podríamos suponer. Ejemplo 13.2 Sea \\[f(x_1, x_2, x_3) = \\frac{x_1 - x_2^2}{1 - x_3}.\\] Esta función tiene limite en todos los puntos en los que \\(x_3 ≠ 1\\). Calculemos algunos valores: \\[lim_{(x_1, x_2, x_3) \\to (1, 2, -3)}f(x_1, x_2, x_3) = \\frac{1 - 2^2}{1 - (-3)} = \\frac{-3}{4}\\] \\[lim_{(x_1, x_2, x_3) \\to (0,0,0)}f(x_1, x_2, x_3) = \\frac{0 - 0^2}{1 - 0} = 0\\] \\[lim_{(x_1, x_2, x_3) \\to (2,1,1)}f(x_1, x_2, x_3) = \\frac{2 - 1^2}{1 - 1} = \\infty\\] También podemos tener indeterminaciones: \\[lim_{(x_1, x_2, x_3) \\to (4,2,1)}f(x_1, x_2, x_3) = \\frac{4 - 2^2}{1 - 1} = \\frac{0}{0}\\] No entraremos en como se resuelven las indeterminaciones. 13.2.3 Continuidad En el caso de una variable decíamos que una función \\(f(x)\\) era continua en \\(x = a\\) si \\(\\lim_{x \\to a} = f(a)\\). Esta misma idea la podemos trasladar al caso de varias variables. Una función \\(f(x_1, x_2, …, x_n)\\) es continua en el punto \\((a_1, a_2, …, a_n)\\) si \\(\\lim_{(x_1, x_2, …, x_n) \\to (a_1, a_2, …, a_n)} =f(a_1, a_2, …, a_n)\\). No entraremos en cómo establecer la continuidad de funciones. Baste saber que las funciones polinómicas son continuas, también las racionales, con la posible excepcion de los puntos donde se anla el denominador. También lo son funciones trigonométricas del tipo \\(\\cos(x+y^2)\\), exponenciales, logarítmicas, etc. 13.3 Derivadas parciales La derivada es la derivada respecto de una variable. Esto era implícito en la notación primada, \\(f^\\prime(x)\\), y explicito en la notación de Leibniz: \\[\\frac{df(x)}{dx}.\\] Ahora que tenemos varias variables seguimos derivando sólo respecto de una de ellas. A esto se llama una derivada parcial. Su representación es similar a la de Leibniz, pero usando una “d” curvada: \\(\\partial\\). La derivada parcial de $f(x,y) respecto de \\(x\\) se escribiría como \\[\\frac{\\partial f(x,y)}{\\partial x}\\] mientras que si es respecto de \\(y\\) se escribiria \\[\\frac{\\partial f(x,y)}{\\partial y}.\\] Calcular estas derivadas parciales es tan fácil como calcular las derivadas ordinarias: se considera que la variable respecto a la cual se deriva es “la” variable y que las demás son constantes. Por ejemplo, sea \\(f(xy) = 3x^2y\\). Calculemos \\(\\frac{\\partial f(x,y)}{\\partial x}\\). Como el 3 y la \\(y\\) son constantes en esta derivada parcial, las podemos sacar fuera: \\[\\frac{\\partial}{\\partial x} (3x^2y) = 3y \\frac{\\partial}{\\partial x} x^2\\] Como ahora la función que queda sólo tiene una variable: aquella respecto a la cual derivamos, procedemos como si fuera una derivada ordinaria: \\[3y \\frac{\\partial}{\\partial x} x^2 = 3y\\, 2x = 6xy\\] Veamos un ejemplo algo mas complicado. Ejemplo 13.3 Sea \\(f(x,y,z) = 3xyz\\sin(x^2y^2 + z)\\). Calcula \\[\\frac{\\partial f(x,y,z)}{\\partial y}.\\] Esto es el producto de \\(3xyz\\) y de \\(\\sin(x^2y^2 + z)\\). Vamos a ir despacio. Empezamos derivando cada parte por separado: \\[\\frac{\\partial}{\\partial y} (3xyz) = 3xz\\] y \\[\\frac{\\partial}{\\partial y} \\sin(x^2y^2 + z) = 2x^2y\\cos(x^2y^2 + z).\\] Y ahora aplicamos la regla de la derivada del un producto: \\[\\frac{\\partial f(x,y,z)}{\\partial y} = 3xz \\cdot \\sin(x^2y^2 + z) + 3xyz \\cdot 2x^2y\\cos(x^2y^2 + z).\\] Esto lo podemos arreglar un poco y queda \\[3xz(\\sin(x^2y^2 + z) + 2x^2y^2 \\cos(x^2y^2 + z))\\] 13.3.1 Interpretación geométrica Aunque en general no hay gráficas y no hay geometría “visible”, podemos dar una interpretación intuitiva de la derivada parcial si tenemos dos variables. Esta interpretacion se puede extender al caso de 3 o más. Supongamos que estamos en una montaña y la función es la elevación sobre el nivel del mar. Es decir \\(z = f(x,y)\\) y \\(z\\) es la elevación. En este caso \\(x\\) es el eje Este-Oeste e \\(y\\) representa el eje Norte-Sur. Suponemos que es positivo hacia el Norte y hacia el Este y negativo hacia el Sur y hacia el Oeste. Entonces \\(\\frac{\\partial z}{\\partial x}\\) es la pendiente de la montaña en el eje Este-Oeste. Si esta derivada parcial es positiva quiere decir que la despazarnos hacia el Este estamos subiendo; si es negativo quiere decir que al desplazarnos hacia el Este estamos bajando; si es 0 quiere decir que en ese punto ni sube ni baja, al desplazarnos hacia el Este, ni sube ni baja (puede subir o bajar si cogemos otra dirección). Y análogamente \\(\\frac{\\partial z}{\\partial y}\\) sería la pendiente en ese punto según el eje Norte-Sur. Si es positiva es que la ir hacia el Norte estamos subiendo; si negativa, es que bajamos; si es 0, en esa dirección ni sube ni baja, aunque puede hacerlo en otras direcciones. Esta imagen de la montaña lo podemos generalizar a cualquier función de dos variables: Y si tenemos más de dos variables la idea es la misma: si todas las variables menos una quedan constantes, lo que nos queda es una curva en una determinada dirección. La derivada parcial es la pendiente de esa curva en ese punto. 13.3.2 Definición formal Después de explicar la idea general de lo que es una derivada parcial y ver su interpretacion geométrica en el caso de dos variables, definamos formalmente lo que es una derivada parcial. Es la misma idea que con la derivada ordinaria: el cálculo del límite cuando damos un “empujoncito” a la función. Solamente que en este caso lo empujamos según una de las variables, dejando el resto fijas. Definición 13.1 Sea la función \\(f(x_1, x_2, … , x_n)\\). Definimos como derivada parcial de \\(f\\) respecto a \\(x_i\\) al límite \\[\\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, …, x_i + h, …, x_n) - f(x_1, …, x_i, …, x_n)}{h}\\] 13.3.3 Derivadas parciales sucesivas La derivada parcial de una función es otra función, que podemos volver a derivar. Así obtenemos derivadas parciales sucesivas. No tenemos que volver a derivar respecto a la misma variable, sino que podemos cambiar. En el caso de una función de dos variables \\(f(x,y)\\) podemos tener cuatro posibles derivadas segundas: \\[\\frac{\\partial}{\\partial x}\\left(\\frac{\\partial f}{\\partial x}\\right) = \\frac{\\partial^2 f}{\\partial x^2} \\qquad \\frac{\\partial}{\\partial x}\\left(\\frac{\\partial f}{\\partial y}\\right) = \\frac{\\partial^2 f}{\\partial x \\partial y}\\] \\[\\frac{\\partial}{\\partial y}\\left(\\frac{\\partial f}{\\partial x}\\right) = \\frac{\\partial^2 f}{\\partial y \\partial x} \\qquad \\frac{\\partial}{\\partial y}\\left(\\frac{\\partial f}{\\partial y}\\right) = \\frac{\\partial^2 f}{\\partial y^2}\\] Hay que tener cuidado: \\[\\frac{\\partial^2 f}{\\partial x \\partial y}\\] quiere decir que primero derivamos respecto de \\(y\\) y después derivamos el resultado respecto de \\(x\\). Por suerte para los descuidados, en se puede demostrar que para la mayoria de las funciones habituales (polinomios, racionales, trigonometricas, etc), da igual el orden, es decir \\[\\frac{\\partial^2 f}{\\partial x \\partial y} = \\frac{\\partial^2 f}{\\partial y \\partial x}.\\] Veamos un ejemplo. Ejemplo 13.4 Halla las cuatro derivadas segundas de la función \\(f(x,y) = x\\sqrt{y^2 + 1}\\). Empezamos por hallar las dos derivadas primeras: \\[\\begin{align} \\frac{\\partial f}{\\partial x} &amp;= \\sqrt{y^2 + 1}\\\\ \\frac{\\partial f}{\\partial y} &amp;= \\frac{xy}{\\sqrt{y^2 + 1}} \\end{align}\\] Y ahora calculamos las cuatro derivadas segundas \\[\\begin{align} \\frac{\\partial^2 f}{\\partial x^2} = \\frac{\\partial}{\\partial x}\\left(\\frac{\\partial f}{\\partial x}\\right) &amp;= \\frac{\\partial}{\\partial x} \\sqrt{y^2 + 1} = 0\\\\ \\frac{\\partial^2 f}{\\partial y \\partial x} = \\frac{\\partial}{\\partial y}\\left(\\frac{\\partial f}{\\partial x}\\right) &amp;= \\frac{\\partial}{\\partial y}\\sqrt{y^2 + 1} = \\frac{y}{\\sqrt{y^2 + 1}}\\\\ \\frac{\\partial^2 f}{\\partial x \\partial y} = \\frac{\\partial}{\\partial x}\\left(\\frac{\\partial f}{\\partial y}\\right) &amp;= \\frac{\\partial}{\\partial x}\\frac{xy}{\\sqrt{y^2 + 1}} = \\frac{y}{\\sqrt{y^2 + 1}}\\\\ \\frac{\\partial^2 f}{\\partial y^2} = \\frac{\\partial}{\\partial y}\\left(\\frac{\\partial f}{\\partial y}\\right) &amp;= \\frac{\\partial}{\\partial y}\\frac{xy}{\\sqrt{y^2 + 1}} = x\\, \\frac{ 1 - y^2}{\\sqrt{(y^2 + 1)^3}} \\end{align}\\] Vemos que \\[\\frac{\\partial^2 f}{\\partial x \\partial y} = \\frac{\\partial^2 f}{\\partial y \\partial x} = \\frac{y}{\\sqrt{y^2 + 1}}\\] 13.4 Derivadas direccionales Hemos visto que las derivadas parcial de \\(f\\) respecto a \\(x_i\\) mide la pendiente de la función si seguimos la dirección del eje \\(x_i\\). Pero eso es un poco restrictivo: nos puede interesar calcular la pendiente respecto a alguna otra dirección. Vamos a ver cómo podemos calcular la pendiente de la función en cualqueir dirección que nos interese. A esto se llama una derivada direccional. Lo primero que debemos hacer es definir la dirección que nos interesa. Sigamos con nuestro ejemplo de la montaña. Digamos que nos interesa la dirección Sudeste-Noroeste, una diagonal. Un vector que va en esa dirección es el vector \\((-1, 1)\\) Nos va interesar tener un vector de longitud unidad y este no lo es: es de longitud \\(\\sqrt{2}\\). Simplemente dividimos cada componente por la oongitud del vector y tenemos nuestro vector direccional unitario \\(\\vec{u} = (u_x, u_y) = \\left(\\frac{-1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right)\\). Para tener la derivada direccional según \\(\\vec{u}\\) hemos de dar el “empujoncito” a nuestra función en esta dirección. Vamos a movernos una pequeña distancia \\(h\\) según esta dirección. En el sistema de coordenadas, quiere decir que nos hemos movido \\(\\frac{-1}{\\sqrt{2}} \\,h = u_x h\\) según el eje Este-Oeste (como es negativo, hacia el Oeste) , y \\(\\frac{1}{\\sqrt{2}} \\,h = u_y h\\) según el eje Norte-Sur (como es positivo, hacia el Norte). No es difícil ver que el límite que hemos de resolver para calcular la pendiente es \\[\\lim_{h \\to 0} \\frac{f(x+ u_x h, y + u_y h) - f(x, y)}{h}.\\] Calcular este límite puede parecer muy complicado, pero se puede demostrar que es simplemente \\[\\frac{\\partial f}{\\partial x}u_x + \\frac{\\partial f}{\\partial y}u_y.\\] Esto, en nuestro ejemplo, se convierte en \\[\\frac{\\partial f}{\\partial x}\\frac{-1}{\\sqrt{2}} + \\frac{\\partial f}{\\partial y}\\frac{1}{\\sqrt{2}}.\\] Definición 13.2 Definimos derivada direccional de la funcion \\(f(x_1, …,x_n)\\) según el vector unitario $ = $ y lo escribimos como \\(D_\\vec{u}f(x_1, …,x_n)\\), como el limite \\[\\lim_{h \\to 0}\\frac{f(x_1 + u_{x_1} h + \\cdots + x_n + u_{x_n} h) - f(x_1, …,x_n)}{h}\\] Esta derivada direccional se puede calcular a partir de las derivadas parciales: \\[D_\\vec{u}f(x_1, …,x_n) = \\frac{\\partial f}{\\partial x_1}u_{x_1} + \\cdots +\\frac{\\partial f}{\\partial x_n}u_{x_n}\\] Ejemplo 13.5 Sea \\(f(x,y) = \\sqrt{36 - x^2 - 3y^2}\\). Calcule sus derivadas parciales y su derivada direccional según la dirección dada por el vector \\(\\vec{v} = (1, 3)\\). Evalua las derivadas en el punto \\(P = (-2,1)\\). Empecemos calculando las derivadas parciales: \\[\\begin{align} \\frac{\\partial f}{\\partial x} &amp;= \\frac{-x}{\\sqrt{36 - x^2 - 3y^2}}\\\\ \\frac{\\partial f}{\\partial y} &amp;= \\frac{-3y}{\\sqrt{36 - x^2 - 3y^2}} \\end{align}\\] El vector que nos han dado no es unitario. Su módulo es \\(\\sqrt{10}\\). El vector unitario en la misma dirección es pues \\(\\vec{u} = \\left(\\frac{1}{\\sqrt{10}}, \\frac{3}{\\sqrt{10}}\\right)\\). Ahora es inmediato calcular la derivada direccional: \\[D_\\vec{u}f(x, y) = \\frac{-x}{\\sqrt{10\\,(36 - x^2 - 3y^2)}} - \\frac{-9y}{\\sqrt{10\\,(36 - x^2 - 3y^2)}} = -\\frac{x + 9y}{\\sqrt{10\\,(36 - x^2 - 3y^2)}}.\\] Evaluemos estas tres derivadas en el punto \\(P = (-2, 1)\\): \\[\\begin{align} \\frac{\\partial f}{\\partial x} &amp;= \\frac{2}{\\sqrt{36 - 4 - 3}} = 0.371\\\\ \\frac{\\partial f}{\\partial y} &amp;= \\frac{-3}{\\sqrt{36 - 4 - 3}} = -0.557 D_\\vec{u}f(x, y) &amp;= -\\frac{-2 + 9}{\\sqrt{10\\,(36 - 4 - 3)}} = -0.411 \\end{align}\\] ##Gradiente Con las derivadas parciales podemos saber cuánto cambia el valor de algo en las direcciones de los ejes. Con las derivadas direccionales podemos saber cuánto cambia el valor en cualquier dirección que queramos. Pero a menudo lo que queremos saber es cuánto es el máximo cambio y en qué dirección se produce. En nuestro ejemplo de la montaña, queremos saber cuál es la pendiente máxima y en qué dirección es. El gradiente nos va a dar esta información. Como el gradiente nos da tanto la magnitud como la dirección, va a ser un vector. Definición 13.3 Dada una función \\(f(x_1, …,x_n)\\) definimos vector gradiente (o simplemente gradiente) de esta función, y lo representamos por \\(\\vec{\\nabla}f\\) al vector \\[\\vec{\\nabla}f(x_1, …,x_n) = \\left(\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, … , \\frac{\\partial f}{\\partial x_n}\\right)\\] Ejemplo 13.6 Sea \\(f(x,y) = \\sqrt{36 - x^2 - 3y^2}\\). Su gradiente es: \\[\\vec{\\nabla}f(x, y) = \\left(\\frac{-x}{\\sqrt{36 - x^2 - 3y^2}}, \\frac{-3y}{\\sqrt{36 - x^2 - 3y^2}}\\right)\\] Se puede demostrar que el gradiente nos da en cada punto la dirección del máximo cambio de la función en ese punto y que el módulo del vector gradiente nos da el valor de la máxima pendiente en el punto. El gradiente es muy útil. Por ejemplo, si tenemos una función con las temperaturas en un espacio, el gradiente en un punto nos indica hacia dónde está el máximo cambio de temperatura, y por lo tanto, hacia dónde va a fluir el calor. Dibuando los gradientes nos podemos hacer una idea del flujo del calor en ese espacio: En el gráfico de la izquierda hay un foco de alta temperatura en el centro y la temperatura asciende alrededor de este foco (y el calor fluye alejandose del foco), mientras que en el de la derecha la temperatura crece uniformemente hacia la izquierda, como si tuviéramos una pared en el lado izquierdo a temperatura uniforme. Notad que en este caso (y muchos otros) el flujo va en sentido contrario al gradiente: el gradiente va de valores menores a mayores de temperatura, mientras que el calor va desde lugares calientes a lugares fríos. Por eso a veces se revierten las flechas, como en el gráfico siguiente: Si esto fuera una superficie, las flechas degradiente nos da una indicación de hacia dónde rodaría una pelota que se dejara en un punto. EL tamaño de la flecha nos indica también la aceleración que tendría. Hay una relación interesante entre el gradiente y las curvas de nivel: el gradiente es siempre perpendicular a las curvas de nivel. Eso es lógico: si el vector gradiente no fuera perpendicular a la curva de nivel, podríamos descomponerlo en dos vectores: uno paralelo a la curva y otro perpendicular. Pero si tiene una componente paralela, quiere decir que hay un cambio de nivel en la curva, lo cual no puede ser: es una curva de nivel constante. Luego el gradiente debe ser perpendicular a la curva de nivel. 13.4.1 Gradientes y derivadas direccionales Vimos en el apartado 13.4 cómo calcular derivadas direccionales. Una vez se tiene el gradiente, calcular una derivada direccional según el vector unitario \\(\\vec{u}\\) es simplemente un producto escalar: \\[D_\\vec{u} f = \\vec{\\nabla}f \\cdot \\vec{u}.\\] Efectivamente \\[\\left(\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, … , \\frac{\\partial f}{\\partial x_n}\\right) \\cdot (u_{x_1}, u_{x_2}…, u_{x_n}) = \\frac{\\partial f}{\\partial x_1}u_{x_1} + \\frac{\\partial f}{\\partial x_2}u_{x_2} + \\cdots \\frac{\\partial f}{\\partial x_n}u_{x_n} = D_\\vec{u} f.\\] 13.4.2 Máximos, mínimos, puntos de silla Con las derivadas ordinarias vimos que si el valor de la primera derivada es 0 podemos tener un máxim, un mínimo o un punto de inflexión de pendiente horizontal. En el caso de funciones de varias variables, pasa algo parecido. Vamos a centrarnos en el caso de dos variables, \\(f(x,y)\\). Si ambas derivadas parciales son 0 podemos tener un máximo: o un mínimo o algo que no es ni un máximo ni un mínimo y que se llam un punto de silla: En el caso de las derivadas ordinarias necesitábamos las derivadas segundas para saber si nos encontrábamos ante un máximo, un mínimo o un punto de inflexión. Aquí pasa algo parecido: necesitamos las cuatro derivadas segundas para poder diferenciar entre los tres casos. No es muy difícil, pero no lo vamos a ver aquí. 13.5 Integrales múltiples Como podemos derivar una función de varias variables, también las podemos integrar. Y la idea general es la misma: lo hacemos respecto de una variable cada vez, manteniendo las demás constantes. A esto se llama una integral múltiple. Por ejemplo, si tenemos la función \\(f(x,y) = \\frac{3 \\sin(y)}{x}\\), podríamos resolver la integral doble \\[\\int_0^π \\int_1^e \\frac{3 \\sin(y)}{x} \\, dx \\, dy.\\] Para dejar claro lo que esto significa, vamos a poner paréntesis: \\[\\int_0^π \\left(\\int_1^e \\frac{3 \\sin(y)}{x} \\, dx\\right) \\, dy.\\] Es decir, primero vamos a integrar la función con respecto a \\(x\\), y haremos variar \\(x\\) entre 1 y \\(e\\), y al resultado lo integraremos respecto a \\(y\\), haciendo variar \\(y\\) entre 0 y π. Hagamos la primera integral. Como es respecto a \\(x\\), entonces \\(3 \\sin(y)\\) es constante y lo podemos sacar fuera y nos queda: \\[\\int_0^π \\left(3 \\sin(y) \\int_1^e \\frac{1}{x} \\, dx\\right) \\, dy.\\] Esta integral es inmediata: \\[\\int_0^π \\left(3 \\sin(y) \\left.\\log(x)\\right|_1^e\\right) \\, dy.\\] Evaluamos: \\[\\int_0^π \\left(3 \\sin(y) (1 - 0)\\right) \\, dy = \\int_0^π 3 \\sin(y) \\, dy.\\] Hecha esta primera integral, pasamos a la segunda, que también es inmediata: \\[\\left.-\\cos(y)\\right|_0^π = -cos(π) - (- cos(0)) = 1 +1 = 2.\\] De la misma manera que el cálculo de derivadas parciales no es en el fondo diferente al cálculo de derivadas simples, calcular integrales múltiples no es en el fondo diferente a calcular integrales simples. 13.5.1 Interpretación geométrica de la integral doble Vimos que la integral simple \\(\\int_a^b f(x)\\, dx\\) es el área bajo la curva de la función entre \\(a\\) y \\(b\\). Una integral doble extiende esta misma idea a una dimensión más: la integral \\[\\int_{a_y}^{b_y} \\int_{a_x}^{b_x} f(x, y) \\, dx \\, dy\\] es el volumen bajo la superficie de \\(f(x, y)\\) dentro del rectángulo: Para integrales triples o con más variables, la idea es la misma, aunque ya no podemos hablar de superficies o volúmenes: si tenemos una función con \\(n\\) variables, la integral nos calcula el “hipervolumen” de dimensión \\(n+1\\) bajo la función. 13.5.2 Primitivas de integrales múltiples Aunque en el ejemplo de arriba hemos evaluado la primera integral antes de continuar con la segunda, no es necesario. Lo que generalmente se hace es calcular la primitiva de la integral múltiple y después evaluar: \\[\\int_0^π \\int_1^e \\frac{3 \\sin(y)}{x} \\, dx \\, dy = \\left.\\left.- 3\\cos(y) \\log(x)\\right|_1^e \\right|_0^π = \\left.- 3\\cos(y) (1 - 0) \\right|_0^π = -\\cos(0) - (- \\cos(π)) = 2\\] 13.5.3 Orden de integración Hemos visto que hemos de integrar desde dentro hacia fuera. Si tenemos \\[\\int_{z_a}^{z_b}\\int_{y_a}^{y_b}\\int_{x_a}^{x_b} f(x, y, z) \\, dx\\, dy \\, dz\\] hemos primero de integrar respecto de \\(x\\), después respecto de \\(y\\) y finalmente respecto de \\(z\\). Pero se puede demostrar que en ciertas circunstancias se puede cambiar el orden de integración sin cambiar el resultado. Si se cumplen las circunstancias \\[\\int_{z_a}^{z_b}\\int_{y_a}^{y_b}\\int_{x_a}^{x_b} f(x, y, z) \\, dx\\, dy \\, dz =\\int_{y_a}^{y_b}\\int_{z_a}^{z_b}\\int_{x_a}^{x_b} f(x, y, z) \\, dx\\, dz \\, dy\\] o cualquier otra combinación que hagamos. Nótese que si cambiamos el orden de los \\(dx\\), \\(dy\\) y \\(dz\\) del final de la integral, hemos de cambiar también el orden de los límites de integración al principio: si cambio el orden de integración he de cambiar también el orden de evaluación. ¿Y cuáles son las circunstancias que permiten el cambio? No entraremos en detalle, pero las funciones habituales (polinomios, exponenciales, trigonomñetricas, etc) las cumplen. Casi siempre lo podremos hacer. 13.5.4 Ejemplos Las integrales múltiples son muy útiles para calcular superficies y volúmenes de figuras geométricas. Sabemos que la superficie del círculo de radio \\(R\\) es \\(S = πR^2\\). Vamos a usar una integral doble para deducirlo. Ejemplo 13.7 Calcula con integrales la superfice de un círculo de radio R. Para calcular la superficie sumaremos pequños rectángulos de lados \\(dx\\) y \\(dy\\): Empecemos por calcular la superficie de una tira horizontal que está a altura \\(y\\). Esto será la suma de las áreas de los rectángulos: \\[\\int_a^b dx dy\\] Hemos de determinar los extremos de integración, que dependen del valor de \\(y\\). Por Pitágoras es fácil ver que \\(a = -\\sqrt{R^2 - y^2}\\) y que \\(b = \\sqrt{R^2 - y^2}\\). Por lo tanto la integral es \\[\\int_{-\\sqrt{R^2 - y^2}}^\\sqrt{R^2 - y^2} dx dy.\\] Ahora hemos de sumar todas las tiras, desde el extremo inferior del círculo (\\(y = -R\\)) al extremo superior (\\(y = R\\)). Y así tenemos nuestra integral doble: \\[\\int_{-R}^R \\int_{-\\sqrt{R^2 - y^2}}^\\sqrt{R^2 - y^2} dx\\, dy.\\] La primera integral es inmediata y nos queda \\[\\int_{-R}^R 2\\sqrt{R^2 - y^2} dy.\\] Sacamos la \\(R\\) de la raíz y hacemos el cambio de variable \\(u = \\frac{y}{R}\\), lo que implica que \\(dy = R du\\). Con el cambio de variable cambiamos los extremos de integración. Es fácil ver que si \\(y = -R\\) entonces \\(u = -1\\) y que si \\(y = R\\) entonces \\(u = 1\\). Nos queda \\[2R\\int_{-1}^1 \\sqrt{1 - u^2} \\, R\\, du = 2R^2\\int_{-1}^1 \\sqrt{1 - u^2} \\, du\\] La integral \\(\\int \\sqrt{1 - u^2} \\, du\\), que parece inocente, no es tan fácil. Primero hemos de hacer al cambio de variable \\(u = \\sin(v)\\), lo que implica que \\(du = \\cos(v) dv\\). Como \\(1 - \\sin^2 (v) = \\cos^2(v)\\) (para esto hacemos el cambio), nos queda: \\[\\int \\sqrt{1 - u^2} \\, du = \\int \\cos^2(v) \\, dv.\\] Ahora hemos de aplicar la igualdad trigonométrica \\(\\cos^2(v) = \\frac{1}{2}(\\cos(2v) + 1)\\). Y a partir de aquí ya sale. La solución es \\[2R^2 \\left(\\left. \\frac{1}{2}(u \\sqrt{1-u^2} + \\arcsin(u))\\right|_{-1}^{1} \\right)\\] Y el resultado de esto es \\(πR^2\\). Parece una forma muy complicada de calcular una superficie. Eso es porque hemos usado coordenadas rectangulares aplicadas a un círculo. El cálculo de la integral se puede simplificar mucho si escogemos mejor las variables. Usemos coordenadas polares. Nuestras coordenadas son ahora \\(r\\), la distancia al centro, y \\(\\theta\\), el ángulo. Vamos a ir sumando pequeños sectores circulares. Como son muy pequeños, los podemos considerar rectángulos y su superficie será \\(dr\\cdot rd\\theta\\). Es \\(rd\\theta\\) y no sólo \\(d\\theta\\), pues \\(d\\theta\\) es un ángulo y queremos una longitud: \\(rd\\theta\\) es una longitud. Tenemos que sumar todos estos rectángulos, desde \\(r = 0\\) a \\(r = R\\), esto nos da una “cuñita”, y después debemos barrer la cuña por todo el círculo, es decir , desde \\(\\theta = 0\\) a \\(\\theta = 2π\\). La integral a resolver es pues \\[\\int_0^{2π}\\int_0^R r\\,dr \\,d\\theta\\] y esta integral es de resolución inmediata: \\[\\int_0^{2π}\\int_0^R r\\,dr \\,d\\theta = \\left.\\left.\\frac{r^2}{2} \\theta\\right|_{r=0}^{r = R}\\right|_{\\theta = 0}^{\\theta = 2π} = πR^2\\] Vamos a resolver otro problema, esta vez aplicando coordenadas rectangulares a un rectángulo. Ejemplo 13.8 Tenemos una plancha rectangular de un material que no tiene densidad constante: es más pesada a la derecha y arriba que a la izquierda y abajo. Suponiendo el origen de coordenadas en el ángulo inferior izquierdo, la densidad \\(\\sigma\\) en el punto de coordenadas \\((x, y)\\) viene dada por la expresión \\(\\sigma(x, y) = 1 + 0.3 x + 0.7 y\\). La plancha tiene anchura \\(a\\) y altura \\(b\\). ¿Cuál es su masa? Para calcular la masa de la plancha, hemos de sumar la masa de todos los pequeños rectángulos de tamaño \\(dx\\), \\(dy\\). Como los rectángulos son muy pequeños, podemos considerar que en ellos la densidad es constante. Si el rectángulo está en el punto \\((x, y)\\), la masa de este pequeño rectángulo será \\(\\sigma\\, dx\\, dy = (1 + 0.3 x + 0.7 y) \\, dx\\, dy\\). Sumamos las masas de todos estos rectángulos: \\[\\int_0^b\\int_0^a (1 + 0.3 x + 0.7 y) \\, dx\\, dy = \\left.\\left. xy + 0.7x\\frac{y^2}{2} + 0.3\\frac{x^2}{2}y \\right|_{x=0}^{x = a}\\right|_{y = 0}^{y = b} = ab + 0.35 ab^2 + 0.15a^2b\\] Acabemos este apartado calculando un volumen con una integral triple: Ejemplo 13.9 Calcula el volumen de un cono de radio \\(R\\) y altura \\(h\\). Dividiremos el cono en una serie de discosapilados verticalmente. Como los discos son círculos, usaremos coordenadas polares, \\(r\\) y \\(\\theta\\), como en el ejemplo del círculo, y para la altura usaremos una variable que llamaremos \\(z\\). Dividimos el cono en pequeños cubos de lados \\(dr\\), \\(rd\\theta\\) y \\(dz\\). El volumen de un disco se calcula casi igual que el del círculo, ya hecho: \\[\\int_0^{2π}\\int_0^? r\\,dr \\,d\\theta\\, dz\\] He puesto un interrogante en el límite superior de la integral en \\(r\\), porque el radio del disco va a depender de a qué altura esté: en la base va a ser \\(R\\), pero después va a disminuir cuánto más alto esté. Es decir, va a depender de \\(z\\). No es difícil deducir que el radio de un disco a altura \\(z\\) es \\(R - \\frac{R}{h}z\\). Entonces esta integral queda: \\[\\int_0^{2π}\\int_0^{R - \\frac{R}{h}z} r\\,dr \\,d\\theta\\, dz.\\] Este es el volumen de un disco que está a altura \\(z\\). Ahora hay que sumar todos los discos desde \\(z=0\\) a \\(z = h\\): \\[\\int_0^h\\int_0^{2π}\\int_0^{R - \\frac{R}{h}z} r\\,dr \\,d\\theta\\, dz.\\] Las dos primeras integrales son fáciles y ya las hemos hecho. Nos queda la tercera: \\[π\\int_0^h \\left(R - \\frac{R}{h}z\\right)^2dz\\] Desarrollando: \\[π\\int_0^h \\left(R^2 + \\frac{R^2}{h^2}z^2 - 2\\frac{R^2}{h}z\\right)dz\\] Es un polinomio, por lo tanto, inmediata: \\[π\\left.\\left(R^2z + \\frac{R^2}{h^2}\\frac{z^3}{3} - 2\\frac{R^2}{h}\\frac{z^2}{2}\\right)\\right|_0^h.\\] Para \\(z=0\\) es 0, luego queda: \\[π\\left(R^2h + \\frac{R^2}{h^2}\\frac{h^3}{3} - \\frac{R^2}{h}h^2\\right) = π\\left(R^2h + \\frac{R^2 h}{3} - R^2h\\right).\\] Y nos queda la conocida fórmula del volumen de uncono: \\[V = \\frac{1}{3}πR^2 h\\] Para terminar, calculemos la posición del centro de masas de la plancha de densidad no uniforme del ejemplo que hemos visto antes. La posición del centro de masas será un vector, pues tiene dos componentes. Esto quiere decir que tenemos dos variables de entrada y un vector de salida. Luego tenemos una función vectorial multivariable. Veamos qué hacer con estas fuciones. 13.6 Funciones vectoriales multivariable Cuando comentamos las funciones vectoriales de una variable vimos que era como tener un función real de una variable por cada componente del vector: no había ningún cálculo ni concepto nuevo, sino que había que repetir lo mismo \\(m\\) veces. Con las funciones vectoriales multivariable pasa lo mismo: tenemos \\(m\\) componentes, cada una de ellas, una función de \\(n\\) variables. Repetimos de una función de \\(n\\) variables una vez or componente, esto es, \\(m\\) veces. No vamos a entrar más en ello. Simplemente haremos un ejemplo. Tenemos una plancha rectangular de un material que no tiene densidad constante: es más pesada a la derecha y arriba que a la izquierda y abajo. Suponiendo el origen de coordenadas en el ángulo inferior izquierdo, la densidad \\(\\sigma\\) en el punto de coordenadas \\((x, y)\\) viene dada por la expresión \\(\\sigma(x, y) = 1 + 0.3 x + 0.7 y\\). La plancha tiene anchura \\(a\\) y altura \\(b\\). ¿Dónde está su centro de masas? La expresión para encontrar el centro de masas de un objeto continuo es \\[\\vec{r}_{CM} = \\frac{1}{M}\\int\\vec{r}\\,dm\\] El vector \\(\\vec{r} = (x\\,\\vec{i} + y\\,\\vec{j})\\) es el vector que localiza \\(dm\\). Este diferencial es un rectángulo de lados \\(dx\\) y \\(dy\\) y su densidad la podemos considerar constante y es \\(1 + 0.3 x + 0.7 y\\). Sabmos la masa de la plancha, pues la hemos calculado ya, \\(M = ab + 0.35 ab^2 + 0.15a^2b\\). La expresión queda: \\[\\vec{r}_{CM} = \\frac{1}{M}\\int_0^b\\int_0^a(x\\,\\vec{i} + y\\,\\vec{j})(1 + 0.3 x + 0.7 y)\\,dx\\,dy.\\] Esta integral se descompone en 2: \\[\\frac{1}{M}\\left(\\left(\\int_0^b\\int_0^a x(1 + 0.3 x + 0.7 y)\\,dx\\,dy\\right) \\vec{i} + \\left(\\int_0^b\\int_0^a y(1 + 0.3 x + 0.7 y)\\,dx\\,dy\\right) \\vec{j}\\right).\\] Son integrales fáciles y no las haremos. El resultado es \\[\\vec{r}_{CM} = \\frac{1}{M}\\left(\\frac{a^2b}{2} + 0.1a^3b + 0.175a^2b^2\\right)\\vec{i} + \\frac{1}{M}\\left(\\frac{ab^2}{2} + 0.075a^2b^2 + \\frac{0.7}{3}ab^3\\right)\\vec{j}\\] "]
]
